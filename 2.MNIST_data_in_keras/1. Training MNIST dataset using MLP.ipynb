{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b0d4f7",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf331e",
   "metadata": {},
   "source": [
    "`MNIST` is a dataset of $60,000$ grayscale images($28x28$ $pixels$) of the $10$ digits ($0-9$), along with a test set of $10,000$ images\n",
    "\n",
    "The digits have been size-normalized and centered in a fixed-size image of $28x28$ pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f4bea",
   "metadata": {},
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology) database is a large collection of handwritten digits as monochrome images. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "The goal of this experiment is to find a set of hyperparameters that result in an accurate model and excellent model performance using GridSearchCV from Scikit-learn as a tunning technique.\n",
    "\n",
    "Randomly I selected 3 optimizers (Adam, RMSprop, and SGD) as a starting point to develop the MLP models; later I tuned the 3 different models with their own hyperparameters and chose the model that predicted with higher accuracy the digits.\n",
    "\n",
    "I created my own database with 20 samples and I preproced the images trying to simulate the original set to predict digits with the selected model.\n",
    "\n",
    "In the end, the model showed high accuracy on the test set but the accuracy decreased with the custom dataset.\n",
    "\n",
    "The problem with MNIST is that the dataset is \"too perfect\";  in real life, we have to deal with lights and shadows in images, variations in the way people draw a digit, noise (shapes that are not part of the actual digit), no-centered draws, and more consideration. A digit recognition model that only works on its own dataset wouldn't be that interesting but is good enough if you are new in this field and if your goal is to learn, practice, and get familiar with different machine learning tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acff5e3",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Yefeng Xia. (August 19,2020). [From MNIST to the real-world, why the trained CNN model not works?](https://yefengxia.medium.com/from-mnist-to-the-real-world-why-the-trained-cnn-model-not-works-701fac4b73d2)\n",
    "\n",
    "2. Engati Simply Intelligence. (January ,2021). [MNIST Dataset](https://www.engati.com/glossary/mnist-dataset)\n",
    "\n",
    "3. Keras.io.().[MNIST digits classification dataset](https://keras.io/api/datasets/mnist/)\n",
    "\n",
    "4. Mostafa Ibrahim. (March 13, 2024).[A Deep Dive Into Learning Curves in Machine Learning](https://wandb.ai/mostafaibrahim17/ml-articles/reports/A-Deep-Dive-Into-Learning-Curves-in-Machine-Learning--Vmlldzo0NjA1ODY0#convergence-)\n",
    "\n",
    "5.  Jason Brownlee. (August 6, 2019). [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a610ff",
   "metadata": {},
   "source": [
    "# 2. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87240017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MNIST database has a training set of 48000 examples.\n",
      "The MNIST database has a validation set of 12000 examples.\n",
      "The MNIST database has a test set of 10000 examples.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# extract validation dataset\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42)\n",
    "\n",
    "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
    "print(\"The MNIST database has a validation set of %d examples.\" % len(X_validation))\n",
    "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945e860c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the images: (28, 28)\n",
      "label of the first image 5\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the images:\",X_train[0].shape)\n",
    "print(\"label of the first image\",y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30054aff",
   "metadata": {},
   "source": [
    "# 3. Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7443548a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLkAAAGVCAYAAAASbSMnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxVklEQVR4nO3df5TVdZ0/8NfA4EgIo8iPgYBZ1h9ribGGJpI/0A2UklWx1dItPLu5mj8KsV/GUcfaJDnqWofSrF3NTUuPq2ZlGqWMlmupi2lmfkEx8CAiqDOEMgjz+f7BcXQChPc4d+687308zvmc47339ZnP63M/nM/Led7P/UxNURRFAAAAAEDG+pS7AQAAAAB4p4RcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcVITrrrsuampq4tlnn01et6mpKWpqamL16tXd1s8bP7OrTj311Kipqdli2WeffbqtRwDSVNqsiYj4v//7v/jQhz4Uu+yyS+y6664xY8aMeOaZZ7qpQwBSVNqc+fWvfx2f+tSnYsKECVFXV9flfYMUteVuANi6/v37xz333LPFcwDQHf70pz/F5MmT4+///u/j5ptvjvXr18eFF14Yhx56aDz66KMxdOjQcrcIQMZ+9atfxS9/+cvYf//9Y9CgQbFw4cJyt0QVEHJBL9WnT5+YOHFiudsAoEJdeOGFUVdXFz/96U9j0KBBERExYcKE2GuvveKyyy6LSy+9tMwdApCzCy64IC666KKIiLjsssuEXPQIX1ekYi1YsCCOPfbYGDVqVOy8886x5557xumnn77NS3iXL18eM2bMiEGDBkV9fX388z//c7z44otb1N10001x8MEHx4ABA2KXXXaJo446KhYtWlTq3QGgF8p11mzcuDF++tOfxgknnNARcEVENDY2xhFHHBG33XZbt20LgK7Ldc5EbP7QHnqaf3VUrKeffjoOPvjguOqqq+IXv/hFXHjhhfHb3/42DjnkkHj99de3qD/++ONjzz33jFtuuSWampri9ttvj6OOOqpT7SWXXBIf//jH473vfW/cfPPN8d///d+xdu3aOPTQQ+OPf/zj2/bzxnfsr7vuuh3q/7XXXouGhobo27dvjBo1Ks4+++x46aWXkt4DAEor11nz9NNPx2uvvRbve9/7tnjtfe97XyxZsiTWr1+/Y28CACWT65yBcvF1RSrWGWec0fHfRVHEpEmTYvLkydHY2Bg///nP4x//8R871c+YMSPmzZsXERFTp06N4cOHxymnnBI333xznHLKKbF8+fK46KKL4uyzz45vfvObHetNmTIl9tprr7j44ovjpptu2mY/ffr0ib59++7QJxrjx4+P8ePHx7hx4yIiorm5Of7jP/4jfvWrX8VDDz0Uu+yyS9J7AUBp5Dpr1qxZExERgwcP3uK1wYMHR1EU8fLLL8eIESO2/yYAUDK5zhkoF/8yqVirVq2KM844I0aPHh21tbXRr1+/aGxsjIiIJ598cov6U045pdPjE088MWpra+Pee++NiIi77747Nm7cGJ/85Cdj48aNHcvOO+8chx9++Ha/Y/7Gep/85Ce32/u5554b5557bkyZMiWmTJkS//7v/x7XX399/OlPf4rvfve7O/gOAFBqOc+aiHjbv5r1Tv9yIwDvXO5zBnqaK7moSO3t7TF16tRYsWJFXHDBBbHffvvFgAEDor29PSZOnBivvfbaFus0NDR0elxbWxu77757x6fdL7zwQkREHHjggVvdZqk/zTj++ONjwIAB8eCDD5Z0OwDsmJxnze677x4Rb17R9VYvvfRS1NTUxK677tot2wKga3KeM1AuQi4q0h/+8If4/e9/H9ddd13MnDmz4/klS5Zsc52VK1fGu9/97o7HGzdujDVr1nT8IjBkyJCIiLjllls6Pj3paUVRGDwAvUTOs2aPPfaI/v37x+OPP77Fa48//njsueeesfPOO5ds+wBsX85zBspFyEVFeuMrFnV1dZ2e/853vrPNdW644YaYMGFCx+Obb745Nm7cGJMnT46IiKOOOipqa2vj6aefjhNOOKH7m96OW265JV599dWYOHFij28bgC3lPGtqa2tj+vTpceutt8a8efNi4MCBERGxbNmyuPfee+Pcc88t2bYB2DE5zxkoFyEXFWmfffaJPfbYI770pS9FURQxePDg+MlPfhILFizY5jq33npr1NbWxpQpU+KJJ56ICy64IMaPHx8nnnhiRET8zd/8TXzlK1+JOXPmxDPPPBNHH3107LbbbvHCCy/E7373uxgwYEBcfPHF2/z5119/ffzLv/xL/Nd//dfbfof9z3/+c5x88snxsY99LPbcc8+oqamJ5ubmuPLKK2PfffeNT33qU11/YwDoNjnPmoiIiy++OA488MA45phj4ktf+lKsX78+LrzwwhgyZEicd955XXtTAOg2uc+ZF198MZqbmyMiOq4c/vnPfx5Dhw6NoUOHxuGHH576lsB2CbmoSP369Yuf/OQn8dnPfjZOP/30qK2tjQ996EPxy1/+MsaMGbPVdW699dZoamqKq666KmpqamL69Olx5ZVXxk477dRRc/7558d73/ve+MY3vhE//OEPo62tLRoaGuLAAw/s9JdPtqa9vT02bdoU7e3tb1s3aNCgGD58eFxxxRXxwgsvxKZNm6KxsTE+85nPxJe//OUYMGBA+hsCQLfLedZEbP7laeHChfHFL34xPvrRj0ZtbW0ceeSRcdlll8XQoUPT3gwAul3uc+aJJ56If/qnf+r03JlnnhkRsUM3uYeuqCmKoih3EwAAAADwTriDNQAAAADZE3IBAAAAkD0hFwAAAADZE3IBAAAAkD0hFwAAAADZqy13A3+tvb09VqxYEQMHDoyamppytwOQvaIoYu3atTFy5Mjo08dnGxFmDUB3M2s6M2cAuteOzpleF3KtWLEiRo8eXe42ACrO8uXLY9SoUeVuo1cwawBKw6zZzJwBKI3tzZle9zHLwIEDy90CQEVyfn2T9wKgNJxfN/M+AJTG9s6vvS7kcjkvQGk4v77JewFQGs6vm3kfAEpje+fXkoVc3/72t2Ps2LGx8847x4QJE+L+++8v1aYAqELmDAClZM4A5KckIddNN90Us2bNijlz5sSiRYvi0EMPjWnTpsWyZctKsTkAqow5A0ApmTMAeaopiqLo7h960EEHxfvf//646qqrOp57z3veE8cdd1zMnTu3U21bW1u0tbV1PG5tbXWTRoASaGlpiUGDBpW7jW6RMmcizBqAnlIps8acAeidtjdnuv1Krg0bNsQjjzwSU6dO7fT81KlT44EHHtiifu7cuVFfX9+xGAYAvJ3UORNh1gCw48wZgHx1e8i1evXq2LRpUwwfPrzT88OHD4+VK1duUX/++edHS0tLx7J8+fLubgmACpI6ZyLMGgB2nDkDkK/aUv3gv77jfVEUW70Lfl1dXdTV1ZWqDQAq1I7OmQizBoB05gxAfrr9Sq4hQ4ZE3759t/iUY9WqVVt8GgIAqcwZAErJnAHIV7eHXDvttFNMmDAhFixY0On5BQsWxKRJk7p7cwBUGXMGgFIyZwDyVZKvK86ePTs+8YlPxAEHHBAHH3xwXHPNNbFs2bI444wzSrE5AKqMOQNAKZkzAHkqSch10kknxZo1a+IrX/lKPP/88zFu3Li48847o7GxsRSbA6DKmDMAlJI5A5CnmqIoinI38Vatra1RX19f7jYAKk5LS0sMGjSo3G30CmYNQGmYNZuZMwClsb050+335AIAAACAnibkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsldb7gYAAACAPEybNi2p/qc//WmJOum6j3zkI0n1d911V4k6obu5kgsAAACA7Am5AAAAAMiekAsAAACA7Am5AAAAAMiekAsAAACA7Am5AAAAAMiekAsAAACA7Am5AAAAAMiekAsAAACA7Am5AAAAAMiekAsAAACA7NWWuwEgL7vttltS/ZgxY0rUSWVZs2ZNUv1zzz1Xok4AAKD7tLe3l7uFLRRFUe4WKBFXcgEAAACQPSEXAAAAANnr9pCrqakpampqOi0NDQ3dvRkAqpQ5A0CpmTUAeSrJPbn23Xff+OUvf9nxuG/fvqXYDABVypwBoNTMGoD8lCTkqq2t9UkHACVjzgBQamYNQH5Kck+uxYsXx8iRI2Ps2LHxsY99LJ555plt1ra1tUVra2unBQDeTsqciTBrAEjndxqA/HR7yHXQQQfF9ddfH3fffXd897vfjZUrV8akSZNizZo1W62fO3du1NfXdyyjR4/u7pYAqCCpcybCrAEgjd9pAPJUUxRFUcoNrFu3LvbYY4/4whe+ELNnz97i9ba2tmhra+t43NraaihAL7bbbrsl1Y8ZM6ZEnVSWtwtotua5555L3kZLS0sMGjQoeb3ebntzJsKsAegp1TprzBmqybRp05Lq77jjjhJ10nXHHHNMUv3dd99dok5Itb05U5J7cr3VgAEDYr/99ovFixdv9fW6urqoq6srdRsAVKjtzZkIswaAd8bvNAB5KMk9ud6qra0tnnzyyRgxYkSpNwVAFTJnACg1swYgD90ecn3uc5+L5ubmWLp0afz2t7+Nj370o9Ha2hozZ87s7k0BUIXMGQBKzawByFO3f13xueeei49//OOxevXqGDp0aEycODEefPDBaGxs7O5N0cuk3n9h//33T6pvbm5Oqu8Jhx12WFJ96ne/P/jBDybV94QhQ4Yk1e+5554l6qSyvPDCC0n1I0eOLFEnvZ85Q2/zxS9+Man+3e9+d1L93Llzk+qff/75pHpgS2YNbNs111xT7ha2cP311yfV33///SXqhHLr9pDrRz/6UXf/SADoYM4AUGpmDUCeSn5PLgAAAAAoNSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANmrLXcDVI5LL700qX733XdPqm9ubk6qj4iYOHFiUv3tt9+eVD948OCk+r59+ybVr1q1Kqk+IqK1tTV5nVJasmRJuVt4x374wx8m1U+YMCF5G48++mjyOkD3O/zww5PX+fznP59Uv3bt2qT61Fnw7W9/O6k+dZZ1Reo2zjjjjBJ1stnTTz+dvM5NN92UVL9s2bKk+g0bNiTVA5TLyJEjk+rb29tL1MmbWlpakupfffXVEnVCubmSCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyF5tuRug9zrjjDOS6j/1qU8l1d92221J9UOGDEmqj4j48Y9/XNJt/O53v0uqv/zyy5PqH3jggaT6iIgVK1YkrwNQqebMmZNUP2vWrORtvPjiiyXdxpgxY5Lqm5ubk+rHjRuXVB8RURRFUv2yZcuS6l966aWk+j322COpfuDAgUn1ERFf/epXk+rnzZuXVH/BBRck1b/++utJ9QDb8pWvfKXcLUC3cSUXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANmrLXcD9Ix+/folr/Ov//qvSfV9+qRlpq+++mpS/csvv5xUHxGx7777Jq+TYu3atUn1bW1tJeoEoDpMnjw5qf6zn/1sUv0rr7ySVB8R8b3vfS+p/pZbbkmqHzBgQFJ9qvvvvz95nV/84hdJ9dddd11S/XPPPZdUf8ABByTVH3TQQUn1EREnnXRSUv1nPvOZpPqampqk+i9/+ctJ9RERmzZtSl4HqHyp59DU3/u6Yt26dUn1Tz31VIk6ITeu5AIAAAAge0IuAAAAALIn5AIAAAAge0IuAAAAALIn5AIAAAAge0IuAAAAALIn5AIAAAAge0IuAAAAALIn5AIAAAAge0IuAAAAALIn5AIAAAAgezVFURTlbuKtWltbo76+vtxtVJzp06cnr3P77bcn1a9YsSKp/v3vf39S/YsvvphUD3TW0tISgwYNKncbvYJZ03uMGjUqqX7RokVJ9bvvvntS/YIFC5LqIyLGjx+fVD9s2LCk+nvuuSep/mtf+1pS/b333ptUz4656667kuqnTp2aVH/mmWcm1UdEXH311cnrpDJrNjNnyMlPfvKTpPoPf/jDSfXt7e1J9RERS5YsSap/z3vek7wN8rS9OeNKLgAAAACyJ+QCAAAAIHvJIdd9990X06dPj5EjR0ZNTc0WX2kriiKamppi5MiR0b9//5g8eXI88cQT3dUvABXOnAGglMwZgMqVHHKtW7cuxo8fH/Pnz9/q6/PmzYsrrrgi5s+fHw899FA0NDTElClTYu3ate+4WQAqnzkDQCmZMwCVqzZ1hWnTpsW0adO2+lpRFHHllVfGnDlzYsaMGRER8f3vfz+GDx8eN954Y5x++unvrFsAKp45A0ApmTMAlatb78m1dOnSWLlyZae/DlNXVxeHH354PPDAA1tdp62tLVpbWzstALA1XZkzEWYNADvGnAHIW7eGXCtXroyIiOHDh3d6fvjw4R2v/bW5c+dGfX19xzJ69OjubAmACtKVORNh1gCwY8wZgLyV5K8r1tTUdHpcFMUWz73h/PPPj5aWlo5l+fLlpWgJgAqSMmcizBoA0pgzAHlKvifX22loaIiIzZ+AjBgxouP5VatWbfFpyBvq6uqirq6uO9sAoEJ1Zc5EmDUA7BhzBiBv3Xol19ixY6OhoSEWLFjQ8dyGDRuiubk5Jk2a1J2bAqAKmTMAlJI5A5C35Cu5/vKXv8SSJUs6Hi9dujQeffTRGDx4cIwZMyZmzZoVl1xySey1116x1157xSWXXBLvete74uSTT+7WxgGoTOYMAKVkzgBUruSQ6+GHH44jjjii4/Hs2bMjImLmzJlx3XXXxRe+8IV47bXX4swzz4yXX345DjrooPjFL34RAwcO7L6uSbatP5PcnYYNG5ZU/7vf/a5Enbxp2bJlSfWXXHJJUv29996bVL9hw4akeqhG5ky++vfvn7zOZZddllS/++67J9XfcMMNSfWrV69Oqo+ImDJlSlL9sccem1R/1113JdW//vrrSfWUximnnJJU/9RTTyXVNzU1JdVHRFx99dXJ61Qic4ZKt+uuuybVDxgwoDSNvAMrVqwodwtkKjnkmjx5chRFsc3Xa2pqoqmpqUuDFwDMGQBKyZwBqFwl+euKAAAAANCThFwAAAAAZE/IBQAAAED2hFwAAAAAZE/IBQAAAED2hFwAAAAAZE/IBQAAAED2hFwAAAAAZE/IBQAAAED2hFwAAAAAZE/IBQAAAED2asvdAD1j5cqVJd9GbW3aP6cxY8aUqJOub+POO+9Mqn/ggQdK+vPnzp2bVA9QTocddljyOieeeGJS/UsvvZRUf+mllybVjx49Oqk+IuKzn/1sUv2TTz6ZVP/6668n1dM7rFmzJqk+9Ti/8MILSfVA9fjEJz6RVH/ooYeWqJOu+7d/+7dyt0CmXMkFAAAAQPaEXAAAAABkT8gFAAAAQPaEXAAAAABkT8gFAAAAQPaEXAAAAABkT8gFAAAAQPaEXAAAAABkT8gFAAAAQPaEXAAAAABkT8gFAAAAQPZqy90APWPevHnJ6xxzzDFJ9evWrUuq//3vf59U3xXTpk1Lqv/bv/3bpPpJkyaVtH7//fdPqo+IOPnkk5PqN27cmLwNgK35yEc+krxOS0tLUv2xxx6bVP+HP/whqX7x4sVJ9RERRx55ZFJ96j6Tp8svvzypfujQoUn1Z555ZlI9QLlcffXVyes8//zzJeiEauBKLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyV1vuBugZ69evT17nAx/4QAk66VmzZs1Kqj/ggAOS6u+6666k+t122y2p/oQTTkiqj4h4/PHHk+rHjRuXVL9p06akeiBfO+20U1J96jk0IuLFF19Mqv/Nb36TvI0UbW1tyessXLiw+xuh19lnn32S6mfOnJlUf8011yTV33777Un1QL4GDBiQVP+e97wnqb5Pn7RrX1Lrn3rqqaT6iIhXX301eR2IcCUXAAAAABVAyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGRPyAUAAABA9oRcAAAAAGSvttwNQG/y8MMPJ9V/4AMfSKr/xje+kVT/4Q9/OKk+ImLvvfdOqr/ggguS6puampLqgXwdddRRSfUHH3xw8ja+973vJa8D79Tf/d3fJa/T3NycVN+/f/+k+gULFiTVF0WRVA/k6+KLL06qP+2005Lq29vbk+pTOV/Rk1zJBQAAAED2hFwAAAAAZC855Lrvvvti+vTpMXLkyKipqYnbb7+90+unnnpq1NTUdFomTpzYXf0CUOHMGQBKyZwBqFzJIde6deti/PjxMX/+/G3WHH300fH88893LHfeeec7ahKA6mHOAFBK5gxA5Uq+8fy0adNi2rRpb1tTV1cXDQ0NXW4KgOplzgBQSuYMQOUqyT25Fi5cGMOGDYu99947TjvttFi1atU2a9va2qK1tbXTAgBvJ2XORJg1AKQxZwDy1O0h17Rp0+KGG26Ie+65Jy6//PJ46KGH4sgjj4y2trat1s+dOzfq6+s7ltGjR3d3SwBUkNQ5E2HWALDjzBmAfCV/XXF7TjrppI7/HjduXBxwwAHR2NgYP/vZz2LGjBlb1J9//vkxe/bsjsetra2GAgDblDpnIswaAHacOQOQr24Puf7aiBEjorGxMRYvXrzV1+vq6qKurq7UbQBQobY3ZyLMGgC6zpwByEdJ7sn1VmvWrInly5fHiBEjSr0pAKqQOQNAKZkzAPlIvpLrL3/5SyxZsqTj8dKlS+PRRx+NwYMHx+DBg6OpqSlOOOGEGDFiRDz77LPx5S9/OYYMGRLHH398tzYOQGUyZwAoJXMGoHIlh1wPP/xwHHHEER2P3/ju+cyZM+Oqq66Kxx9/PK6//vp45ZVXYsSIEXHEEUfETTfdFAMHDuy+rqGXeOaZZ5Lqjz322KT6efPmJdVHRJx77rlJ9WeffXZS/Q9+8IOk+rf+TyTsCHOm95gyZUpSfVEUydv4zW9+k7wOla9fv35J9fvvv39S/Zw5c5LqIyL5HPPe9743qf7ZZ59NqqfrzBnKaejQocnr9LaAdd26dUn1LS0tJeoEtpQcck2ePPlt/yf27rvvfkcNAVDdzBkASsmcAahcJb8nFwAAAACUmpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADIXm25G6Bn7LnnnsnrLFmypASdVLf29vak+osvvjh5Gx/5yEeS6vfee++k+pEjRybV+3cE+TrnnHOS6l955ZXkbfz6179OXof8DB8+PKn+mmuuSaqfPn16Uv19992XVB8R8eEPfzip/tlnn03eBlD55syZk7zOmDFjStBJ133+859Pqv/BD35Qok5gS67kAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7Qi4AAAAAsifkAgAAACB7teVugJ7x2GOPJa9z2GGHJdU//PDDydvg7a1duzZ5nW9+85tJ9fPnz0/eBsDWvPbaa8nrLFmypASdkKJv377J63zuc59Lqp88eXJS/VFHHZVUv3DhwqT6E088Mak+ImL16tXJ6wCV74ADDkiqnz59eok66Tnf+c53yt0CbJMruQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADInpALAAAAgOwJuQAAAADIXm25G6Bn7Lzzzsnr1Nb655GjDRs2lLsFoErttttuyetMmTIlqX7BggXJ28jdxIkTk+pT5/dFF12UVB8R8Q//8A9J9evXr0+qnz17dlL9DTfckFS/evXqpHqAbXnooYeS6tvb20vUCRDhSi4AAAAAKoCQCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyF5tuRugZ9TU1CSv079//xJ0Qoo99tgjeZ0vfOELJegEqEbPPPNMUv3YsWOTt/HVr341qb62Nv//dfn0pz+dVH/UUUcl1ffr1y+pvr29Pak+IuKWW25Jqr/00kuT6h955JGkeoByST2HduWcW2pXX311uVuAbuNKLgAAAACyJ+QCAAAAIHtJIdfcuXPjwAMPjIEDB8awYcPiuOOOi6eeeqpTTVEU0dTUFCNHjoz+/fvH5MmT44knnujWpgGoTOYMAKVm1gBUrqSQq7m5Oc4666x48MEHY8GCBbFx48aYOnVqrFu3rqNm3rx5ccUVV8T8+fPjoYceioaGhpgyZUqsXbu225sHoLKYMwCUmlkDULmS7t561113dXp87bXXxrBhw+KRRx6Jww47LIqiiCuvvDLmzJkTM2bMiIiI73//+zF8+PC48cYb4/TTT+++zgGoOOYMAKVm1gBUrnd0T66WlpaIiBg8eHBERCxdujRWrlwZU6dO7aipq6uLww8/PB544IGt/oy2trZobW3ttABARPfMmQizBoBt8zsNQOXocshVFEXMnj07DjnkkBg3blxERKxcuTIiIoYPH96pdvjw4R2v/bW5c+dGfX19xzJ69OiutgRABemuORNh1gCwdX6nAagsXQ65zj777Hjsscfihz/84Rav1dTUdHpcFMUWz73h/PPPj5aWlo5l+fLlXW0JgArSXXMmwqwBYOv8TgNQWZLuyfWGc845J+6444647777YtSoUR3PNzQ0RMTmTz9GjBjR8fyqVau2+CTkDXV1dVFXV9eVNgCoUN05ZyLMGgC25HcagMqTdCVXURRx9tlnx6233hr33HNPjB07ttPrY8eOjYaGhliwYEHHcxs2bIjm5uaYNGlS93QMQMUyZwAoNbMGoHIlXcl11llnxY033hg//vGPY+DAgR3fSa+vr4/+/ftHTU1NzJo1Ky655JLYa6+9Yq+99opLLrkk3vWud8XJJ59ckh0AoHKYMwCUmlkDULlqiqIodrh4G99Bv/baa+PUU0+NiM2fjFx88cXxne98J15++eU46KCD4lvf+lbHjRy3p7W1Nerr63e0JXZQV+4LsHHjxqT6+fPnJ9Vfe+21SfUvvfRSUn1X9OvXL6n+8MMPT6rfb7/9kurPOeecpPqIiMbGxqT6devWJdUfcsghSfWPPfZYUj2l09LSEoMGDSp3G2+rJ+ZMhFmzo1LPJ2+96mFH7bnnnsnrVJslS5Yk1S9atCip/mtf+1pSfYRzO9tm1mxmzlSPTZs2JdW3t7eXqJOuO+aYY5Lq77777hJ1Atu3vTmTdCXXjuRhNTU10dTUFE1NTSk/GgDMGQBKzqwBqFxd/uuKAAAAANBbCLkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDs1Za7AXrGlClTkte56667kurnzZuXVD9r1qyk+tdeey2pviv69EnLfceOHVuiTrpu48aNSfUnn3xyUv1jjz2WVA/k689//nNS/Qc/+MHkbaSeg4444oik+v79+yfVP/fcc0n1XZF6Hr3xxhuT6l988cWkegCASuFKLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyJ+QCAAAAIHtCLgAAAACyV1MURVHuJt6qtbU16uvry90GEbHHHnsk1Z933nlJ9UcccURS/d57751U3xs9+uijSfXLli1L3sall16aVP/ggw8mb4M8tbS0xKBBg8rdRq9g1uSrX79+SfV9+qR9ntfW1pZUD3Rm1mxmzlSPTZs2JdW3t7eXqJM33XHHHUn1p59+elL96tWrk+qhO21vzriSCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDs1Za7AXqvp59+Oqn+zDPPTKrfddddk+rHjBmTVN8b/b//9/+S6tevX1+iTgDy9Prrr5e7BQDo0Ldv33K3ALyFK7kAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyJ6QCwAAAIDsCbkAAAAAyF5tuRuger3yyislrQcAAACqhyu5AAAAAMiekAsAAACA7CWFXHPnzo0DDzwwBg4cGMOGDYvjjjsunnrqqU41p556atTU1HRaJk6c2K1NA1CZzBkASs2sAahcSSFXc3NznHXWWfHggw/GggULYuPGjTF16tRYt25dp7qjjz46nn/++Y7lzjvv7NamAahM5gwApWbWAFSupBvP33XXXZ0eX3vttTFs2LB45JFH4rDDDut4vq6uLhoaGrqnQwCqhjkDQKmZNQCV6x3dk6ulpSUiIgYPHtzp+YULF8awYcNi7733jtNOOy1WrVq1zZ/R1tYWra2tnRYAiOieORNh1gCwbX6nAagcNUVRFF1ZsSiKOPbYY+Pll1+O+++/v+P5m266KXbZZZdobGyMpUuXxgUXXBAbN26MRx55JOrq6rb4OU1NTXHxxRd3fQ8A2CEtLS0xaNCgcrexw7przkSYNQA9pVpnjTkD0DO2O2eKLjrzzDOLxsbGYvny5W9bt2LFiqJfv37F//zP/2z19fXr1xctLS0dy/Lly4uIsFgsFks3Ly0tLV095ZdFd82ZojBrLBaLpaeWap015ozFYrH0zLK9OZN0T643nHPOOXHHHXfEfffdF6NGjXrb2hEjRkRjY2MsXrx4q6/X1dVt85N3AKpTd86ZCLMGgC35nQag8iSFXEVRxDnnnBO33XZbLFy4MMaOHbvdddasWRPLly+PESNGdLlJAKqDOQNAqZk1AJUr6cbzZ511VvzgBz+IG2+8MQYOHBgrV66MlStXxmuvvRYREX/5y1/ic5/7XPzv//5vPPvss7Fw4cKYPn16DBkyJI4//viS7AAAlcOcAaDUzBqACpbynfXYxncir7322qIoiuLVV18tpk6dWgwdOrTo169fMWbMmGLmzJnFsmXLdngbLS0tZf+Op8VisVTiksN9UrbVe3fOmaIwaywWi6VUi1mzmTljsVgspVm2N2e6/NcVS6W1tTXq6+vL3QZAxcntL16VklkDUBpmzWbmDEBpbG/OJH1dEQAAAAB6IyEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANkTcgEAAACQPSEXAAAAANnrdSFXURTlbgGgIjm/vsl7AVAazq+beR8ASmN759deF3KtXbu23C0AVCTn1zd5LwBKw/l1M+8DQGls7/xaU/Syjxna29tjxYoVMXDgwKipqen0Wmtra4wePTqWL18egwYNKlOHPcs+2+dKZZ97bp+Looi1a9fGyJEjo0+fXvfZRllsa9b4d2mfK5V9ts+lZtZ0Zs68yT7b50pln3vnnKntwZ52SJ8+fWLUqFFvWzNo0KCq+Uf0BvtcHexzdSjHPtfX1/fo9nq77c0a/y6rg32uDva555g1bzJntmSfq4N9rg69ec74mAUAAACA7Am5AAAAAMheViFXXV1dXHTRRVFXV1fuVnqMfa4O9rk6VOM+56Yaj5F9rg72uTpU4z7nphqPkX2uDva5OuSwz73uxvMAAAAAkCqrK7kAAAAAYGuEXAAAAABkT8gFAAAAQPaEXAAAAABkT8gFAAAAQPayCbm+/e1vx9ixY2PnnXeOCRMmxP3331/ulkqmqakpampqOi0NDQ3lbqtb3XfffTF9+vQYOXJk1NTUxO23397p9aIooqmpKUaOHBn9+/ePyZMnxxNPPFGeZrvJ9vb51FNP3eK4T5w4sTzNdpO5c+fGgQceGAMHDoxhw4bFcccdF0899VSnmko71juyz5V4rCtBNc2ZCLMmovLOPxHVN2vMGXMmN9U0a8yZyjv/RFTfnIkwa3KbNVmEXDfddFPMmjUr5syZE4sWLYpDDz00pk2bFsuWLSt3ayWz7777xvPPP9+xPP744+VuqVutW7cuxo8fH/Pnz9/q6/PmzYsrrrgi5s+fHw899FA0NDTElClTYu3atT3caffZ3j5HRBx99NGdjvudd97Zgx12v+bm5jjrrLPiwQcfjAULFsTGjRtj6tSpsW7duo6aSjvWO7LPEZV3rHNXjXMmwqyptPNPRPXNGnPGnMlJNc4ac6ayzj8R1TdnIsya7GZNkYEPfOADxRlnnNHpuX322af40pe+VKaOSuuiiy4qxo8fX+42ekxEFLfddlvH4/b29qKhoaH4+te/3vHc+vXri/r6+uLqq68uQ4fd76/3uSiKYubMmcWxxx5bln56yqpVq4qIKJqbm4uiqI5j/df7XBTVcaxzU21zpijMmmo4/1TjrDFnNqv045yraps15kzln3+qcc4UhVnzht56rHv9lVwbNmyIRx55JKZOndrp+alTp8YDDzxQpq5Kb/HixTFy5MgYO3ZsfOxjH4tnnnmm3C31mKVLl8bKlSs7HfO6uro4/PDDK/qYR0QsXLgwhg0bFnvvvXecdtppsWrVqnK31K1aWloiImLw4MERUR3H+q/3+Q2VfqxzUq1zJsKsqfTzz7ZU8vnHnHlTJR/nHFXrrDFnKvv8sy2Vfv4xa97UG491rw+5Vq9eHZs2bYrhw4d3en748OGxcuXKMnVVWgcddFBcf/31cffdd8d3v/vdWLlyZUyaNCnWrFlT7tZ6xBvHtZqOeUTEtGnT4oYbboh77rknLr/88njooYfiyCOPjLa2tnK31i2KoojZs2fHIYccEuPGjYuIyj/WW9vniMo/1rmpxjkTYdZU+vlnWyr5/GPOmDO9WTXOGnOmss8/21Lp5x+zpvfPmtqybj1BTU1Np8dFUWzxXKWYNm1ax3/vt99+cfDBB8cee+wR3//+92P27Nll7KxnVdMxj4g46aSTOv573LhxccABB0RjY2P87Gc/ixkzZpSxs+5x9tlnx2OPPRa//vWvt3itUo/1tva50o91rir13+G2mDWbVdtxr+Tzjznzpko+zrmr1H+LW2PObFZNxzyi8s8/Zs2beuux7vVXcg0ZMiT69u27RQK6atWqLZLSSjVgwIDYb7/9YvHixeVupUe88VdXqvmYR0SMGDEiGhsbK+K4n3POOXHHHXfEvffeG6NGjep4vpKP9bb2eWsq6VjnyJzZzKzZrNqOe6Wcf8wZc6a3M2vMmTdU0zGPqKzzj1mTx6zp9SHXTjvtFBMmTIgFCxZ0en7BggUxadKkMnXVs9ra2uLJJ5+MESNGlLuVHjF27NhoaGjodMw3bNgQzc3NVXPMIyLWrFkTy5cvz/q4F0URZ599dtx6661xzz33xNixYzu9XonHenv7vDWVcKxzZs5sZtbkf/7pitzPP+aMOZMLs8acicj//NMVlXD+MWsymzU9epv7LvrRj35U9OvXr/jP//zP4o9//GMxa9asYsCAAcWzzz5b7tZK4rzzzisWLlxYPPPMM8WDDz5YHHPMMcXAgQMran/Xrl1bLFq0qFi0aFEREcUVV1xRLFq0qPjzn/9cFEVRfP3rXy/q6+uLW2+9tXj88ceLj3/848WIESOK1tbWMnfedW+3z2vXri3OO++84oEHHiiWLl1a3HvvvcXBBx9cvPvd7856nz/96U8X9fX1xcKFC4vnn3++Y3n11Vc7airtWG9vnyv1WOeu2uZMUZg1RVF555+iqL5ZY86YMzmptlljzlTe+acoqm/OFIVZk9usySLkKoqi+Na3vlU0NjYWO+20U/H+97+/05+urDQnnXRSMWLEiKJfv37FyJEjixkzZhRPPPFEudvqVvfee28REVssM2fOLIpi859hveiii4qGhoairq6uOOyww4rHH3+8vE2/Q2+3z6+++moxderUYujQoUW/fv2KMWPGFDNnziyWLVtW7rbfka3tb0QU1157bUdNpR3r7e1zpR7rSlBNc6YozJqiqLzzT1FU36wxZ8yZ3FTTrDFnKu/8UxTVN2eKwqzJbdbUFEVRdP06MAAAAAAov15/Ty4AAAAA2B4hFwAAAADZE3IBAAAAkD0hFwAAAADZE3IBAAAAkD0hFwAAAADZE3IBAAAAkD0hFwAAAADZE3IBAAAAkD0hFwAAAADZE3IBAAAAkL3/D0mb2hF/NYRrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the first 3 images:\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(3):\n",
    "    ax = fig.add_subplot(1,3,i+1)\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(\"label: \"+str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6ffd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image section:\n",
      " [[ 21   0   0   0   0   0   0   0   0   0]\n",
      " [223 223 193  71   6   0   0   0   0   0]\n",
      " [253 253 253 253 196 121   0   0   0   0]\n",
      " [144 144 217 251 253 253 170   4   0   0]\n",
      " [  0   0   0  53 236 253 253 215   3   0]\n",
      " [  0   0   0   0  34 180 253 253 128   0]\n",
      " [  0   0   0   0   0   2 140 253 236  36]\n",
      " [  0   0   0   0   0   0  13 215 253  62]\n",
      " [  0   0   0   0   0   0   0 105 253  62]\n",
      " [  0   0   0   0   0   0   0  99 253  62]] \n",
      "\n",
      "pixel maximum value: 255\n",
      "pixel minimum value: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "section = X_train[0][10:20,10:20]\n",
    "print(\"image section:\\n\",section,\"\\n\")\n",
    "print(\"pixel maximum value:\", np.max(X_train[0]))\n",
    "print(\"pixel minimum value:\", np.min(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e9afc",
   "metadata": {},
   "source": [
    "# 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2fdeab",
   "metadata": {},
   "source": [
    "## Normalize images:\n",
    "\n",
    "*\"When using the image as it is and passing through a Deep Neural Network, the computation of high numeric values may become more complex.\n",
    "To reduce this we can normalize the values to range from 0 to 1. In this way, the numbers will be small and the computation becomes easier and faster.\"* **Asha Ponraj.(Feb19,2021), [A Tip A Day â€” Python Tip #8](https://medium.com/analytics-vidhya/a-tip-a-day-python-tip-8-why-should-we-normalize-image-pixel-values-or-divide-by-255-4608ac5cd26a#:~:text=When%20using%20the%20image%20as,computation%20becomes%20easier%20and%20faster.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcec08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_validation = X_validation/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52812b",
   "metadata": {},
   "source": [
    "## Encode the labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f384fca",
   "metadata": {},
   "source": [
    "The dataset labels are categorical variables (digits from 0 through 9). We need to encode these values before feeding them to a neural network. Since there are very few categories we can use `one-hot` encoding.\n",
    "\n",
    "To represent a given label, `one-hot` encoding creates a vector of length equal to the total number of categories (in this case 10), Then, in order to represent a given label, the corresponding element of the encoding vector is set to 1, and all other elements to 0 (for example [0 0 0 0 0 1 0 0 0 0] is iqual to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3031be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer representation of first 5 labels:\n",
      " [5 0 1 6 1]\n",
      "one-hot representation of first 5 labels:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "print (\"integer representation of first 5 labels:\\n\",y_train[0:5])\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_validation = to_categorical(y_validation,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "print(\"one-hot representation of first 5 labels:\\n\",y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d825fd",
   "metadata": {},
   "source": [
    "# 5. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c37ff",
   "metadata": {},
   "source": [
    "## Requeriments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fbc86",
   "metadata": {},
   "source": [
    "`scikeras` makes it possible to use `keras` with `scikit learn`. In this particular case, I'm going to use `GridSearchCV` from `scikit learn` for model tuning and return the hyperparameters that adjust the most to the neural network model.\n",
    "\n",
    "if you already have Keras and TensorFlow, install `scikeras` with no dependencies:\n",
    "\n",
    "```bash\n",
    "pip install --no-deps scikeras\n",
    "```\n",
    "\n",
    "Documentation available at: https://adriangb.com/scikeras/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cafd31",
   "metadata": {},
   "source": [
    "## Reproducibility:\n",
    "\n",
    "In a reproducible model, the weights of the model should be initialized with same values in subsequent runs, for experimentation purposes or to debug a problem.\n",
    "\n",
    "More about reproducibility in keras:\n",
    "\n",
    "- [Reproducibility in Keras Models](https://keras.io/examples/keras_recipes/reproducibility_recipes/)\n",
    "\n",
    "- [Layer weight initializers](https://keras.io/api/layers/initializers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6eec4",
   "metadata": {},
   "source": [
    "## Design: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064dd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use CPU/GPU in training process\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Neural network \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# Optimizers\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# Grid Search\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Prevent overfitting in training process for epochs > 2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the best weights in a checkpoint file \n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98519427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# to control randomness\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "# control randomness, used with RELU activation function\n",
    "he = keras.initializers.he_normal(seed=42)\n",
    "\n",
    "# control randomness, used with softmax activation function\n",
    "glorot = keras.initializers.glorot_normal(seed=42)\n",
    "\n",
    "# control randomness, used with bias \n",
    "zeros = keras.initializers.zeros()\n",
    "ones = keras.initializers.ones()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d30477",
   "metadata": {},
   "source": [
    "Every pixel in an image will be treated as the input of the Multilayer perceptron (MLP) model; the output or the prediction is encoded with one-hot algorithm and return a single array of lenght 10, where the position with the highest value represent the predicted digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138dc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(unitsHL1, unitsHL2, \n",
    "          dropoutHL1, dropoutHL2, \n",
    "          optimizer_learning_rate, \n",
    "          optimizer_momentum,\n",
    "          optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    # flattern convert image into an array\n",
    "    model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "    # hidden layer 1\n",
    "    model.add(Dense(unitsHL1, \n",
    "                    activation='relu', \n",
    "                    kernel_initializer=he,\n",
    "                    bias_initializer=ones,\n",
    "                   ))\n",
    "    # regularization\n",
    "    if dropoutHL1 > 0:\n",
    "        model.add(Dropout(dropoutHL1))\n",
    "    # hidden layer 2\n",
    "    model.add(Dense(unitsHL2, \n",
    "                    activation='relu', \n",
    "                    kernel_initializer=he,\n",
    "                    bias_initializer=ones,\n",
    "                    ))\n",
    "    # regularization\n",
    "    if dropoutHL2 > 0:\n",
    "        model.add(Dropout(dropoutHL2))\n",
    "    # output layer\n",
    "    model.add(Dense(10, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer=glorot,\n",
    "                    bias_initializer=ones,\n",
    "                   ))\n",
    "    # optimizer\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(\n",
    "            learning_rate=optimizer_learning_rate\n",
    "        )\n",
    "    elif optimizer == 'SGD':\n",
    "        opt = SGD(\n",
    "            learning_rate=optimizer_learning_rate,\n",
    "            momentum=optimizer_momentum,\n",
    "        )\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(\n",
    "            learning_rate=optimizer_learning_rate, \n",
    "            momentum=optimizer_momentum,\n",
    "        )\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer = opt,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914792b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_results(models,epochs,batch_size,X,Y,X_val,Y_val,callbacks,verbose=0): \n",
    "    '''\n",
    "    Save the history,epochs,loss and accuracy of a trained model into a dictionary\n",
    "    Input: \n",
    "        - models(array):\n",
    "        - epochs(array): array integer or single integer\n",
    "        - batch_size(array): array integer or single integer\n",
    "        - earlystopping(None): callback,\n",
    "        - X,Y,X_val,Y_val(array): train and validation set\n",
    "        - verbose (int) : 0,1 or 2 show training process details.\n",
    "    Output:\n",
    "        - results(dic):\n",
    "    '''\n",
    "    results = {}\n",
    "    for index,model in enumerate(models):\n",
    "        results[model.name] = {}\n",
    "        # check for single epoch or epoch list\n",
    "        if isinstance(epochs,(int,float)):\n",
    "            n_epochs = epochs\n",
    "        elif isinstance(epochs,list):\n",
    "            n_epochs = epochs[index]\n",
    "        elif len(epochs) != len(models):\n",
    "            print(f\"epoch missing value, {len(epochs)} values was given but need {len(models)}\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"epoch value error\")\n",
    "            break\n",
    "        # check for single batch size or batch size list\n",
    "        if isinstance(batch_size,(int,float)):\n",
    "            n_batch_size = batch_size\n",
    "        elif isinstance(batch_size,list):\n",
    "            n_batch_size = batch_size[index]\n",
    "            \n",
    "        elif len(batch_size) != len(models):\n",
    "            print(f\"batch size missing value,{len(batch_size)} values was given but need {len(models)}\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"batch size value error\")\n",
    "            break\n",
    "        # model fit with train and validation set\n",
    "        results[model.name]['hist'] = model.fit(\n",
    "            x = X,\n",
    "            y = Y,\n",
    "            batch_size = n_batch_size,\n",
    "            epochs = n_epochs,\n",
    "            verbose = verbose,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(X_val,Y_val),\n",
    "            shuffle=True,\n",
    "        )\n",
    "        history = results[model.name]['hist']\n",
    "        # stopped epochs\n",
    "        if (callbacks and earlystopping.stopped_epoch > 0 ):\n",
    "            stopepoch = earlystopping.stopped_epoch\n",
    "            results[model.name]['stop epochs'] = stopepoch\n",
    "            # validation loss and accuracy at stopped epoch\n",
    "            results[model.name]['val_loss'] = history.history['val_loss'][stopepoch]\n",
    "            results[model.name]['val_accuracy'] = history.history['val_accuracy'][stopepoch]\n",
    "        else:\n",
    "            results[model.name]['stop epochs'] = n_epochs\n",
    "            # model calculate with all the epochs\n",
    "            results[model.name]['val_loss'] = history.history['val_loss'][n_epochs-1]\n",
    "            results[model.name]['val_accuracy'] = history.history['val_accuracy'][n_epochs-1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af152409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_results(results):\n",
    "    '''\n",
    "    input: \n",
    "        - results(dic) : model training results saved in a dictionary\n",
    "                        {'model':{'key1':'result1','key2':'result2'...}}\n",
    "    output\n",
    "        - plot: loss(left plot), accuracy(right plot)\n",
    "    '''\n",
    "    n_plots = len(list(results.keys()))\n",
    "    if n_plots == 1:\n",
    "        fig,axes = plt.subplots(n_plots,2,figsize=(13,5))\n",
    "        # Convert to 2D array\n",
    "        axes = axes.reshape(1, -1)\n",
    "    else:\n",
    "        fig,axes = plt.subplots(n_plots,2,figsize=(13,13))\n",
    "    for index,model in enumerate(list(results.keys())):\n",
    "        history = results[model]['hist']\n",
    "        # loss\n",
    "        axes[index,0].plot(history.history['val_loss'])\n",
    "        axes[index,0].plot(history.history['loss'])\n",
    "        axes[index,0].set_title(model + ' loss')\n",
    "        axes[index,0].set_xlabel('Epoch')\n",
    "        axes[index,0].set_ylabel('Loss')\n",
    "        axes[index,0].legend(['val_loss','loss'], loc='upper left')\n",
    "        # accuracy\n",
    "        axes[index,1].plot(history.history['val_accuracy'])\n",
    "        axes[index,1].plot(history.history['accuracy'])\n",
    "        axes[index,1].set_title(model + ' accuracy')\n",
    "        axes[index,1].set_xlabel('Epoch')\n",
    "        axes[index,1].set_ylabel('Accuracy')\n",
    "        axes[index,1].legend(['val_accuracy','accuracy'], loc='upper left')\n",
    "    plt.tight_layout()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe7472",
   "metadata": {},
   "source": [
    "## Grid search tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd19b7e",
   "metadata": {},
   "source": [
    "The code below was executed several times until found parameters that returned a good performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335bc6d",
   "metadata": {},
   "source": [
    "### Grid search : Layers and Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c22211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# patience: number of epochs with no improvement before stopping\n",
    "# min: training will stop when the quantity monitored has stopped decreasing\n",
    "# monitor: \"val_loss\" measure loss on validation set \n",
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "adam_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=550,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0,\n",
    "    optimizer='Adam',\n",
    "    callbacks= earlystopping,\n",
    "    epochs=20,\n",
    ")\n",
    "adam_param_grid = {\n",
    "    'unitsHL1':[550,750],\n",
    "    'unitsHL2':[200,400],\n",
    "    'optimizer_learning_rate':[0.001,0.01],\n",
    "}\n",
    "adam_grid = GridSearchCV(estimator=adam_estimator, param_grid=adam_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84f6cfcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.1494 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.1205 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9697\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.1520 - val_accuracy: 0.9541\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1188 - accuracy: 0.9630 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.1138 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1017 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "1177/1200 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9944Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2997 - accuracy: 0.9103 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9523\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.1244 - val_accuracy: 0.9603\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1145 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1437 - val_accuracy: 0.9738\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2963 - accuracy: 0.9102 - val_loss: 0.1595 - val_accuracy: 0.9517\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1303 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 0.1479 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0916 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1021 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9934Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9764\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.1613 - val_accuracy: 0.9492\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 0.1182 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9909Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1096 - val_accuracy: 0.9725\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.1509 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1098 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1305 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1178/1200 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1180 - val_accuracy: 0.9720\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.1517 - val_accuracy: 0.9525\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1204 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.1194 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1397 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3027 - accuracy: 0.9105 - val_loss: 0.1473 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1224 - accuracy: 0.9617 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.1136 - val_accuracy: 0.9668\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1070 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1131 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1354 - val_accuracy: 0.9724\n",
      "Epoch 11/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9934Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1122 - val_accuracy: 0.9766\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.1524 - val_accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0997 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1104 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1314 - val_accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9771\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3131 - accuracy: 0.9086 - val_loss: 0.1432 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 7/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2961 - accuracy: 0.9114 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1035 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9929Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2924 - accuracy: 0.9121 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1155 - val_accuracy: 0.9651\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1138 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.1225 - val_accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1184 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.1291 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9955Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3000 - accuracy: 0.9096 - val_loss: 0.1486 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0909 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0969 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0956 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0921 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1002 - val_accuracy: 0.9791\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2973 - accuracy: 0.9094 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1608 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.1076 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3039 - accuracy: 0.9093 - val_loss: 0.1404 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1659 - val_accuracy: 0.9469\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0917 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.1032 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0950 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.1257 - val_accuracy: 0.9727\n",
      "Epoch 10/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9923Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9768\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3144 - accuracy: 0.9101 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9640 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.0960 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9897Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3038 - accuracy: 0.9106 - val_loss: 0.1541 - val_accuracy: 0.9531\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1163 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.1177 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3111 - accuracy: 0.9091 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.1410 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.1010 - val_accuracy: 0.9741\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0959 - val_accuracy: 0.9766\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1227 - val_accuracy: 0.9774\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3062 - accuracy: 0.9113 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.1263 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9713\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.1095 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0986 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1414 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1320 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1268 - val_accuracy: 0.9775\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3143 - accuracy: 0.9104 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1636 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.1255 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1017 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9923Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1203 - val_accuracy: 0.9727\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3937 - accuracy: 0.9070 - val_loss: 0.2177 - val_accuracy: 0.9355\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9512 - val_loss: 0.2066 - val_accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 0.1988 - val_accuracy: 0.9488\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9617 - val_loss: 0.2710 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2032 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.1894 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1168 - accuracy: 0.9695 - val_loss: 0.4487 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.2050 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9741Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.1925 - val_accuracy: 0.9617\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3933 - accuracy: 0.9054 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2034 - accuracy: 0.9422 - val_loss: 0.2575 - val_accuracy: 0.9344\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1845 - accuracy: 0.9493 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.2109 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "1177/1200 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9592Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1524 - accuracy: 0.9592 - val_loss: 0.2775 - val_accuracy: 0.9477\n",
      "Epoch 5: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3991 - accuracy: 0.9028 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9430 - val_loss: 0.2267 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.1943 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9567 - val_loss: 0.2158 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1561 - accuracy: 0.9580 - val_loss: 0.2284 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1522 - accuracy: 0.9613 - val_loss: 0.2077 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1833 - val_accuracy: 0.9569\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9671 - val_loss: 0.1686 - val_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.2496 - val_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.9679 - val_loss: 0.2077 - val_accuracy: 0.9553\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1187 - accuracy: 0.9717 - val_loss: 0.2272 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9732Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1094 - accuracy: 0.9732 - val_loss: 0.2458 - val_accuracy: 0.9555\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3627 - accuracy: 0.9090 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.2003 - val_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.2473 - val_accuracy: 0.9363\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.2016 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9617Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.9616 - val_loss: 0.2125 - val_accuracy: 0.9528\n",
      "Epoch 5: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.9054 - val_loss: 0.1936 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1729 - accuracy: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9514\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1625 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9627 - val_loss: 0.1859 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1412 - accuracy: 0.9639 - val_loss: 0.1605 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1238 - accuracy: 0.9676 - val_loss: 0.2128 - val_accuracy: 0.9533\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9606\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1952 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9725Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.9726 - val_loss: 0.1688 - val_accuracy: 0.9663\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4289 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2069 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.2249 - val_accuracy: 0.9409\n",
      "Epoch 5/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9552Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.2078 - val_accuracy: 0.9500\n",
      "Epoch 5: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4448 - accuracy: 0.8983 - val_loss: 0.2164 - val_accuracy: 0.9410\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2049 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1989 - accuracy: 0.9454 - val_loss: 0.2326 - val_accuracy: 0.9461\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1739 - accuracy: 0.9532 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1617 - accuracy: 0.9568 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1586 - accuracy: 0.9591 - val_loss: 0.1986 - val_accuracy: 0.9550\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1507 - accuracy: 0.9615 - val_loss: 0.2034 - val_accuracy: 0.9502\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9635Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9635 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4384 - accuracy: 0.8970 - val_loss: 0.2229 - val_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2203 - accuracy: 0.9386 - val_loss: 0.2267 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2015 - accuracy: 0.9461 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9492 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1711 - accuracy: 0.9539 - val_loss: 0.2259 - val_accuracy: 0.9470\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 0.2283 - val_accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.2462 - val_accuracy: 0.9493\n",
      "Epoch 8/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9604Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 0.2542 - val_accuracy: 0.9519\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4598 - accuracy: 0.8938 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2194 - accuracy: 0.9393 - val_loss: 0.2887 - val_accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.2388 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9495 - val_loss: 0.2109 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1666 - accuracy: 0.9544 - val_loss: 0.2328 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1585 - accuracy: 0.9580 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2425 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9618Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9618 - val_loss: 0.2390 - val_accuracy: 0.9465\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8960 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2221 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2056 - accuracy: 0.9445 - val_loss: 0.2407 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1894 - accuracy: 0.9482 - val_loss: 0.2061 - val_accuracy: 0.9486\n",
      "Epoch 5/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9548Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1672 - accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.9424\n",
      "Epoch 5: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3890 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2065 - accuracy: 0.9428 - val_loss: 0.2160 - val_accuracy: 0.9434\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9490 - val_loss: 0.2030 - val_accuracy: 0.9491\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1631 - accuracy: 0.9560 - val_loss: 0.2051 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1496 - accuracy: 0.9608 - val_loss: 0.2316 - val_accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.2238 - val_accuracy: 0.9525\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9632 - val_loss: 0.1964 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.2163 - val_accuracy: 0.9602\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1251 - accuracy: 0.9695 - val_loss: 0.2522 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9732Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1057 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9582\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3759 - accuracy: 0.9077 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2073 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9456\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1678 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9632 - val_loss: 0.2180 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9644 - val_loss: 0.2449 - val_accuracy: 0.9484\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9684Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1274 - accuracy: 0.9684 - val_loss: 0.2191 - val_accuracy: 0.9577\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3781 - accuracy: 0.9100 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9337\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1694 - accuracy: 0.9539 - val_loss: 0.1895 - val_accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1582 - accuracy: 0.9572 - val_loss: 0.2150 - val_accuracy: 0.9485\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.2038 - val_accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9649 - val_loss: 0.1998 - val_accuracy: 0.9561\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1304 - accuracy: 0.9660 - val_loss: 0.1811 - val_accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1851 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9693 - val_loss: 0.2541 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1102 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.1771 - val_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1854 - val_accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1979 - val_accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9759Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.2191 - val_accuracy: 0.9594\n",
      "Epoch 15: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3951 - accuracy: 0.9054 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9386\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1544 - accuracy: 0.9592 - val_loss: 0.1821 - val_accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1391 - accuracy: 0.9630 - val_loss: 0.1648 - val_accuracy: 0.9588\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9648 - val_loss: 0.1903 - val_accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.2147 - val_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9696Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9693 - val_loss: 0.2290 - val_accuracy: 0.9529\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3963 - accuracy: 0.9036 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9472 - val_loss: 0.2252 - val_accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.1891 - val_accuracy: 0.9527\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9616Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1454 - accuracy: 0.9615 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
      "Epoch 5: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.8877 - val_loss: 0.2266 - val_accuracy: 0.9364\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2322 - accuracy: 0.9352 - val_loss: 0.2302 - val_accuracy: 0.9394\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1800 - accuracy: 0.9525 - val_loss: 0.2147 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9574 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1416 - accuracy: 0.9637 - val_loss: 0.2670 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9627Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1444 - accuracy: 0.9627 - val_loss: 0.2326 - val_accuracy: 0.9486\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4861 - accuracy: 0.8921 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 0.2093 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1900 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9466\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1774 - accuracy: 0.9521 - val_loss: 0.2082 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.1971 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1648 - accuracy: 0.9578 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.2186 - val_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 0.2569 - val_accuracy: 0.9448\n",
      "Epoch 10/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1419 - accuracy: 0.9646Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9646 - val_loss: 0.2178 - val_accuracy: 0.9484\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.4744 - accuracy: 0.8952 - val_loss: 0.2387 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2240 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9379\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1931 - accuracy: 0.9472 - val_loss: 0.1842 - val_accuracy: 0.9498\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.2538 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1742 - accuracy: 0.9529 - val_loss: 0.2317 - val_accuracy: 0.9517\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.2327 - val_accuracy: 0.9496\n",
      "Epoch 7/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9601Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 0.2381 - val_accuracy: 0.9510\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5268 - accuracy: 0.8886 - val_loss: 0.2405 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.9300 - val_loss: 0.2778 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 0.2480 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2050 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1831 - accuracy: 0.9492 - val_loss: 0.2605 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9519 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9540 - val_loss: 0.2105 - val_accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.9528Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.2721 - val_accuracy: 0.9365\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4795 - accuracy: 0.8931 - val_loss: 0.2500 - val_accuracy: 0.9263\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2228 - accuracy: 0.9368 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9417\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.2290 - val_accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.2428 - val_accuracy: 0.9458\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1570 - accuracy: 0.9580 - val_loss: 0.2083 - val_accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.2158 - val_accuracy: 0.9545\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9654Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1295 - accuracy: 0.9654 - val_loss: 0.2430 - val_accuracy: 0.9488\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2656 - accuracy: 0.9194 - val_loss: 0.1549 - val_accuracy: 0.9537\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1071 - accuracy: 0.9664 - val_loss: 0.0971 - val_accuracy: 0.9708\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0701 - accuracy: 0.9771 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0786 - val_accuracy: 0.9770\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.1006 - val_accuracy: 0.9738\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.1074 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0852 - val_accuracy: 0.9794\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9918Restoring model weights from the end of the best epoch: 4.\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1116 - val_accuracy: 0.9768\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    adam_grid_result = adam_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dab35ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.974958 using {'optimizer_learning_rate': 0.001, 'unitsHL1': 750, 'unitsHL2': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (adam_grid_result.best_score_, adam_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab54a8",
   "metadata": {},
   "source": [
    "### Grid search : Layers and RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1720426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.1494 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.1205 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9697\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9939Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1133 - val_accuracy: 0.9758\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.1520 - val_accuracy: 0.9541\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1188 - accuracy: 0.9630 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.1138 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1017 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.1229 - val_accuracy: 0.9744\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.2997 - accuracy: 0.9103 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9523\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.1244 - val_accuracy: 0.9603\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1145 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1437 - val_accuracy: 0.9738\n",
      "Epoch 13/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9953Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.1200 - val_accuracy: 0.9771\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.2963 - accuracy: 0.9102 - val_loss: 0.1595 - val_accuracy: 0.9517\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1303 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 0.1479 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0916 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1021 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.1142 - val_accuracy: 0.9771\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.1613 - val_accuracy: 0.9492\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 0.1182 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1096 - val_accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9911Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.1099 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.1509 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1098 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1305 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1180 - val_accuracy: 0.9720\n",
      "Epoch 9/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.1198 - val_accuracy: 0.9721\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.1517 - val_accuracy: 0.9525\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1204 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.1194 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1397 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "Epoch 11/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9932Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1320 - val_accuracy: 0.9737\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3027 - accuracy: 0.9105 - val_loss: 0.1473 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.1224 - accuracy: 0.9617 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.1136 - val_accuracy: 0.9668\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1070 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1131 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1354 - val_accuracy: 0.9724\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1122 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.1265 - val_accuracy: 0.9772\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.1524 - val_accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0997 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1104 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1314 - val_accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9942Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9795\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3131 - accuracy: 0.9086 - val_loss: 0.1432 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.1018 - val_accuracy: 0.9756\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.2961 - accuracy: 0.9114 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1035 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1241 - val_accuracy: 0.9735\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.2924 - accuracy: 0.9121 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1155 - val_accuracy: 0.9651\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1138 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.1225 - val_accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1184 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.1291 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.1330 - val_accuracy: 0.9759\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3000 - accuracy: 0.9096 - val_loss: 0.1486 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0909 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0969 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0956 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0921 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1002 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1092 - val_accuracy: 0.9762\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.2973 - accuracy: 0.9094 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1608 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.1076 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0988 - val_accuracy: 0.9773\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 4ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 48121s 40s/step - loss: 0.3039 - accuracy: 0.9093 - val_loss: 0.1404 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1659 - val_accuracy: 0.9469\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0917 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.1032 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0950 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.1257 - val_accuracy: 0.9727\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9768\n",
      "Epoch 11/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9952Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1474 - val_accuracy: 0.9718\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3144 - accuracy: 0.9101 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9640 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.0960 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
      "Epoch 8/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1035 - val_accuracy: 0.9763\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3038 - accuracy: 0.9106 - val_loss: 0.1541 - val_accuracy: 0.9531\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1163 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.1177 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 10/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.1422 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3111 - accuracy: 0.9091 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.1410 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.1010 - val_accuracy: 0.9741\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0959 - val_accuracy: 0.9766\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1227 - val_accuracy: 0.9774\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 12/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9956Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1370 - val_accuracy: 0.9766\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3062 - accuracy: 0.9113 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.1263 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9713\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.1095 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0986 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1414 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1320 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1268 - val_accuracy: 0.9775\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9954Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1228 - val_accuracy: 0.9783\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3143 - accuracy: 0.9104 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1636 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.1255 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1017 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1203 - val_accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.1180 - val_accuracy: 0.9747\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2962 - accuracy: 0.9117 - val_loss: 0.1435 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1174 - accuracy: 0.9636 - val_loss: 0.1250 - val_accuracy: 0.9631\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.1271 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1082 - val_accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1149 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0977 - val_accuracy: 0.9797\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1208 - val_accuracy: 0.9747\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2986 - accuracy: 0.9112 - val_loss: 0.1517 - val_accuracy: 0.9549\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.1092 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0967 - val_accuracy: 0.9754\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.1039 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.1173 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1013 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9912Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2979 - accuracy: 0.9102 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9635 - val_loss: 0.1336 - val_accuracy: 0.9578\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.1091 - val_accuracy: 0.9674\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.1132 - val_accuracy: 0.9670\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.0853 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.1058 - val_accuracy: 0.9731\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0998 - val_accuracy: 0.9743\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1119 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.2953 - accuracy: 0.9114 - val_loss: 0.1550 - val_accuracy: 0.9529\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1176 - accuracy: 0.9640 - val_loss: 0.1526 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 0.1162 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.1238 - val_accuracy: 0.9635\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.1121 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1115 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0902 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.1139 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.1317 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1199 - val_accuracy: 0.9747\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1128 - val_accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9768\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3153 - accuracy: 0.9064 - val_loss: 0.1492 - val_accuracy: 0.9568\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1227 - accuracy: 0.9632 - val_loss: 0.1630 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0960 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1109 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1132 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.1005 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1129 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9919Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.1127 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3115 - accuracy: 0.9112 - val_loss: 0.1453 - val_accuracy: 0.9553\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.1369 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.1010 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0951 - val_accuracy: 0.9732\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.1043 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.1063 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1081 - val_accuracy: 0.9755\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1081 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1388 - val_accuracy: 0.9714\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3040 - accuracy: 0.9105 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9637 - val_loss: 0.1213 - val_accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.1084 - val_accuracy: 0.9706\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.1165 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.1149 - val_accuracy: 0.9768\n",
      "Epoch 10/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9942Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.1295 - val_accuracy: 0.9754\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3058 - accuracy: 0.9098 - val_loss: 0.1440 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9643 - val_loss: 0.1452 - val_accuracy: 0.9553\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9755 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1134 - val_accuracy: 0.9769\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1036 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1323 - val_accuracy: 0.9742\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1074 - val_accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9961Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1584 - val_accuracy: 0.9732\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3041 - accuracy: 0.9115 - val_loss: 0.1458 - val_accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 0.1537 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 0.1157 - val_accuracy: 0.9656\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.1241 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0993 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0996 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1100 - val_accuracy: 0.9752\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9751\n",
      "Epoch 10/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3195 - accuracy: 0.9089 - val_loss: 0.1418 - val_accuracy: 0.9577\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1187 - accuracy: 0.9642 - val_loss: 0.1511 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.1036 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1229 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.1071 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0930 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1578 - val_accuracy: 0.9726\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9940Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1278 - val_accuracy: 0.9754\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.1494 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.1205 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9697\n",
      "Epoch 11/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9940Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1133 - val_accuracy: 0.9758\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.1520 - val_accuracy: 0.9541\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1188 - accuracy: 0.9630 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.1138 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1017 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.1229 - val_accuracy: 0.9744\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2997 - accuracy: 0.9103 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9523\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.1244 - val_accuracy: 0.9603\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1145 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1437 - val_accuracy: 0.9738\n",
      "Epoch 13/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9954Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.1200 - val_accuracy: 0.9771\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2963 - accuracy: 0.9102 - val_loss: 0.1595 - val_accuracy: 0.9517\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1303 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 0.1479 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0916 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1021 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.1142 - val_accuracy: 0.9771\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.1613 - val_accuracy: 0.9492\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 0.1182 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1096 - val_accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9910Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.1099 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.1509 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1098 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1305 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1180 - val_accuracy: 0.9720\n",
      "Epoch 9/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.1198 - val_accuracy: 0.9721\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.1517 - val_accuracy: 0.9525\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1204 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.1194 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1397 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "Epoch 11/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1320 - val_accuracy: 0.9737\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.3027 - accuracy: 0.9105 - val_loss: 0.1473 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1224 - accuracy: 0.9617 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.1136 - val_accuracy: 0.9668\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1070 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1131 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1354 - val_accuracy: 0.9724\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1122 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.1265 - val_accuracy: 0.9772\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.1524 - val_accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0997 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1104 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1314 - val_accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9795\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3131 - accuracy: 0.9086 - val_loss: 0.1432 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.1018 - val_accuracy: 0.9756\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2961 - accuracy: 0.9114 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1035 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1241 - val_accuracy: 0.9735\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2924 - accuracy: 0.9121 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1155 - val_accuracy: 0.9651\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1138 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.1225 - val_accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1184 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.1291 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.1330 - val_accuracy: 0.9759\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3000 - accuracy: 0.9096 - val_loss: 0.1486 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0909 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0969 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0956 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0921 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1002 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9949Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1092 - val_accuracy: 0.9762\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2973 - accuracy: 0.9094 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1608 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.1076 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0988 - val_accuracy: 0.9773\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3039 - accuracy: 0.9093 - val_loss: 0.1404 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1659 - val_accuracy: 0.9469\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0917 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.1032 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0950 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.1257 - val_accuracy: 0.9727\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9768\n",
      "Epoch 11/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9952Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1474 - val_accuracy: 0.9718\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3144 - accuracy: 0.9101 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9640 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.0960 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
      "Epoch 8/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1035 - val_accuracy: 0.9763\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3038 - accuracy: 0.9106 - val_loss: 0.1541 - val_accuracy: 0.9531\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.1177 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 10/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.1422 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3111 - accuracy: 0.9091 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.1410 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.1010 - val_accuracy: 0.9741\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0959 - val_accuracy: 0.9766\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1227 - val_accuracy: 0.9774\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 12/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9956Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1370 - val_accuracy: 0.9766\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3062 - accuracy: 0.9113 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.1263 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9713\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.1095 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0986 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1414 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1320 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1268 - val_accuracy: 0.9775\n",
      "Epoch 13/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9954Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1228 - val_accuracy: 0.9783\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3143 - accuracy: 0.9104 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1636 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.1255 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1017 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1203 - val_accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.1180 - val_accuracy: 0.9747\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2962 - accuracy: 0.9117 - val_loss: 0.1435 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9636 - val_loss: 0.1250 - val_accuracy: 0.9631\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.1271 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1082 - val_accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1149 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0977 - val_accuracy: 0.9797\n",
      "Epoch 11/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1208 - val_accuracy: 0.9747\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2986 - accuracy: 0.9112 - val_loss: 0.1517 - val_accuracy: 0.9549\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.1092 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0967 - val_accuracy: 0.9754\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.1039 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.1173 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1013 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9912Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2979 - accuracy: 0.9102 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9635 - val_loss: 0.1336 - val_accuracy: 0.9578\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.1091 - val_accuracy: 0.9674\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.1132 - val_accuracy: 0.9670\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.0853 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.1058 - val_accuracy: 0.9731\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0998 - val_accuracy: 0.9743\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1119 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2953 - accuracy: 0.9114 - val_loss: 0.1550 - val_accuracy: 0.9529\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1176 - accuracy: 0.9640 - val_loss: 0.1526 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 0.1162 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.1238 - val_accuracy: 0.9635\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.1121 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1115 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0902 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.1139 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.1317 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1199 - val_accuracy: 0.9747\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1128 - val_accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9768\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3153 - accuracy: 0.9064 - val_loss: 0.1492 - val_accuracy: 0.9568\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1227 - accuracy: 0.9632 - val_loss: 0.1630 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0960 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1109 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1132 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.1005 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1129 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.1127 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3115 - accuracy: 0.9112 - val_loss: 0.1453 - val_accuracy: 0.9553\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.1369 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.1010 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0951 - val_accuracy: 0.9732\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.1043 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.1063 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1081 - val_accuracy: 0.9755\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1081 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1388 - val_accuracy: 0.9714\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3040 - accuracy: 0.9105 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1149 - accuracy: 0.9637 - val_loss: 0.1213 - val_accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.1084 - val_accuracy: 0.9706\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.1165 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.1149 - val_accuracy: 0.9768\n",
      "Epoch 10/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.1295 - val_accuracy: 0.9754\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3058 - accuracy: 0.9098 - val_loss: 0.1440 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9643 - val_loss: 0.1452 - val_accuracy: 0.9553\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9755 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1134 - val_accuracy: 0.9769\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1036 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1323 - val_accuracy: 0.9742\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1074 - val_accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9961Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1584 - val_accuracy: 0.9732\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3041 - accuracy: 0.9115 - val_loss: 0.1458 - val_accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 0.1537 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 0.1157 - val_accuracy: 0.9656\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.1241 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0993 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0996 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1100 - val_accuracy: 0.9752\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9751\n",
      "Epoch 10/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3195 - accuracy: 0.9089 - val_loss: 0.1418 - val_accuracy: 0.9577\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1187 - accuracy: 0.9642 - val_loss: 0.1511 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.1036 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1229 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.1071 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0930 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1578 - val_accuracy: 0.9726\n",
      "Epoch 13/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9940Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1278 - val_accuracy: 0.9754\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.1494 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.1205 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9697\n",
      "Epoch 11/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9938Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1133 - val_accuracy: 0.9758\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.1520 - val_accuracy: 0.9541\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1188 - accuracy: 0.9630 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.1138 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1017 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.1229 - val_accuracy: 0.9744\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2997 - accuracy: 0.9103 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9523\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.1244 - val_accuracy: 0.9603\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1145 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1437 - val_accuracy: 0.9738\n",
      "Epoch 13/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9953Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.1200 - val_accuracy: 0.9771\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2963 - accuracy: 0.9102 - val_loss: 0.1595 - val_accuracy: 0.9517\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1303 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 0.1479 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0916 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1021 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.1142 - val_accuracy: 0.9771\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.1613 - val_accuracy: 0.9492\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 0.1182 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1096 - val_accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9911Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.1099 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.1509 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1098 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1305 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1180 - val_accuracy: 0.9720\n",
      "Epoch 9/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.1198 - val_accuracy: 0.9721\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.1517 - val_accuracy: 0.9525\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1204 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.1194 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1397 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "Epoch 11/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1320 - val_accuracy: 0.9737\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3027 - accuracy: 0.9105 - val_loss: 0.1473 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1224 - accuracy: 0.9617 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.1136 - val_accuracy: 0.9668\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1070 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1131 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1354 - val_accuracy: 0.9724\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1122 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.1265 - val_accuracy: 0.9772\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.1524 - val_accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0997 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1104 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1314 - val_accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9795\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3131 - accuracy: 0.9086 - val_loss: 0.1432 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.1018 - val_accuracy: 0.9756\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2961 - accuracy: 0.9114 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1035 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1241 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2924 - accuracy: 0.9121 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1155 - val_accuracy: 0.9651\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1138 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.1225 - val_accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1184 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.1291 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.1330 - val_accuracy: 0.9759\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3000 - accuracy: 0.9096 - val_loss: 0.1486 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0909 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0969 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0956 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0921 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1002 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1092 - val_accuracy: 0.9762\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2973 - accuracy: 0.9094 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1608 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.1076 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0988 - val_accuracy: 0.9773\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3039 - accuracy: 0.9093 - val_loss: 0.1404 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1659 - val_accuracy: 0.9469\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0917 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.1032 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0950 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.1257 - val_accuracy: 0.9727\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9768\n",
      "Epoch 11/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1474 - val_accuracy: 0.9718\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3144 - accuracy: 0.9101 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9640 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.0960 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1035 - val_accuracy: 0.9763\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3038 - accuracy: 0.9106 - val_loss: 0.1541 - val_accuracy: 0.9531\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.1177 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 10/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.1422 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3111 - accuracy: 0.9091 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.1410 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.1010 - val_accuracy: 0.9741\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0959 - val_accuracy: 0.9766\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1227 - val_accuracy: 0.9774\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 12/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9956Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1370 - val_accuracy: 0.9766\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3062 - accuracy: 0.9113 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.1263 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9713\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.1095 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0986 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1414 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1320 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1268 - val_accuracy: 0.9775\n",
      "Epoch 13/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9954Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1228 - val_accuracy: 0.9783\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.3143 - accuracy: 0.9104 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1636 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.1255 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1017 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1203 - val_accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.1180 - val_accuracy: 0.9747\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2962 - accuracy: 0.9117 - val_loss: 0.1435 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9636 - val_loss: 0.1250 - val_accuracy: 0.9631\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.1271 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1082 - val_accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1149 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0977 - val_accuracy: 0.9797\n",
      "Epoch 11/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1208 - val_accuracy: 0.9747\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2986 - accuracy: 0.9112 - val_loss: 0.1517 - val_accuracy: 0.9549\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.1092 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0967 - val_accuracy: 0.9754\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.1039 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.1173 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1013 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9912Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2979 - accuracy: 0.9102 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9635 - val_loss: 0.1336 - val_accuracy: 0.9578\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.1091 - val_accuracy: 0.9674\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.1132 - val_accuracy: 0.9670\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.0853 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.1058 - val_accuracy: 0.9731\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0998 - val_accuracy: 0.9743\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1119 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9114 - val_loss: 0.1550 - val_accuracy: 0.9529\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1176 - accuracy: 0.9640 - val_loss: 0.1526 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 0.1162 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.1238 - val_accuracy: 0.9635\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.1121 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1115 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0902 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.1139 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.1317 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1199 - val_accuracy: 0.9747\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1128 - val_accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9768\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3153 - accuracy: 0.9064 - val_loss: 0.1492 - val_accuracy: 0.9568\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1227 - accuracy: 0.9632 - val_loss: 0.1630 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0960 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1109 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1132 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.1005 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1129 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.1127 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3115 - accuracy: 0.9112 - val_loss: 0.1453 - val_accuracy: 0.9553\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.1369 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.1010 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0951 - val_accuracy: 0.9732\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.1043 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.1063 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1081 - val_accuracy: 0.9755\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1081 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1388 - val_accuracy: 0.9714\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3040 - accuracy: 0.9105 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9637 - val_loss: 0.1213 - val_accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.1084 - val_accuracy: 0.9706\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.1165 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.1149 - val_accuracy: 0.9768\n",
      "Epoch 10/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.1295 - val_accuracy: 0.9754\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3058 - accuracy: 0.9098 - val_loss: 0.1440 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9643 - val_loss: 0.1452 - val_accuracy: 0.9553\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9755 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1134 - val_accuracy: 0.9769\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1036 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1323 - val_accuracy: 0.9742\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1074 - val_accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9961Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1584 - val_accuracy: 0.9732\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3041 - accuracy: 0.9115 - val_loss: 0.1458 - val_accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 0.1537 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 0.1157 - val_accuracy: 0.9656\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.1241 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0993 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0996 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1100 - val_accuracy: 0.9752\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9751\n",
      "Epoch 10/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3195 - accuracy: 0.9089 - val_loss: 0.1418 - val_accuracy: 0.9577\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1187 - accuracy: 0.9642 - val_loss: 0.1511 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.1036 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1229 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.1071 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0930 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1578 - val_accuracy: 0.9726\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9940Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1278 - val_accuracy: 0.9754\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.9121 - val_loss: 0.1494 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9603\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.0969 - val_accuracy: 0.9724\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0863 - val_accuracy: 0.9754\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1069 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.1205 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.1309 - val_accuracy: 0.9697\n",
      "Epoch 11/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9939Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1133 - val_accuracy: 0.9758\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.1520 - val_accuracy: 0.9541\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1188 - accuracy: 0.9630 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.1076 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.1138 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1017 - val_accuracy: 0.9761\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.1229 - val_accuracy: 0.9744\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2997 - accuracy: 0.9103 - val_loss: 0.1585 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9523\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.1244 - val_accuracy: 0.9603\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1138 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.1071 - val_accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1145 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1437 - val_accuracy: 0.9738\n",
      "Epoch 13/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9953Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.1200 - val_accuracy: 0.9771\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2963 - accuracy: 0.9102 - val_loss: 0.1595 - val_accuracy: 0.9517\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1303 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0795 - accuracy: 0.9748 - val_loss: 0.1479 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9813 - val_loss: 0.1148 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0916 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.1021 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0921 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.1079 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.1142 - val_accuracy: 0.9771\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.1613 - val_accuracy: 0.9492\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9750 - val_loss: 0.0995 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0348 - accuracy: 0.9881 - val_loss: 0.1182 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1096 - val_accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9911Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.1099 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3155 - accuracy: 0.9076 - val_loss: 0.1509 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9602\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1098 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0977 - val_accuracy: 0.9752\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.1305 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1180 - val_accuracy: 0.9720\n",
      "Epoch 9/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.1198 - val_accuracy: 0.9721\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.1517 - val_accuracy: 0.9525\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1204 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9636\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0762 - accuracy: 0.9757 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.1037 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.1194 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1397 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "Epoch 11/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1320 - val_accuracy: 0.9737\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3027 - accuracy: 0.9105 - val_loss: 0.1473 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1224 - accuracy: 0.9617 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0785 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.1136 - val_accuracy: 0.9668\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1070 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9775\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1131 - val_accuracy: 0.9735\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1354 - val_accuracy: 0.9724\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1122 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.1265 - val_accuracy: 0.9772\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.1524 - val_accuracy: 0.9532\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0800 - accuracy: 0.9748 - val_loss: 0.1161 - val_accuracy: 0.9655\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0997 - val_accuracy: 0.9736\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1104 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.1314 - val_accuracy: 0.9724\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9795\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3131 - accuracy: 0.9086 - val_loss: 0.1432 - val_accuracy: 0.9575\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1220 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1017 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.1405 - val_accuracy: 0.9663\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.1018 - val_accuracy: 0.9756\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2961 - accuracy: 0.9114 - val_loss: 0.1522 - val_accuracy: 0.9542\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1181 - accuracy: 0.9639 - val_loss: 0.1265 - val_accuracy: 0.9624\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9721\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1035 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.1204 - val_accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1241 - val_accuracy: 0.9735\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2924 - accuracy: 0.9121 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1155 - val_accuracy: 0.9651\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1138 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.1225 - val_accuracy: 0.9686\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 0.1184 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.1291 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1105 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.1330 - val_accuracy: 0.9759\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3000 - accuracy: 0.9096 - val_loss: 0.1486 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1200 - accuracy: 0.9640 - val_loss: 0.1610 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0803 - accuracy: 0.9743 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0560 - accuracy: 0.9814 - val_loss: 0.1285 - val_accuracy: 0.9640\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0909 - val_accuracy: 0.9753\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0969 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0956 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.0921 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1002 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1092 - val_accuracy: 0.9762\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2973 - accuracy: 0.9094 - val_loss: 0.1620 - val_accuracy: 0.9528\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1608 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 0.1129 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.1076 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0988 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3039 - accuracy: 0.9093 - val_loss: 0.1404 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1185 - accuracy: 0.9642 - val_loss: 0.1659 - val_accuracy: 0.9469\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.0917 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9694\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.1032 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0950 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1025 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.1257 - val_accuracy: 0.9727\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9768\n",
      "Epoch 11/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1474 - val_accuracy: 0.9718\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3144 - accuracy: 0.9101 - val_loss: 0.1460 - val_accuracy: 0.9562\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9640 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0940 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9820 - val_loss: 0.0960 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.0960 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
      "Epoch 8/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.1035 - val_accuracy: 0.9763\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3038 - accuracy: 0.9106 - val_loss: 0.1541 - val_accuracy: 0.9531\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9637 - val_loss: 0.1210 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0740 - accuracy: 0.9760 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.1016 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.1177 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 10/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.1422 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3111 - accuracy: 0.9091 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.1410 - val_accuracy: 0.9565\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0952 - val_accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.1010 - val_accuracy: 0.9741\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0959 - val_accuracy: 0.9766\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1385 - val_accuracy: 0.9700\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.1227 - val_accuracy: 0.9774\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 12/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9956Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1370 - val_accuracy: 0.9766\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3062 - accuracy: 0.9113 - val_loss: 0.1525 - val_accuracy: 0.9538\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9753 - val_loss: 0.1263 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1018 - val_accuracy: 0.9713\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.1095 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 0.1114 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.1088 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0986 - val_accuracy: 0.9773\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9758\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.1414 - val_accuracy: 0.9727\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1320 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1268 - val_accuracy: 0.9775\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9954Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1228 - val_accuracy: 0.9783\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3143 - accuracy: 0.9104 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1636 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.9762 - val_loss: 0.0988 - val_accuracy: 0.9694\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.1199 - val_accuracy: 0.9668\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.1255 - val_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1017 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.1203 - val_accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.1180 - val_accuracy: 0.9747\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2962 - accuracy: 0.9117 - val_loss: 0.1435 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1174 - accuracy: 0.9636 - val_loss: 0.1250 - val_accuracy: 0.9631\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.1271 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.1082 - val_accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1149 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0977 - val_accuracy: 0.9797\n",
      "Epoch 11/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1208 - val_accuracy: 0.9747\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2986 - accuracy: 0.9112 - val_loss: 0.1517 - val_accuracy: 0.9549\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 0.1092 - val_accuracy: 0.9689\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0967 - val_accuracy: 0.9754\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.1039 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.1173 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1013 - val_accuracy: 0.9762\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9912Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9703\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2979 - accuracy: 0.9102 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1210 - accuracy: 0.9635 - val_loss: 0.1336 - val_accuracy: 0.9578\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.1091 - val_accuracy: 0.9674\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.1132 - val_accuracy: 0.9670\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.0853 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.1058 - val_accuracy: 0.9731\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0998 - val_accuracy: 0.9743\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1119 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2953 - accuracy: 0.9114 - val_loss: 0.1550 - val_accuracy: 0.9529\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1176 - accuracy: 0.9640 - val_loss: 0.1526 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0769 - accuracy: 0.9760 - val_loss: 0.1162 - val_accuracy: 0.9659\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.1238 - val_accuracy: 0.9635\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.1121 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.1115 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0902 - val_accuracy: 0.9757\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.1139 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.1317 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1199 - val_accuracy: 0.9747\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1128 - val_accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9768\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3153 - accuracy: 0.9064 - val_loss: 0.1492 - val_accuracy: 0.9568\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1227 - accuracy: 0.9632 - val_loss: 0.1630 - val_accuracy: 0.9470\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0960 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1109 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1132 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.1005 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1129 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.1127 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3115 - accuracy: 0.9112 - val_loss: 0.1453 - val_accuracy: 0.9553\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.1369 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.1010 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0951 - val_accuracy: 0.9732\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.1043 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.1063 - val_accuracy: 0.9743\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1081 - val_accuracy: 0.9755\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1081 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.1388 - val_accuracy: 0.9714\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3040 - accuracy: 0.9105 - val_loss: 0.1538 - val_accuracy: 0.9519\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9637 - val_loss: 0.1213 - val_accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.1084 - val_accuracy: 0.9706\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.1165 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.1149 - val_accuracy: 0.9768\n",
      "Epoch 10/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.1295 - val_accuracy: 0.9754\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3058 - accuracy: 0.9098 - val_loss: 0.1440 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1170 - accuracy: 0.9643 - val_loss: 0.1452 - val_accuracy: 0.9553\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0767 - accuracy: 0.9755 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0998 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1134 - val_accuracy: 0.9769\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1036 - val_accuracy: 0.9804\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1323 - val_accuracy: 0.9742\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1074 - val_accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9961Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.1584 - val_accuracy: 0.9732\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.3041 - accuracy: 0.9115 - val_loss: 0.1458 - val_accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 0.1537 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0769 - accuracy: 0.9752 - val_loss: 0.1157 - val_accuracy: 0.9656\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.1241 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.0939 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0993 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0996 - val_accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.1100 - val_accuracy: 0.9752\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1189 - val_accuracy: 0.9751\n",
      "Epoch 10/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.1092 - val_accuracy: 0.9787\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3195 - accuracy: 0.9089 - val_loss: 0.1418 - val_accuracy: 0.9577\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1187 - accuracy: 0.9642 - val_loss: 0.1511 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0589 - accuracy: 0.9809 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.1036 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1229 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.1071 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0930 - val_accuracy: 0.9788\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1361 - val_accuracy: 0.9720\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1578 - val_accuracy: 0.9726\n",
      "Epoch 13/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1278 - val_accuracy: 0.9754\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3937 - accuracy: 0.9070 - val_loss: 0.2177 - val_accuracy: 0.9355\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9512 - val_loss: 0.2066 - val_accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 0.1988 - val_accuracy: 0.9488\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9617 - val_loss: 0.2710 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2032 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.1894 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1168 - accuracy: 0.9695 - val_loss: 0.4487 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.2050 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.1925 - val_accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0985 - accuracy: 0.9761 - val_loss: 0.2213 - val_accuracy: 0.9613\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3933 - accuracy: 0.9054 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2034 - accuracy: 0.9422 - val_loss: 0.2575 - val_accuracy: 0.9344\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1845 - accuracy: 0.9493 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.2109 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1524 - accuracy: 0.9592 - val_loss: 0.2775 - val_accuracy: 0.9477\n",
      "Epoch 6/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9615Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1504 - accuracy: 0.9615 - val_loss: 0.2307 - val_accuracy: 0.9488\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3991 - accuracy: 0.9028 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2011 - accuracy: 0.9430 - val_loss: 0.2267 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.1943 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9567 - val_loss: 0.2158 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1561 - accuracy: 0.9580 - val_loss: 0.2284 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1522 - accuracy: 0.9613 - val_loss: 0.2077 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1833 - val_accuracy: 0.9569\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9671 - val_loss: 0.1686 - val_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.2496 - val_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1306 - accuracy: 0.9679 - val_loss: 0.2077 - val_accuracy: 0.9553\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1187 - accuracy: 0.9717 - val_loss: 0.2272 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1094 - accuracy: 0.9732 - val_loss: 0.2458 - val_accuracy: 0.9555\n",
      "Epoch 13/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9744Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1034 - accuracy: 0.9744 - val_loss: 0.2181 - val_accuracy: 0.9578\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3627 - accuracy: 0.9090 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.2003 - val_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.2473 - val_accuracy: 0.9363\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.2016 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1492 - accuracy: 0.9616 - val_loss: 0.2125 - val_accuracy: 0.9528\n",
      "Epoch 6/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9667Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1382 - accuracy: 0.9665 - val_loss: 0.2185 - val_accuracy: 0.9502\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3691 - accuracy: 0.9054 - val_loss: 0.1936 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1729 - accuracy: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9514\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1625 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1399 - accuracy: 0.9627 - val_loss: 0.1859 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1412 - accuracy: 0.9639 - val_loss: 0.1605 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9676 - val_loss: 0.2128 - val_accuracy: 0.9533\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9606\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1952 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1090 - accuracy: 0.9726 - val_loss: 0.1688 - val_accuracy: 0.9663\n",
      "Epoch 11/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9733Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1048 - accuracy: 0.9733 - val_loss: 0.2243 - val_accuracy: 0.9528\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4289 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2069 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.2249 - val_accuracy: 0.9409\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.2078 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1989 - val_accuracy: 0.9553\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1446 - accuracy: 0.9615 - val_loss: 0.2191 - val_accuracy: 0.9573\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1383 - accuracy: 0.9641 - val_loss: 0.1778 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1376 - accuracy: 0.9643 - val_loss: 0.2693 - val_accuracy: 0.9467\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9672 - val_loss: 0.2325 - val_accuracy: 0.9538\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1280 - accuracy: 0.9683 - val_loss: 0.2571 - val_accuracy: 0.9516\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1241 - accuracy: 0.9682 - val_loss: 0.2569 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9676Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1310 - accuracy: 0.9677 - val_loss: 0.2859 - val_accuracy: 0.9499\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.8983 - val_loss: 0.2164 - val_accuracy: 0.9410\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2049 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1989 - accuracy: 0.9454 - val_loss: 0.2326 - val_accuracy: 0.9461\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1739 - accuracy: 0.9532 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1617 - accuracy: 0.9568 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1586 - accuracy: 0.9591 - val_loss: 0.1986 - val_accuracy: 0.9550\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1507 - accuracy: 0.9615 - val_loss: 0.2034 - val_accuracy: 0.9502\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1418 - accuracy: 0.9635 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 9/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9654Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1358 - accuracy: 0.9654 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.8970 - val_loss: 0.2229 - val_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9386 - val_loss: 0.2267 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2015 - accuracy: 0.9461 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9492 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1711 - accuracy: 0.9539 - val_loss: 0.2259 - val_accuracy: 0.9470\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 0.2283 - val_accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.2462 - val_accuracy: 0.9493\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 0.2542 - val_accuracy: 0.9519\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9620Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1550 - accuracy: 0.9620 - val_loss: 0.2132 - val_accuracy: 0.9507\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.4598 - accuracy: 0.8938 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2194 - accuracy: 0.9393 - val_loss: 0.2887 - val_accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.2388 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1854 - accuracy: 0.9495 - val_loss: 0.2109 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9544 - val_loss: 0.2328 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1585 - accuracy: 0.9580 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2425 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9618 - val_loss: 0.2390 - val_accuracy: 0.9465\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.9558\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9642 - val_loss: 0.2146 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.2260 - val_accuracy: 0.9493\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1419 - accuracy: 0.9636 - val_loss: 0.2670 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1381 - accuracy: 0.9658 - val_loss: 0.2825 - val_accuracy: 0.9456\n",
      "Epoch 14/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9687Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1230 - accuracy: 0.9687 - val_loss: 0.2258 - val_accuracy: 0.9527\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4420 - accuracy: 0.8960 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2221 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9445 - val_loss: 0.2407 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1894 - accuracy: 0.9482 - val_loss: 0.2061 - val_accuracy: 0.9486\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1672 - accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.9424\n",
      "Epoch 6/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9556Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1719 - accuracy: 0.9556 - val_loss: 0.2441 - val_accuracy: 0.9422\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3890 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2065 - accuracy: 0.9428 - val_loss: 0.2160 - val_accuracy: 0.9434\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1854 - accuracy: 0.9490 - val_loss: 0.2030 - val_accuracy: 0.9491\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1631 - accuracy: 0.9560 - val_loss: 0.2051 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1496 - accuracy: 0.9608 - val_loss: 0.2316 - val_accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.2238 - val_accuracy: 0.9525\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9632 - val_loss: 0.1964 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.2163 - val_accuracy: 0.9602\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1251 - accuracy: 0.9695 - val_loss: 0.2522 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1057 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9582\n",
      "Epoch 12/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9735Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1091 - accuracy: 0.9735 - val_loss: 0.2083 - val_accuracy: 0.9547\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3759 - accuracy: 0.9077 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2073 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9456\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1678 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9632 - val_loss: 0.2180 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9644 - val_loss: 0.2449 - val_accuracy: 0.9484\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1274 - accuracy: 0.9684 - val_loss: 0.2191 - val_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9696Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1223 - accuracy: 0.9696 - val_loss: 0.2368 - val_accuracy: 0.9566\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3781 - accuracy: 0.9100 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9337\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1694 - accuracy: 0.9539 - val_loss: 0.1895 - val_accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1582 - accuracy: 0.9572 - val_loss: 0.2150 - val_accuracy: 0.9485\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.2038 - val_accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1381 - accuracy: 0.9649 - val_loss: 0.1998 - val_accuracy: 0.9561\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1304 - accuracy: 0.9660 - val_loss: 0.1811 - val_accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1851 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9693 - val_loss: 0.2541 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1102 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.1771 - val_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1854 - val_accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1979 - val_accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.2191 - val_accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9771Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.2106 - val_accuracy: 0.9654\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3951 - accuracy: 0.9054 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9386\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1544 - accuracy: 0.9592 - val_loss: 0.1821 - val_accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1391 - accuracy: 0.9630 - val_loss: 0.1648 - val_accuracy: 0.9588\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9648 - val_loss: 0.1903 - val_accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.2147 - val_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9693 - val_loss: 0.2290 - val_accuracy: 0.9529\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9702Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1162 - accuracy: 0.9702 - val_loss: 0.1979 - val_accuracy: 0.9557\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3963 - accuracy: 0.9036 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9472 - val_loss: 0.2252 - val_accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.1891 - val_accuracy: 0.9527\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1454 - accuracy: 0.9615 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
      "Epoch 6/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9658Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1322 - accuracy: 0.9658 - val_loss: 0.2101 - val_accuracy: 0.9513\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.4892 - accuracy: 0.8877 - val_loss: 0.2266 - val_accuracy: 0.9364\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2322 - accuracy: 0.9352 - val_loss: 0.2302 - val_accuracy: 0.9394\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9525 - val_loss: 0.2147 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9574 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1416 - accuracy: 0.9637 - val_loss: 0.2670 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1444 - accuracy: 0.9627 - val_loss: 0.2326 - val_accuracy: 0.9486\n",
      "Epoch 12/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9639Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1402 - accuracy: 0.9638 - val_loss: 0.2272 - val_accuracy: 0.9521\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4861 - accuracy: 0.8921 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 0.2093 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1900 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9466\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1774 - accuracy: 0.9521 - val_loss: 0.2082 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.1971 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1648 - accuracy: 0.9578 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.2186 - val_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 0.2569 - val_accuracy: 0.9448\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9646 - val_loss: 0.2178 - val_accuracy: 0.9484\n",
      "Epoch 11/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9647Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9647 - val_loss: 0.2034 - val_accuracy: 0.9543\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4744 - accuracy: 0.8952 - val_loss: 0.2387 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2240 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9379\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1931 - accuracy: 0.9472 - val_loss: 0.1842 - val_accuracy: 0.9498\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.2538 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1742 - accuracy: 0.9529 - val_loss: 0.2317 - val_accuracy: 0.9517\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.2327 - val_accuracy: 0.9496\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 0.2381 - val_accuracy: 0.9510\n",
      "Epoch 8/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.1493 - accuracy: 0.9613Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1494 - accuracy: 0.9612 - val_loss: 0.1858 - val_accuracy: 0.9548\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.5268 - accuracy: 0.8886 - val_loss: 0.2405 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2393 - accuracy: 0.9300 - val_loss: 0.2778 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 0.2480 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2050 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1831 - accuracy: 0.9492 - val_loss: 0.2605 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1786 - accuracy: 0.9519 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1691 - accuracy: 0.9540 - val_loss: 0.2105 - val_accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.2721 - val_accuracy: 0.9365\n",
      "Epoch 9/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9579Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 0.2336 - val_accuracy: 0.9498\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4795 - accuracy: 0.8931 - val_loss: 0.2500 - val_accuracy: 0.9263\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2228 - accuracy: 0.9368 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9417\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.2290 - val_accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.2428 - val_accuracy: 0.9458\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1570 - accuracy: 0.9580 - val_loss: 0.2083 - val_accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.2158 - val_accuracy: 0.9545\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1295 - accuracy: 0.9654 - val_loss: 0.2430 - val_accuracy: 0.9488\n",
      "Epoch 13/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.9662Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1268 - accuracy: 0.9662 - val_loss: 0.2338 - val_accuracy: 0.9445\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.3752 - accuracy: 0.9087 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1985 - accuracy: 0.9447 - val_loss: 0.2436 - val_accuracy: 0.9388\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1734 - accuracy: 0.9528 - val_loss: 0.1856 - val_accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1553 - accuracy: 0.9593 - val_loss: 0.2109 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1431 - accuracy: 0.9628 - val_loss: 0.2013 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.2265 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9648 - val_loss: 0.1950 - val_accuracy: 0.9592\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1279 - accuracy: 0.9674 - val_loss: 0.2056 - val_accuracy: 0.9539\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3913 - accuracy: 0.9061 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9440 - val_loss: 0.2058 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1841 - accuracy: 0.9509 - val_loss: 0.2333 - val_accuracy: 0.9403\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1636 - accuracy: 0.9566 - val_loss: 0.2396 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1467 - accuracy: 0.9614 - val_loss: 0.2179 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1370 - accuracy: 0.9644 - val_loss: 0.1999 - val_accuracy: 0.9607\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.2109 - val_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1374 - accuracy: 0.9653 - val_loss: 0.1949 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9678 - val_loss: 0.2164 - val_accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 0.2091 - val_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1100 - accuracy: 0.9735 - val_loss: 0.2754 - val_accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9731 - val_loss: 0.2118 - val_accuracy: 0.9578\n",
      "Epoch 13/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9758Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0989 - accuracy: 0.9756 - val_loss: 0.2487 - val_accuracy: 0.9513\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4027 - accuracy: 0.9059 - val_loss: 0.2252 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9443 - val_loss: 0.1705 - val_accuracy: 0.9509\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1751 - accuracy: 0.9536 - val_loss: 0.2058 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1607 - accuracy: 0.9554 - val_loss: 0.3140 - val_accuracy: 0.9336\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9622 - val_loss: 0.1823 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9653Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1338 - accuracy: 0.9653 - val_loss: 0.2558 - val_accuracy: 0.9501\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3985 - accuracy: 0.9040 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1927 - accuracy: 0.9462 - val_loss: 0.2652 - val_accuracy: 0.9259\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1802 - accuracy: 0.9522 - val_loss: 0.2011 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1605 - accuracy: 0.9574 - val_loss: 0.1911 - val_accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1499 - accuracy: 0.9604 - val_loss: 0.2031 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1384 - accuracy: 0.9643 - val_loss: 0.1863 - val_accuracy: 0.9602\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1294 - accuracy: 0.9666 - val_loss: 0.2084 - val_accuracy: 0.9560\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1217 - accuracy: 0.9693 - val_loss: 0.2252 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1211 - accuracy: 0.9695 - val_loss: 0.2089 - val_accuracy: 0.9577\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1112 - accuracy: 0.9729 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9740Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1082 - accuracy: 0.9740 - val_loss: 0.2194 - val_accuracy: 0.9580\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4284 - accuracy: 0.9026 - val_loss: 0.2534 - val_accuracy: 0.9245\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2041 - accuracy: 0.9433 - val_loss: 0.2564 - val_accuracy: 0.9277\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1785 - accuracy: 0.9514 - val_loss: 0.1774 - val_accuracy: 0.9537\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9560 - val_loss: 0.1986 - val_accuracy: 0.9459\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1551 - accuracy: 0.9596 - val_loss: 0.2516 - val_accuracy: 0.9413\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1435 - accuracy: 0.9620 - val_loss: 0.2224 - val_accuracy: 0.9472\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2803 - val_accuracy: 0.9428\n",
      "Epoch 8/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9669Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1227 - accuracy: 0.9668 - val_loss: 0.2122 - val_accuracy: 0.9571\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.4755 - accuracy: 0.8967 - val_loss: 0.2649 - val_accuracy: 0.9225\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2237 - accuracy: 0.9368 - val_loss: 0.2389 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1916 - accuracy: 0.9474 - val_loss: 0.2335 - val_accuracy: 0.9445\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1741 - accuracy: 0.9539 - val_loss: 0.1963 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9559 - val_loss: 0.2178 - val_accuracy: 0.9525\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1568 - accuracy: 0.9593 - val_loss: 0.2197 - val_accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2714 - val_accuracy: 0.9457\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1330 - accuracy: 0.9655 - val_loss: 0.1923 - val_accuracy: 0.9547\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1340 - accuracy: 0.9653 - val_loss: 0.2601 - val_accuracy: 0.9469\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1271 - accuracy: 0.9688 - val_loss: 0.2437 - val_accuracy: 0.9576\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1407 - accuracy: 0.9662 - val_loss: 0.2239 - val_accuracy: 0.9483\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1158 - accuracy: 0.9710 - val_loss: 0.2459 - val_accuracy: 0.9528\n",
      "Epoch 13/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9711Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1149 - accuracy: 0.9709 - val_loss: 0.2185 - val_accuracy: 0.9542\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.4951 - accuracy: 0.8964 - val_loss: 0.2130 - val_accuracy: 0.9370\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 5ms/step - loss: 0.2238 - accuracy: 0.9366 - val_loss: 0.2381 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2011 - accuracy: 0.9432 - val_loss: 0.2019 - val_accuracy: 0.9454\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1949 - accuracy: 0.9466 - val_loss: 0.2340 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2170 - val_accuracy: 0.9448\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1504 - accuracy: 0.9606 - val_loss: 0.2103 - val_accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9606Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1473 - accuracy: 0.9604 - val_loss: 0.2447 - val_accuracy: 0.9396\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 4ms/step - loss: 0.4739 - accuracy: 0.8992 - val_loss: 0.2179 - val_accuracy: 0.9369\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2117 - accuracy: 0.9393 - val_loss: 0.1901 - val_accuracy: 0.9441\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1854 - accuracy: 0.9492 - val_loss: 0.1963 - val_accuracy: 0.9474\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1621 - accuracy: 0.9550 - val_loss: 0.2958 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1618 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1566 - accuracy: 0.9594 - val_loss: 0.1901 - val_accuracy: 0.9542\n",
      "Epoch 7/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9622Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1460 - accuracy: 0.9622 - val_loss: 0.2354 - val_accuracy: 0.9492\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4987 - accuracy: 0.8948 - val_loss: 0.2114 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2163 - accuracy: 0.9391 - val_loss: 0.2183 - val_accuracy: 0.9321\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9462 - val_loss: 0.2195 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1852 - accuracy: 0.9498 - val_loss: 0.2339 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1673 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9496\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1581 - accuracy: 0.9598 - val_loss: 0.2061 - val_accuracy: 0.9527\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1530 - accuracy: 0.9599 - val_loss: 0.2378 - val_accuracy: 0.9477\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1468 - accuracy: 0.9629 - val_loss: 0.1854 - val_accuracy: 0.9546\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1474 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9533\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1317 - accuracy: 0.9653 - val_loss: 0.2188 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1371 - accuracy: 0.9662 - val_loss: 0.2198 - val_accuracy: 0.9469\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1273 - accuracy: 0.9688 - val_loss: 0.2327 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9689Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1229 - accuracy: 0.9688 - val_loss: 0.2029 - val_accuracy: 0.9568\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.4554 - accuracy: 0.8961 - val_loss: 0.2130 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.1963 - val_accuracy: 0.9405\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9482 - val_loss: 0.2119 - val_accuracy: 0.9438\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1906 - accuracy: 0.9483 - val_loss: 0.2231 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1635 - accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.9456\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1658 - accuracy: 0.9567 - val_loss: 0.2191 - val_accuracy: 0.9468\n",
      "Epoch 7/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9584Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1571 - accuracy: 0.9584 - val_loss: 0.2271 - val_accuracy: 0.9455\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3937 - accuracy: 0.9070 - val_loss: 0.2177 - val_accuracy: 0.9355\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1950 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1817 - accuracy: 0.9512 - val_loss: 0.2066 - val_accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 0.1988 - val_accuracy: 0.9488\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1460 - accuracy: 0.9617 - val_loss: 0.2710 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2032 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.1894 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1168 - accuracy: 0.9695 - val_loss: 0.4487 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.2050 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.1925 - val_accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0985 - accuracy: 0.9761 - val_loss: 0.2213 - val_accuracy: 0.9613\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3933 - accuracy: 0.9054 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2034 - accuracy: 0.9422 - val_loss: 0.2575 - val_accuracy: 0.9344\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1845 - accuracy: 0.9493 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.2109 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1524 - accuracy: 0.9592 - val_loss: 0.2775 - val_accuracy: 0.9477\n",
      "Epoch 6/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9615Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9615 - val_loss: 0.2307 - val_accuracy: 0.9488\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3991 - accuracy: 0.9028 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9430 - val_loss: 0.2267 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.1943 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9567 - val_loss: 0.2158 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1561 - accuracy: 0.9580 - val_loss: 0.2284 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1522 - accuracy: 0.9613 - val_loss: 0.2077 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1833 - val_accuracy: 0.9569\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9671 - val_loss: 0.1686 - val_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.2496 - val_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1306 - accuracy: 0.9679 - val_loss: 0.2077 - val_accuracy: 0.9553\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1187 - accuracy: 0.9717 - val_loss: 0.2272 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1094 - accuracy: 0.9732 - val_loss: 0.2458 - val_accuracy: 0.9555\n",
      "Epoch 13/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1034 - accuracy: 0.9744 - val_loss: 0.2181 - val_accuracy: 0.9578\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3627 - accuracy: 0.9090 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.2003 - val_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.2473 - val_accuracy: 0.9363\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.2016 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.9616 - val_loss: 0.2125 - val_accuracy: 0.9528\n",
      "Epoch 6/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9667Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1382 - accuracy: 0.9665 - val_loss: 0.2185 - val_accuracy: 0.9502\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.9054 - val_loss: 0.1936 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1729 - accuracy: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9514\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1625 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9627 - val_loss: 0.1859 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1412 - accuracy: 0.9639 - val_loss: 0.1605 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9676 - val_loss: 0.2128 - val_accuracy: 0.9533\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9606\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1952 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1090 - accuracy: 0.9726 - val_loss: 0.1688 - val_accuracy: 0.9663\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9733Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1048 - accuracy: 0.9733 - val_loss: 0.2243 - val_accuracy: 0.9528\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4289 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2069 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.2249 - val_accuracy: 0.9409\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.2078 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1989 - val_accuracy: 0.9553\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1446 - accuracy: 0.9615 - val_loss: 0.2191 - val_accuracy: 0.9573\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9641 - val_loss: 0.1778 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1376 - accuracy: 0.9643 - val_loss: 0.2693 - val_accuracy: 0.9467\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9672 - val_loss: 0.2325 - val_accuracy: 0.9538\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1280 - accuracy: 0.9683 - val_loss: 0.2571 - val_accuracy: 0.9516\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1241 - accuracy: 0.9682 - val_loss: 0.2569 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9676Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1310 - accuracy: 0.9677 - val_loss: 0.2859 - val_accuracy: 0.9499\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.8983 - val_loss: 0.2164 - val_accuracy: 0.9410\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2049 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1989 - accuracy: 0.9454 - val_loss: 0.2326 - val_accuracy: 0.9461\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1739 - accuracy: 0.9532 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1617 - accuracy: 0.9568 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1586 - accuracy: 0.9591 - val_loss: 0.1986 - val_accuracy: 0.9550\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1507 - accuracy: 0.9615 - val_loss: 0.2034 - val_accuracy: 0.9502\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9635 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 9/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9655Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1358 - accuracy: 0.9654 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.8970 - val_loss: 0.2229 - val_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9386 - val_loss: 0.2267 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2015 - accuracy: 0.9461 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9492 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1711 - accuracy: 0.9539 - val_loss: 0.2259 - val_accuracy: 0.9470\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 0.2283 - val_accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.2462 - val_accuracy: 0.9493\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 0.2542 - val_accuracy: 0.9519\n",
      "Epoch 9/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9619Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1550 - accuracy: 0.9620 - val_loss: 0.2132 - val_accuracy: 0.9507\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.4598 - accuracy: 0.8938 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2194 - accuracy: 0.9393 - val_loss: 0.2887 - val_accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.2388 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9495 - val_loss: 0.2109 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9544 - val_loss: 0.2328 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1585 - accuracy: 0.9580 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2425 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9618 - val_loss: 0.2390 - val_accuracy: 0.9465\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.9558\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9642 - val_loss: 0.2146 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.2260 - val_accuracy: 0.9493\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1419 - accuracy: 0.9636 - val_loss: 0.2670 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9658 - val_loss: 0.2825 - val_accuracy: 0.9456\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9687Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1230 - accuracy: 0.9687 - val_loss: 0.2258 - val_accuracy: 0.9527\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8960 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2221 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9445 - val_loss: 0.2407 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1894 - accuracy: 0.9482 - val_loss: 0.2061 - val_accuracy: 0.9486\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1672 - accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.9424\n",
      "Epoch 6/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9556Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1719 - accuracy: 0.9556 - val_loss: 0.2441 - val_accuracy: 0.9422\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3890 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2065 - accuracy: 0.9428 - val_loss: 0.2160 - val_accuracy: 0.9434\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1854 - accuracy: 0.9490 - val_loss: 0.2030 - val_accuracy: 0.9491\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1631 - accuracy: 0.9560 - val_loss: 0.2051 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1496 - accuracy: 0.9608 - val_loss: 0.2316 - val_accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.2238 - val_accuracy: 0.9525\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9632 - val_loss: 0.1964 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.2163 - val_accuracy: 0.9602\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1251 - accuracy: 0.9695 - val_loss: 0.2522 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1057 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9582\n",
      "Epoch 12/20\n",
      "1179/1200 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9736Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9735 - val_loss: 0.2083 - val_accuracy: 0.9547\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3759 - accuracy: 0.9077 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2073 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9456\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1678 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9632 - val_loss: 0.2180 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9644 - val_loss: 0.2449 - val_accuracy: 0.9484\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1274 - accuracy: 0.9684 - val_loss: 0.2191 - val_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9695Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9696 - val_loss: 0.2368 - val_accuracy: 0.9566\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3781 - accuracy: 0.9100 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9337\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1694 - accuracy: 0.9539 - val_loss: 0.1895 - val_accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1582 - accuracy: 0.9572 - val_loss: 0.2150 - val_accuracy: 0.9485\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.2038 - val_accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9649 - val_loss: 0.1998 - val_accuracy: 0.9561\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1304 - accuracy: 0.9660 - val_loss: 0.1811 - val_accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1851 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9693 - val_loss: 0.2541 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1102 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.1771 - val_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1854 - val_accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1979 - val_accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.2191 - val_accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9771Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.2106 - val_accuracy: 0.9654\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3951 - accuracy: 0.9054 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9386\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1544 - accuracy: 0.9592 - val_loss: 0.1821 - val_accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1391 - accuracy: 0.9630 - val_loss: 0.1648 - val_accuracy: 0.9588\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9648 - val_loss: 0.1903 - val_accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.2147 - val_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9693 - val_loss: 0.2290 - val_accuracy: 0.9529\n",
      "Epoch 11/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9705Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1162 - accuracy: 0.9702 - val_loss: 0.1979 - val_accuracy: 0.9557\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3963 - accuracy: 0.9036 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9472 - val_loss: 0.2252 - val_accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.1891 - val_accuracy: 0.9527\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1454 - accuracy: 0.9615 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
      "Epoch 6/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9661Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1322 - accuracy: 0.9658 - val_loss: 0.2101 - val_accuracy: 0.9513\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4892 - accuracy: 0.8877 - val_loss: 0.2266 - val_accuracy: 0.9364\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2322 - accuracy: 0.9352 - val_loss: 0.2302 - val_accuracy: 0.9394\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9525 - val_loss: 0.2147 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9574 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1416 - accuracy: 0.9637 - val_loss: 0.2670 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1444 - accuracy: 0.9627 - val_loss: 0.2326 - val_accuracy: 0.9486\n",
      "Epoch 12/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9639Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1402 - accuracy: 0.9638 - val_loss: 0.2272 - val_accuracy: 0.9521\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4861 - accuracy: 0.8921 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 0.2093 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1900 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9466\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1774 - accuracy: 0.9521 - val_loss: 0.2082 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.1971 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1648 - accuracy: 0.9578 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.2186 - val_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 0.2569 - val_accuracy: 0.9448\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9646 - val_loss: 0.2178 - val_accuracy: 0.9484\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9646Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9647 - val_loss: 0.2034 - val_accuracy: 0.9543\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4744 - accuracy: 0.8952 - val_loss: 0.2387 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9379\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1931 - accuracy: 0.9472 - val_loss: 0.1842 - val_accuracy: 0.9498\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.2538 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.9529 - val_loss: 0.2317 - val_accuracy: 0.9517\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.2327 - val_accuracy: 0.9496\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 0.2381 - val_accuracy: 0.9510\n",
      "Epoch 8/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9613Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1494 - accuracy: 0.9612 - val_loss: 0.1858 - val_accuracy: 0.9548\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5268 - accuracy: 0.8886 - val_loss: 0.2405 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.9300 - val_loss: 0.2778 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 0.2480 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2050 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1831 - accuracy: 0.9492 - val_loss: 0.2605 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9519 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9540 - val_loss: 0.2105 - val_accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.2721 - val_accuracy: 0.9365\n",
      "Epoch 9/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9579Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 0.2336 - val_accuracy: 0.9498\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4795 - accuracy: 0.8931 - val_loss: 0.2500 - val_accuracy: 0.9263\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2228 - accuracy: 0.9368 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9417\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.2290 - val_accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.2428 - val_accuracy: 0.9458\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1570 - accuracy: 0.9580 - val_loss: 0.2083 - val_accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.2158 - val_accuracy: 0.9545\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1295 - accuracy: 0.9654 - val_loss: 0.2430 - val_accuracy: 0.9488\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9662Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1268 - accuracy: 0.9662 - val_loss: 0.2338 - val_accuracy: 0.9445\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3752 - accuracy: 0.9087 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1985 - accuracy: 0.9447 - val_loss: 0.2436 - val_accuracy: 0.9388\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1734 - accuracy: 0.9528 - val_loss: 0.1856 - val_accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1553 - accuracy: 0.9593 - val_loss: 0.2109 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1431 - accuracy: 0.9628 - val_loss: 0.2013 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.2265 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9648 - val_loss: 0.1950 - val_accuracy: 0.9592\n",
      "Epoch 8/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.9673Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1279 - accuracy: 0.9674 - val_loss: 0.2056 - val_accuracy: 0.9539\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3913 - accuracy: 0.9061 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9440 - val_loss: 0.2058 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1841 - accuracy: 0.9509 - val_loss: 0.2333 - val_accuracy: 0.9403\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9566 - val_loss: 0.2396 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1467 - accuracy: 0.9614 - val_loss: 0.2179 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1370 - accuracy: 0.9644 - val_loss: 0.1999 - val_accuracy: 0.9607\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.2109 - val_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9653 - val_loss: 0.1949 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9678 - val_loss: 0.2164 - val_accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 0.2091 - val_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1100 - accuracy: 0.9735 - val_loss: 0.2754 - val_accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9731 - val_loss: 0.2118 - val_accuracy: 0.9578\n",
      "Epoch 13/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0989 - accuracy: 0.9756 - val_loss: 0.2487 - val_accuracy: 0.9513\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4027 - accuracy: 0.9059 - val_loss: 0.2252 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9443 - val_loss: 0.1705 - val_accuracy: 0.9509\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1751 - accuracy: 0.9536 - val_loss: 0.2058 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1607 - accuracy: 0.9554 - val_loss: 0.3140 - val_accuracy: 0.9336\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9622 - val_loss: 0.1823 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9653Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1338 - accuracy: 0.9653 - val_loss: 0.2558 - val_accuracy: 0.9501\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3985 - accuracy: 0.9040 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1927 - accuracy: 0.9462 - val_loss: 0.2652 - val_accuracy: 0.9259\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1802 - accuracy: 0.9522 - val_loss: 0.2011 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1605 - accuracy: 0.9574 - val_loss: 0.1911 - val_accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1499 - accuracy: 0.9604 - val_loss: 0.2031 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1384 - accuracy: 0.9643 - val_loss: 0.1863 - val_accuracy: 0.9602\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1294 - accuracy: 0.9666 - val_loss: 0.2084 - val_accuracy: 0.9560\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1217 - accuracy: 0.9693 - val_loss: 0.2252 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.9695 - val_loss: 0.2089 - val_accuracy: 0.9577\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1112 - accuracy: 0.9729 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9740Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1082 - accuracy: 0.9740 - val_loss: 0.2194 - val_accuracy: 0.9580\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4284 - accuracy: 0.9026 - val_loss: 0.2534 - val_accuracy: 0.9245\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2041 - accuracy: 0.9433 - val_loss: 0.2564 - val_accuracy: 0.9277\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1785 - accuracy: 0.9514 - val_loss: 0.1774 - val_accuracy: 0.9537\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1666 - accuracy: 0.9560 - val_loss: 0.1986 - val_accuracy: 0.9459\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1551 - accuracy: 0.9596 - val_loss: 0.2516 - val_accuracy: 0.9413\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1435 - accuracy: 0.9620 - val_loss: 0.2224 - val_accuracy: 0.9472\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2803 - val_accuracy: 0.9428\n",
      "Epoch 8/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9669Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1227 - accuracy: 0.9668 - val_loss: 0.2122 - val_accuracy: 0.9571\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4755 - accuracy: 0.8967 - val_loss: 0.2649 - val_accuracy: 0.9225\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2237 - accuracy: 0.9368 - val_loss: 0.2389 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1916 - accuracy: 0.9474 - val_loss: 0.2335 - val_accuracy: 0.9445\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1741 - accuracy: 0.9539 - val_loss: 0.1963 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1673 - accuracy: 0.9559 - val_loss: 0.2178 - val_accuracy: 0.9525\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1568 - accuracy: 0.9593 - val_loss: 0.2197 - val_accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2714 - val_accuracy: 0.9457\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1330 - accuracy: 0.9655 - val_loss: 0.1923 - val_accuracy: 0.9547\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1340 - accuracy: 0.9653 - val_loss: 0.2601 - val_accuracy: 0.9469\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1271 - accuracy: 0.9688 - val_loss: 0.2437 - val_accuracy: 0.9576\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1407 - accuracy: 0.9662 - val_loss: 0.2239 - val_accuracy: 0.9483\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1158 - accuracy: 0.9710 - val_loss: 0.2459 - val_accuracy: 0.9528\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9709Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9709 - val_loss: 0.2185 - val_accuracy: 0.9542\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4951 - accuracy: 0.8964 - val_loss: 0.2130 - val_accuracy: 0.9370\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9366 - val_loss: 0.2381 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9432 - val_loss: 0.2019 - val_accuracy: 0.9454\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1949 - accuracy: 0.9466 - val_loss: 0.2340 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2170 - val_accuracy: 0.9448\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9606 - val_loss: 0.2103 - val_accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9606Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1473 - accuracy: 0.9604 - val_loss: 0.2447 - val_accuracy: 0.9396\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4739 - accuracy: 0.8992 - val_loss: 0.2179 - val_accuracy: 0.9369\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2117 - accuracy: 0.9393 - val_loss: 0.1901 - val_accuracy: 0.9441\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9492 - val_loss: 0.1963 - val_accuracy: 0.9474\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1621 - accuracy: 0.9550 - val_loss: 0.2958 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1618 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1566 - accuracy: 0.9594 - val_loss: 0.1901 - val_accuracy: 0.9542\n",
      "Epoch 7/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9622Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9622 - val_loss: 0.2354 - val_accuracy: 0.9492\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4987 - accuracy: 0.8948 - val_loss: 0.2114 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2163 - accuracy: 0.9391 - val_loss: 0.2183 - val_accuracy: 0.9321\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9462 - val_loss: 0.2195 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1852 - accuracy: 0.9498 - val_loss: 0.2339 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9496\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1581 - accuracy: 0.9598 - val_loss: 0.2061 - val_accuracy: 0.9527\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1530 - accuracy: 0.9599 - val_loss: 0.2378 - val_accuracy: 0.9477\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1468 - accuracy: 0.9629 - val_loss: 0.1854 - val_accuracy: 0.9546\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1474 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9533\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1317 - accuracy: 0.9653 - val_loss: 0.2188 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1371 - accuracy: 0.9662 - val_loss: 0.2198 - val_accuracy: 0.9469\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1273 - accuracy: 0.9688 - val_loss: 0.2327 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9689Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1229 - accuracy: 0.9688 - val_loss: 0.2029 - val_accuracy: 0.9568\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4554 - accuracy: 0.8961 - val_loss: 0.2130 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.1963 - val_accuracy: 0.9405\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9482 - val_loss: 0.2119 - val_accuracy: 0.9438\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1906 - accuracy: 0.9483 - val_loss: 0.2231 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1635 - accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.9456\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1658 - accuracy: 0.9567 - val_loss: 0.2191 - val_accuracy: 0.9468\n",
      "Epoch 7/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9584Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1571 - accuracy: 0.9584 - val_loss: 0.2271 - val_accuracy: 0.9455\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3937 - accuracy: 0.9070 - val_loss: 0.2177 - val_accuracy: 0.9355\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1950 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9512 - val_loss: 0.2066 - val_accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 0.1988 - val_accuracy: 0.9488\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9617 - val_loss: 0.2710 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2032 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.1894 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1168 - accuracy: 0.9695 - val_loss: 0.4487 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.2050 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.1925 - val_accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.0985 - accuracy: 0.9761 - val_loss: 0.2213 - val_accuracy: 0.9613\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3933 - accuracy: 0.9054 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2034 - accuracy: 0.9422 - val_loss: 0.2575 - val_accuracy: 0.9344\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1845 - accuracy: 0.9493 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.2109 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1524 - accuracy: 0.9592 - val_loss: 0.2775 - val_accuracy: 0.9477\n",
      "Epoch 6/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9615Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1504 - accuracy: 0.9615 - val_loss: 0.2307 - val_accuracy: 0.9488\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3991 - accuracy: 0.9028 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9430 - val_loss: 0.2267 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.1943 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9567 - val_loss: 0.2158 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1561 - accuracy: 0.9580 - val_loss: 0.2284 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1522 - accuracy: 0.9613 - val_loss: 0.2077 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1833 - val_accuracy: 0.9569\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9671 - val_loss: 0.1686 - val_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.2496 - val_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1306 - accuracy: 0.9679 - val_loss: 0.2077 - val_accuracy: 0.9553\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1187 - accuracy: 0.9717 - val_loss: 0.2272 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1094 - accuracy: 0.9732 - val_loss: 0.2458 - val_accuracy: 0.9555\n",
      "Epoch 13/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1034 - accuracy: 0.9744 - val_loss: 0.2181 - val_accuracy: 0.9578\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3627 - accuracy: 0.9090 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.2003 - val_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.2473 - val_accuracy: 0.9363\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.2016 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.9616 - val_loss: 0.2125 - val_accuracy: 0.9528\n",
      "Epoch 6/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9666Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1382 - accuracy: 0.9665 - val_loss: 0.2185 - val_accuracy: 0.9502\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.9054 - val_loss: 0.1936 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1729 - accuracy: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9514\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1625 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9627 - val_loss: 0.1859 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1412 - accuracy: 0.9639 - val_loss: 0.1605 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9676 - val_loss: 0.2128 - val_accuracy: 0.9533\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9606\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1952 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1090 - accuracy: 0.9726 - val_loss: 0.1688 - val_accuracy: 0.9663\n",
      "Epoch 11/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 0.9733Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1048 - accuracy: 0.9733 - val_loss: 0.2243 - val_accuracy: 0.9528\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4289 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2069 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.2249 - val_accuracy: 0.9409\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.2078 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1989 - val_accuracy: 0.9553\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1446 - accuracy: 0.9615 - val_loss: 0.2191 - val_accuracy: 0.9573\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9641 - val_loss: 0.1778 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1376 - accuracy: 0.9643 - val_loss: 0.2693 - val_accuracy: 0.9467\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9672 - val_loss: 0.2325 - val_accuracy: 0.9538\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1280 - accuracy: 0.9683 - val_loss: 0.2571 - val_accuracy: 0.9516\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1241 - accuracy: 0.9682 - val_loss: 0.2569 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9677Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1310 - accuracy: 0.9677 - val_loss: 0.2859 - val_accuracy: 0.9499\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4448 - accuracy: 0.8983 - val_loss: 0.2164 - val_accuracy: 0.9410\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2049 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1989 - accuracy: 0.9454 - val_loss: 0.2326 - val_accuracy: 0.9461\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1739 - accuracy: 0.9532 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1617 - accuracy: 0.9568 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1586 - accuracy: 0.9591 - val_loss: 0.1986 - val_accuracy: 0.9550\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1507 - accuracy: 0.9615 - val_loss: 0.2034 - val_accuracy: 0.9502\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9635 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 9/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9655Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1358 - accuracy: 0.9654 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.8970 - val_loss: 0.2229 - val_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9386 - val_loss: 0.2267 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2015 - accuracy: 0.9461 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9492 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1711 - accuracy: 0.9539 - val_loss: 0.2259 - val_accuracy: 0.9470\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 0.2283 - val_accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.2462 - val_accuracy: 0.9493\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 0.2542 - val_accuracy: 0.9519\n",
      "Epoch 9/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9620Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1550 - accuracy: 0.9620 - val_loss: 0.2132 - val_accuracy: 0.9507\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4598 - accuracy: 0.8938 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2194 - accuracy: 0.9393 - val_loss: 0.2887 - val_accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.2388 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9495 - val_loss: 0.2109 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9544 - val_loss: 0.2328 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1585 - accuracy: 0.9580 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2425 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9618 - val_loss: 0.2390 - val_accuracy: 0.9465\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.9558\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9642 - val_loss: 0.2146 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.2260 - val_accuracy: 0.9493\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1419 - accuracy: 0.9636 - val_loss: 0.2670 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9658 - val_loss: 0.2825 - val_accuracy: 0.9456\n",
      "Epoch 14/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9688Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1230 - accuracy: 0.9687 - val_loss: 0.2258 - val_accuracy: 0.9527\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8960 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2221 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9445 - val_loss: 0.2407 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1894 - accuracy: 0.9482 - val_loss: 0.2061 - val_accuracy: 0.9486\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1672 - accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.9424\n",
      "Epoch 6/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9557Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1719 - accuracy: 0.9556 - val_loss: 0.2441 - val_accuracy: 0.9422\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3890 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2065 - accuracy: 0.9428 - val_loss: 0.2160 - val_accuracy: 0.9434\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9490 - val_loss: 0.2030 - val_accuracy: 0.9491\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1631 - accuracy: 0.9560 - val_loss: 0.2051 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1496 - accuracy: 0.9608 - val_loss: 0.2316 - val_accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.2238 - val_accuracy: 0.9525\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9632 - val_loss: 0.1964 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.2163 - val_accuracy: 0.9602\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1251 - accuracy: 0.9695 - val_loss: 0.2522 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1057 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9582\n",
      "Epoch 12/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9736Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9735 - val_loss: 0.2083 - val_accuracy: 0.9547\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3759 - accuracy: 0.9077 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2073 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9456\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1678 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9632 - val_loss: 0.2180 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9644 - val_loss: 0.2449 - val_accuracy: 0.9484\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1274 - accuracy: 0.9684 - val_loss: 0.2191 - val_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9695Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1223 - accuracy: 0.9696 - val_loss: 0.2368 - val_accuracy: 0.9566\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3781 - accuracy: 0.9100 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9337\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1694 - accuracy: 0.9539 - val_loss: 0.1895 - val_accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1582 - accuracy: 0.9572 - val_loss: 0.2150 - val_accuracy: 0.9485\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.2038 - val_accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9649 - val_loss: 0.1998 - val_accuracy: 0.9561\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1304 - accuracy: 0.9660 - val_loss: 0.1811 - val_accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1851 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9693 - val_loss: 0.2541 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1102 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.1771 - val_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1854 - val_accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1979 - val_accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.2191 - val_accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9772Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.2106 - val_accuracy: 0.9654\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3951 - accuracy: 0.9054 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9386\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1544 - accuracy: 0.9592 - val_loss: 0.1821 - val_accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1391 - accuracy: 0.9630 - val_loss: 0.1648 - val_accuracy: 0.9588\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9648 - val_loss: 0.1903 - val_accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.2147 - val_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9693 - val_loss: 0.2290 - val_accuracy: 0.9529\n",
      "Epoch 11/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9704Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1162 - accuracy: 0.9702 - val_loss: 0.1979 - val_accuracy: 0.9557\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3963 - accuracy: 0.9036 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9472 - val_loss: 0.2252 - val_accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.1891 - val_accuracy: 0.9527\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1454 - accuracy: 0.9615 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
      "Epoch 6/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9660Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1322 - accuracy: 0.9658 - val_loss: 0.2101 - val_accuracy: 0.9513\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.8877 - val_loss: 0.2266 - val_accuracy: 0.9364\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2322 - accuracy: 0.9352 - val_loss: 0.2302 - val_accuracy: 0.9394\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9525 - val_loss: 0.2147 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9574 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1416 - accuracy: 0.9637 - val_loss: 0.2670 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1444 - accuracy: 0.9627 - val_loss: 0.2326 - val_accuracy: 0.9486\n",
      "Epoch 12/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9638Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1402 - accuracy: 0.9638 - val_loss: 0.2272 - val_accuracy: 0.9521\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4861 - accuracy: 0.8921 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 0.2093 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1900 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9466\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1774 - accuracy: 0.9521 - val_loss: 0.2082 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.1971 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1648 - accuracy: 0.9578 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.2186 - val_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 0.2569 - val_accuracy: 0.9448\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9646 - val_loss: 0.2178 - val_accuracy: 0.9484\n",
      "Epoch 11/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9647Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1381 - accuracy: 0.9647 - val_loss: 0.2034 - val_accuracy: 0.9543\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4744 - accuracy: 0.8952 - val_loss: 0.2387 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9379\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1931 - accuracy: 0.9472 - val_loss: 0.1842 - val_accuracy: 0.9498\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.2538 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1742 - accuracy: 0.9529 - val_loss: 0.2317 - val_accuracy: 0.9517\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.2327 - val_accuracy: 0.9496\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 0.2381 - val_accuracy: 0.9510\n",
      "Epoch 8/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9613Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1494 - accuracy: 0.9612 - val_loss: 0.1858 - val_accuracy: 0.9548\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5268 - accuracy: 0.8886 - val_loss: 0.2405 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.9300 - val_loss: 0.2778 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 0.2480 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2050 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1831 - accuracy: 0.9492 - val_loss: 0.2605 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9519 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1691 - accuracy: 0.9540 - val_loss: 0.2105 - val_accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.2721 - val_accuracy: 0.9365\n",
      "Epoch 9/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9580Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 0.2336 - val_accuracy: 0.9498\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4795 - accuracy: 0.8931 - val_loss: 0.2500 - val_accuracy: 0.9263\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2228 - accuracy: 0.9368 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9417\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.2290 - val_accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.2428 - val_accuracy: 0.9458\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1570 - accuracy: 0.9580 - val_loss: 0.2083 - val_accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.2158 - val_accuracy: 0.9545\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1295 - accuracy: 0.9654 - val_loss: 0.2430 - val_accuracy: 0.9488\n",
      "Epoch 13/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9662Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1268 - accuracy: 0.9662 - val_loss: 0.2338 - val_accuracy: 0.9445\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3752 - accuracy: 0.9087 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1985 - accuracy: 0.9447 - val_loss: 0.2436 - val_accuracy: 0.9388\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1734 - accuracy: 0.9528 - val_loss: 0.1856 - val_accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1553 - accuracy: 0.9593 - val_loss: 0.2109 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1431 - accuracy: 0.9628 - val_loss: 0.2013 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.2265 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9648 - val_loss: 0.1950 - val_accuracy: 0.9592\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1279 - accuracy: 0.9674 - val_loss: 0.2056 - val_accuracy: 0.9539\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3913 - accuracy: 0.9061 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9440 - val_loss: 0.2058 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1841 - accuracy: 0.9509 - val_loss: 0.2333 - val_accuracy: 0.9403\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9566 - val_loss: 0.2396 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1467 - accuracy: 0.9614 - val_loss: 0.2179 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1370 - accuracy: 0.9644 - val_loss: 0.1999 - val_accuracy: 0.9607\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.2109 - val_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9653 - val_loss: 0.1949 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9678 - val_loss: 0.2164 - val_accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 0.2091 - val_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9735 - val_loss: 0.2754 - val_accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9731 - val_loss: 0.2118 - val_accuracy: 0.9578\n",
      "Epoch 13/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0989 - accuracy: 0.9756 - val_loss: 0.2487 - val_accuracy: 0.9513\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.9059 - val_loss: 0.2252 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2030 - accuracy: 0.9443 - val_loss: 0.1705 - val_accuracy: 0.9509\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1751 - accuracy: 0.9536 - val_loss: 0.2058 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1607 - accuracy: 0.9554 - val_loss: 0.3140 - val_accuracy: 0.9336\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9622 - val_loss: 0.1823 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9654Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1338 - accuracy: 0.9653 - val_loss: 0.2558 - val_accuracy: 0.9501\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3985 - accuracy: 0.9040 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1927 - accuracy: 0.9462 - val_loss: 0.2652 - val_accuracy: 0.9259\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1802 - accuracy: 0.9522 - val_loss: 0.2011 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1605 - accuracy: 0.9574 - val_loss: 0.1911 - val_accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1499 - accuracy: 0.9604 - val_loss: 0.2031 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1384 - accuracy: 0.9643 - val_loss: 0.1863 - val_accuracy: 0.9602\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1294 - accuracy: 0.9666 - val_loss: 0.2084 - val_accuracy: 0.9560\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1217 - accuracy: 0.9693 - val_loss: 0.2252 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1211 - accuracy: 0.9695 - val_loss: 0.2089 - val_accuracy: 0.9577\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1112 - accuracy: 0.9729 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9740Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1082 - accuracy: 0.9740 - val_loss: 0.2194 - val_accuracy: 0.9580\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.4284 - accuracy: 0.9026 - val_loss: 0.2534 - val_accuracy: 0.9245\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2041 - accuracy: 0.9433 - val_loss: 0.2564 - val_accuracy: 0.9277\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1785 - accuracy: 0.9514 - val_loss: 0.1774 - val_accuracy: 0.9537\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9560 - val_loss: 0.1986 - val_accuracy: 0.9459\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1551 - accuracy: 0.9596 - val_loss: 0.2516 - val_accuracy: 0.9413\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1435 - accuracy: 0.9620 - val_loss: 0.2224 - val_accuracy: 0.9472\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2803 - val_accuracy: 0.9428\n",
      "Epoch 8/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9670Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1227 - accuracy: 0.9668 - val_loss: 0.2122 - val_accuracy: 0.9571\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4755 - accuracy: 0.8967 - val_loss: 0.2649 - val_accuracy: 0.9225\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2237 - accuracy: 0.9368 - val_loss: 0.2389 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1916 - accuracy: 0.9474 - val_loss: 0.2335 - val_accuracy: 0.9445\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1741 - accuracy: 0.9539 - val_loss: 0.1963 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9559 - val_loss: 0.2178 - val_accuracy: 0.9525\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1568 - accuracy: 0.9593 - val_loss: 0.2197 - val_accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2714 - val_accuracy: 0.9457\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1330 - accuracy: 0.9655 - val_loss: 0.1923 - val_accuracy: 0.9547\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1340 - accuracy: 0.9653 - val_loss: 0.2601 - val_accuracy: 0.9469\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1271 - accuracy: 0.9688 - val_loss: 0.2437 - val_accuracy: 0.9576\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1407 - accuracy: 0.9662 - val_loss: 0.2239 - val_accuracy: 0.9483\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1158 - accuracy: 0.9710 - val_loss: 0.2459 - val_accuracy: 0.9528\n",
      "Epoch 13/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9709Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1149 - accuracy: 0.9709 - val_loss: 0.2185 - val_accuracy: 0.9542\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4951 - accuracy: 0.8964 - val_loss: 0.2130 - val_accuracy: 0.9370\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9366 - val_loss: 0.2381 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9432 - val_loss: 0.2019 - val_accuracy: 0.9454\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1949 - accuracy: 0.9466 - val_loss: 0.2340 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2170 - val_accuracy: 0.9448\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9606 - val_loss: 0.2103 - val_accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9606Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1473 - accuracy: 0.9604 - val_loss: 0.2447 - val_accuracy: 0.9396\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4739 - accuracy: 0.8992 - val_loss: 0.2179 - val_accuracy: 0.9369\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2117 - accuracy: 0.9393 - val_loss: 0.1901 - val_accuracy: 0.9441\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9492 - val_loss: 0.1963 - val_accuracy: 0.9474\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1621 - accuracy: 0.9550 - val_loss: 0.2958 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1618 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1566 - accuracy: 0.9594 - val_loss: 0.1901 - val_accuracy: 0.9542\n",
      "Epoch 7/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9621Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9622 - val_loss: 0.2354 - val_accuracy: 0.9492\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4987 - accuracy: 0.8948 - val_loss: 0.2114 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2163 - accuracy: 0.9391 - val_loss: 0.2183 - val_accuracy: 0.9321\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9462 - val_loss: 0.2195 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1852 - accuracy: 0.9498 - val_loss: 0.2339 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9496\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1581 - accuracy: 0.9598 - val_loss: 0.2061 - val_accuracy: 0.9527\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1530 - accuracy: 0.9599 - val_loss: 0.2378 - val_accuracy: 0.9477\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1468 - accuracy: 0.9629 - val_loss: 0.1854 - val_accuracy: 0.9546\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1474 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9533\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1317 - accuracy: 0.9653 - val_loss: 0.2188 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1371 - accuracy: 0.9662 - val_loss: 0.2198 - val_accuracy: 0.9469\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1273 - accuracy: 0.9688 - val_loss: 0.2327 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9689Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1229 - accuracy: 0.9688 - val_loss: 0.2029 - val_accuracy: 0.9568\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4554 - accuracy: 0.8961 - val_loss: 0.2130 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.1963 - val_accuracy: 0.9405\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9482 - val_loss: 0.2119 - val_accuracy: 0.9438\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1906 - accuracy: 0.9483 - val_loss: 0.2231 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1635 - accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.9456\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1658 - accuracy: 0.9567 - val_loss: 0.2191 - val_accuracy: 0.9468\n",
      "Epoch 7/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9585Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1571 - accuracy: 0.9584 - val_loss: 0.2271 - val_accuracy: 0.9455\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3937 - accuracy: 0.9070 - val_loss: 0.2177 - val_accuracy: 0.9355\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9419\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9512 - val_loss: 0.2066 - val_accuracy: 0.9477\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1614 - accuracy: 0.9567 - val_loss: 0.1988 - val_accuracy: 0.9488\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9617 - val_loss: 0.2710 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2032 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.1894 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1168 - accuracy: 0.9695 - val_loss: 0.4487 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.2050 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.1925 - val_accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9762Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0985 - accuracy: 0.9761 - val_loss: 0.2213 - val_accuracy: 0.9613\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3933 - accuracy: 0.9054 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2034 - accuracy: 0.9422 - val_loss: 0.2575 - val_accuracy: 0.9344\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1845 - accuracy: 0.9493 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.2109 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1524 - accuracy: 0.9592 - val_loss: 0.2775 - val_accuracy: 0.9477\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9615Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9615 - val_loss: 0.2307 - val_accuracy: 0.9488\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3991 - accuracy: 0.9028 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9430 - val_loss: 0.2267 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1822 - accuracy: 0.9507 - val_loss: 0.1943 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1634 - accuracy: 0.9567 - val_loss: 0.2158 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1561 - accuracy: 0.9580 - val_loss: 0.2284 - val_accuracy: 0.9495\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1522 - accuracy: 0.9613 - val_loss: 0.2077 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1314 - accuracy: 0.9654 - val_loss: 0.1833 - val_accuracy: 0.9569\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1319 - accuracy: 0.9671 - val_loss: 0.1686 - val_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.2496 - val_accuracy: 0.9530\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.9679 - val_loss: 0.2077 - val_accuracy: 0.9553\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1187 - accuracy: 0.9717 - val_loss: 0.2272 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.9732 - val_loss: 0.2458 - val_accuracy: 0.9555\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1034 - accuracy: 0.9744 - val_loss: 0.2181 - val_accuracy: 0.9578\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3627 - accuracy: 0.9090 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.2003 - val_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1820 - accuracy: 0.9522 - val_loss: 0.2473 - val_accuracy: 0.9363\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.2016 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.9616 - val_loss: 0.2125 - val_accuracy: 0.9528\n",
      "Epoch 6/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9666Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1382 - accuracy: 0.9665 - val_loss: 0.2185 - val_accuracy: 0.9502\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.9054 - val_loss: 0.1936 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.2159 - val_accuracy: 0.9391\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1729 - accuracy: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9514\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1625 - accuracy: 0.9570 - val_loss: 0.1679 - val_accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9627 - val_loss: 0.1859 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1412 - accuracy: 0.9639 - val_loss: 0.1605 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9676 - val_loss: 0.2128 - val_accuracy: 0.9533\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9606\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1129 - accuracy: 0.9707 - val_loss: 0.1952 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1090 - accuracy: 0.9726 - val_loss: 0.1688 - val_accuracy: 0.9663\n",
      "Epoch 11/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9733Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1048 - accuracy: 0.9733 - val_loss: 0.2243 - val_accuracy: 0.9528\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4289 - accuracy: 0.8999 - val_loss: 0.2035 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2094 - val_accuracy: 0.9454\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2069 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1783 - accuracy: 0.9533 - val_loss: 0.2249 - val_accuracy: 0.9409\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.2078 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9593 - val_loss: 0.1989 - val_accuracy: 0.9553\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1446 - accuracy: 0.9615 - val_loss: 0.2191 - val_accuracy: 0.9573\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1383 - accuracy: 0.9641 - val_loss: 0.1778 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1376 - accuracy: 0.9643 - val_loss: 0.2693 - val_accuracy: 0.9467\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9672 - val_loss: 0.2325 - val_accuracy: 0.9538\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1280 - accuracy: 0.9683 - val_loss: 0.2571 - val_accuracy: 0.9516\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1241 - accuracy: 0.9682 - val_loss: 0.2569 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9677Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1310 - accuracy: 0.9677 - val_loss: 0.2859 - val_accuracy: 0.9499\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.8983 - val_loss: 0.2164 - val_accuracy: 0.9410\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2049 - val_accuracy: 0.9448\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1989 - accuracy: 0.9454 - val_loss: 0.2326 - val_accuracy: 0.9461\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1739 - accuracy: 0.9532 - val_loss: 0.1836 - val_accuracy: 0.9515\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1617 - accuracy: 0.9568 - val_loss: 0.2511 - val_accuracy: 0.9403\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1586 - accuracy: 0.9591 - val_loss: 0.1986 - val_accuracy: 0.9550\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1507 - accuracy: 0.9615 - val_loss: 0.2034 - val_accuracy: 0.9502\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9635 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 9/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9654Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1358 - accuracy: 0.9654 - val_loss: 0.2520 - val_accuracy: 0.9500\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.8970 - val_loss: 0.2229 - val_accuracy: 0.9380\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9386 - val_loss: 0.2267 - val_accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2015 - accuracy: 0.9461 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9492 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1711 - accuracy: 0.9539 - val_loss: 0.2259 - val_accuracy: 0.9470\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 0.2283 - val_accuracy: 0.9477\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.2462 - val_accuracy: 0.9493\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1610 - accuracy: 0.9605 - val_loss: 0.2542 - val_accuracy: 0.9519\n",
      "Epoch 9/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.1550 - accuracy: 0.9619Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1550 - accuracy: 0.9620 - val_loss: 0.2132 - val_accuracy: 0.9507\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4598 - accuracy: 0.8938 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2194 - accuracy: 0.9393 - val_loss: 0.2887 - val_accuracy: 0.9164\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.2388 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9495 - val_loss: 0.2109 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9544 - val_loss: 0.2328 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1585 - accuracy: 0.9580 - val_loss: 0.2461 - val_accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2425 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1477 - accuracy: 0.9618 - val_loss: 0.2390 - val_accuracy: 0.9465\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.9558\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9642 - val_loss: 0.2146 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.2260 - val_accuracy: 0.9493\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1419 - accuracy: 0.9636 - val_loss: 0.2670 - val_accuracy: 0.9467\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1381 - accuracy: 0.9658 - val_loss: 0.2825 - val_accuracy: 0.9456\n",
      "Epoch 14/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9687Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1230 - accuracy: 0.9687 - val_loss: 0.2258 - val_accuracy: 0.9527\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8960 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2221 - accuracy: 0.9376 - val_loss: 0.3008 - val_accuracy: 0.9144\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2056 - accuracy: 0.9445 - val_loss: 0.2407 - val_accuracy: 0.9362\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1894 - accuracy: 0.9482 - val_loss: 0.2061 - val_accuracy: 0.9486\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1672 - accuracy: 0.9549 - val_loss: 0.2203 - val_accuracy: 0.9424\n",
      "Epoch 6/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9556Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1719 - accuracy: 0.9556 - val_loss: 0.2441 - val_accuracy: 0.9422\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3890 - accuracy: 0.9042 - val_loss: 0.2238 - val_accuracy: 0.9371\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2065 - accuracy: 0.9428 - val_loss: 0.2160 - val_accuracy: 0.9434\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1854 - accuracy: 0.9490 - val_loss: 0.2030 - val_accuracy: 0.9491\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1631 - accuracy: 0.9560 - val_loss: 0.2051 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1496 - accuracy: 0.9608 - val_loss: 0.2316 - val_accuracy: 0.9510\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.2238 - val_accuracy: 0.9525\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1417 - accuracy: 0.9632 - val_loss: 0.1964 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1262 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1198 - accuracy: 0.9697 - val_loss: 0.2163 - val_accuracy: 0.9602\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1251 - accuracy: 0.9695 - val_loss: 0.2522 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1057 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9582\n",
      "Epoch 12/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9736Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9735 - val_loss: 0.2083 - val_accuracy: 0.9547\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3759 - accuracy: 0.9077 - val_loss: 0.2688 - val_accuracy: 0.9301\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2073 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9456\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1678 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9632 - val_loss: 0.2180 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1374 - accuracy: 0.9644 - val_loss: 0.2449 - val_accuracy: 0.9484\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1395 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1274 - accuracy: 0.9684 - val_loss: 0.2191 - val_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9696Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1223 - accuracy: 0.9696 - val_loss: 0.2368 - val_accuracy: 0.9566\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3781 - accuracy: 0.9100 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.2284 - val_accuracy: 0.9337\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1694 - accuracy: 0.9539 - val_loss: 0.1895 - val_accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1582 - accuracy: 0.9572 - val_loss: 0.2150 - val_accuracy: 0.9485\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1417 - accuracy: 0.9617 - val_loss: 0.2038 - val_accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9649 - val_loss: 0.1998 - val_accuracy: 0.9561\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1304 - accuracy: 0.9660 - val_loss: 0.1811 - val_accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1138 - accuracy: 0.9701 - val_loss: 0.1851 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9693 - val_loss: 0.2541 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1138 - accuracy: 0.9710 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1102 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9653\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.1771 - val_accuracy: 0.9641\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0981 - accuracy: 0.9753 - val_loss: 0.1854 - val_accuracy: 0.9631\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1979 - val_accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.2191 - val_accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9771Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.2106 - val_accuracy: 0.9654\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3951 - accuracy: 0.9054 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.2753 - val_accuracy: 0.9386\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1988 - val_accuracy: 0.9475\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1544 - accuracy: 0.9592 - val_loss: 0.1821 - val_accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1391 - accuracy: 0.9630 - val_loss: 0.1648 - val_accuracy: 0.9588\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1328 - accuracy: 0.9648 - val_loss: 0.1903 - val_accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2079 - val_accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.2147 - val_accuracy: 0.9501\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9693 - val_loss: 0.2290 - val_accuracy: 0.9529\n",
      "Epoch 11/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9702Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1162 - accuracy: 0.9702 - val_loss: 0.1979 - val_accuracy: 0.9557\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3963 - accuracy: 0.9036 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9472 - val_loss: 0.2252 - val_accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.1891 - val_accuracy: 0.9527\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.1858 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1454 - accuracy: 0.9615 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
      "Epoch 6/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.9659Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1322 - accuracy: 0.9658 - val_loss: 0.2101 - val_accuracy: 0.9513\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.8877 - val_loss: 0.2266 - val_accuracy: 0.9364\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2322 - accuracy: 0.9352 - val_loss: 0.2302 - val_accuracy: 0.9394\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 0.2335 - val_accuracy: 0.9442\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9525 - val_loss: 0.2147 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1591 - accuracy: 0.9574 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1416 - accuracy: 0.9637 - val_loss: 0.2670 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1444 - accuracy: 0.9627 - val_loss: 0.2326 - val_accuracy: 0.9486\n",
      "Epoch 12/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9638Restoring model weights from the end of the best epoch: 7.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1402 - accuracy: 0.9638 - val_loss: 0.2272 - val_accuracy: 0.9521\n",
      "Epoch 12: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4861 - accuracy: 0.8921 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 0.2093 - val_accuracy: 0.9437\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1900 - accuracy: 0.9482 - val_loss: 0.2115 - val_accuracy: 0.9466\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1774 - accuracy: 0.9521 - val_loss: 0.2082 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1603 - accuracy: 0.9577 - val_loss: 0.1971 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1648 - accuracy: 0.9578 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.2186 - val_accuracy: 0.9534\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1527 - accuracy: 0.9595 - val_loss: 0.2569 - val_accuracy: 0.9448\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1418 - accuracy: 0.9646 - val_loss: 0.2178 - val_accuracy: 0.9484\n",
      "Epoch 11/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9646Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9647 - val_loss: 0.2034 - val_accuracy: 0.9543\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.4744 - accuracy: 0.8952 - val_loss: 0.2387 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9367 - val_loss: 0.2321 - val_accuracy: 0.9379\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1931 - accuracy: 0.9472 - val_loss: 0.1842 - val_accuracy: 0.9498\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.2538 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1742 - accuracy: 0.9529 - val_loss: 0.2317 - val_accuracy: 0.9517\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.2327 - val_accuracy: 0.9496\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1517 - accuracy: 0.9602 - val_loss: 0.2381 - val_accuracy: 0.9510\n",
      "Epoch 8/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9613Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1494 - accuracy: 0.9612 - val_loss: 0.1858 - val_accuracy: 0.9548\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5268 - accuracy: 0.8886 - val_loss: 0.2405 - val_accuracy: 0.9306\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.9300 - val_loss: 0.2778 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 0.2480 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2050 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1831 - accuracy: 0.9492 - val_loss: 0.2605 - val_accuracy: 0.9362\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1786 - accuracy: 0.9519 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9540 - val_loss: 0.2105 - val_accuracy: 0.9461\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1763 - accuracy: 0.9527 - val_loss: 0.2721 - val_accuracy: 0.9365\n",
      "Epoch 9/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9580Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 0.2336 - val_accuracy: 0.9498\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4795 - accuracy: 0.8931 - val_loss: 0.2500 - val_accuracy: 0.9263\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2228 - accuracy: 0.9368 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1992 - accuracy: 0.9459 - val_loss: 0.2093 - val_accuracy: 0.9417\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1929 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1744 - accuracy: 0.9534 - val_loss: 0.2290 - val_accuracy: 0.9412\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.2428 - val_accuracy: 0.9458\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1570 - accuracy: 0.9580 - val_loss: 0.2083 - val_accuracy: 0.9482\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 0.1984 - val_accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9538\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1375 - accuracy: 0.9632 - val_loss: 0.2158 - val_accuracy: 0.9545\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1295 - accuracy: 0.9654 - val_loss: 0.2430 - val_accuracy: 0.9488\n",
      "Epoch 13/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9662Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1268 - accuracy: 0.9662 - val_loss: 0.2338 - val_accuracy: 0.9445\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3752 - accuracy: 0.9087 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1985 - accuracy: 0.9447 - val_loss: 0.2436 - val_accuracy: 0.9388\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1734 - accuracy: 0.9528 - val_loss: 0.1856 - val_accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1553 - accuracy: 0.9593 - val_loss: 0.2109 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1431 - accuracy: 0.9628 - val_loss: 0.2013 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.2265 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1381 - accuracy: 0.9648 - val_loss: 0.1950 - val_accuracy: 0.9592\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1279 - accuracy: 0.9674 - val_loss: 0.2056 - val_accuracy: 0.9539\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3913 - accuracy: 0.9061 - val_loss: 0.2120 - val_accuracy: 0.9406\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2025 - accuracy: 0.9440 - val_loss: 0.2058 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1841 - accuracy: 0.9509 - val_loss: 0.2333 - val_accuracy: 0.9403\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1636 - accuracy: 0.9566 - val_loss: 0.2396 - val_accuracy: 0.9458\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1467 - accuracy: 0.9614 - val_loss: 0.2179 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1370 - accuracy: 0.9644 - val_loss: 0.1999 - val_accuracy: 0.9607\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.2109 - val_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1374 - accuracy: 0.9653 - val_loss: 0.1949 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1329 - accuracy: 0.9678 - val_loss: 0.2164 - val_accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 0.2091 - val_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1100 - accuracy: 0.9735 - val_loss: 0.2754 - val_accuracy: 0.9514\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1136 - accuracy: 0.9731 - val_loss: 0.2118 - val_accuracy: 0.9578\n",
      "Epoch 13/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.0989 - accuracy: 0.9756 - val_loss: 0.2487 - val_accuracy: 0.9513\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.9059 - val_loss: 0.2252 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2030 - accuracy: 0.9443 - val_loss: 0.1705 - val_accuracy: 0.9509\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1751 - accuracy: 0.9536 - val_loss: 0.2058 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1607 - accuracy: 0.9554 - val_loss: 0.3140 - val_accuracy: 0.9336\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1512 - accuracy: 0.9593 - val_loss: 0.2131 - val_accuracy: 0.9561\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9622 - val_loss: 0.1823 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 0.1331 - accuracy: 0.9654Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1338 - accuracy: 0.9653 - val_loss: 0.2558 - val_accuracy: 0.9501\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3985 - accuracy: 0.9040 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1927 - accuracy: 0.9462 - val_loss: 0.2652 - val_accuracy: 0.9259\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1802 - accuracy: 0.9522 - val_loss: 0.2011 - val_accuracy: 0.9510\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1605 - accuracy: 0.9574 - val_loss: 0.1911 - val_accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1499 - accuracy: 0.9604 - val_loss: 0.2031 - val_accuracy: 0.9492\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1384 - accuracy: 0.9643 - val_loss: 0.1863 - val_accuracy: 0.9602\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1294 - accuracy: 0.9666 - val_loss: 0.2084 - val_accuracy: 0.9560\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1217 - accuracy: 0.9693 - val_loss: 0.2252 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1211 - accuracy: 0.9695 - val_loss: 0.2089 - val_accuracy: 0.9577\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1112 - accuracy: 0.9729 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9740Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1082 - accuracy: 0.9740 - val_loss: 0.2194 - val_accuracy: 0.9580\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4284 - accuracy: 0.9026 - val_loss: 0.2534 - val_accuracy: 0.9245\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2041 - accuracy: 0.9433 - val_loss: 0.2564 - val_accuracy: 0.9277\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1785 - accuracy: 0.9514 - val_loss: 0.1774 - val_accuracy: 0.9537\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1666 - accuracy: 0.9560 - val_loss: 0.1986 - val_accuracy: 0.9459\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1551 - accuracy: 0.9596 - val_loss: 0.2516 - val_accuracy: 0.9413\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1435 - accuracy: 0.9620 - val_loss: 0.2224 - val_accuracy: 0.9472\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1344 - accuracy: 0.9651 - val_loss: 0.2803 - val_accuracy: 0.9428\n",
      "Epoch 8/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9668Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1227 - accuracy: 0.9668 - val_loss: 0.2122 - val_accuracy: 0.9571\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4755 - accuracy: 0.8967 - val_loss: 0.2649 - val_accuracy: 0.9225\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2237 - accuracy: 0.9368 - val_loss: 0.2389 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1916 - accuracy: 0.9474 - val_loss: 0.2335 - val_accuracy: 0.9445\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1741 - accuracy: 0.9539 - val_loss: 0.1963 - val_accuracy: 0.9490\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9559 - val_loss: 0.2178 - val_accuracy: 0.9525\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1568 - accuracy: 0.9593 - val_loss: 0.2197 - val_accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2714 - val_accuracy: 0.9457\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1330 - accuracy: 0.9655 - val_loss: 0.1923 - val_accuracy: 0.9547\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1340 - accuracy: 0.9653 - val_loss: 0.2601 - val_accuracy: 0.9469\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1271 - accuracy: 0.9688 - val_loss: 0.2437 - val_accuracy: 0.9576\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1407 - accuracy: 0.9662 - val_loss: 0.2239 - val_accuracy: 0.9483\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1158 - accuracy: 0.9710 - val_loss: 0.2459 - val_accuracy: 0.9528\n",
      "Epoch 13/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9711Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9709 - val_loss: 0.2185 - val_accuracy: 0.9542\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4951 - accuracy: 0.8964 - val_loss: 0.2130 - val_accuracy: 0.9370\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9366 - val_loss: 0.2381 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2011 - accuracy: 0.9432 - val_loss: 0.2019 - val_accuracy: 0.9454\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1949 - accuracy: 0.9466 - val_loss: 0.2340 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1698 - accuracy: 0.9538 - val_loss: 0.2170 - val_accuracy: 0.9448\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.2199 - val_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 0.1504 - accuracy: 0.9606 - val_loss: 0.2103 - val_accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9604Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1473 - accuracy: 0.9604 - val_loss: 0.2447 - val_accuracy: 0.9396\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4739 - accuracy: 0.8992 - val_loss: 0.2179 - val_accuracy: 0.9369\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2117 - accuracy: 0.9393 - val_loss: 0.1901 - val_accuracy: 0.9441\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9492 - val_loss: 0.1963 - val_accuracy: 0.9474\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1621 - accuracy: 0.9550 - val_loss: 0.2958 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1618 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9471\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1566 - accuracy: 0.9594 - val_loss: 0.1901 - val_accuracy: 0.9542\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.9622Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1460 - accuracy: 0.9622 - val_loss: 0.2354 - val_accuracy: 0.9492\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.4987 - accuracy: 0.8948 - val_loss: 0.2114 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2163 - accuracy: 0.9391 - val_loss: 0.2183 - val_accuracy: 0.9321\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1950 - accuracy: 0.9462 - val_loss: 0.2195 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1852 - accuracy: 0.9498 - val_loss: 0.2339 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1673 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9496\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1581 - accuracy: 0.9598 - val_loss: 0.2061 - val_accuracy: 0.9527\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1530 - accuracy: 0.9599 - val_loss: 0.2378 - val_accuracy: 0.9477\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1468 - accuracy: 0.9629 - val_loss: 0.1854 - val_accuracy: 0.9546\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1474 - accuracy: 0.9635 - val_loss: 0.1981 - val_accuracy: 0.9533\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1317 - accuracy: 0.9653 - val_loss: 0.2188 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1371 - accuracy: 0.9662 - val_loss: 0.2198 - val_accuracy: 0.9469\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1273 - accuracy: 0.9688 - val_loss: 0.2327 - val_accuracy: 0.9502\n",
      "Epoch 13/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9689Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1229 - accuracy: 0.9688 - val_loss: 0.2029 - val_accuracy: 0.9568\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 0.4554 - accuracy: 0.8961 - val_loss: 0.2130 - val_accuracy: 0.9408\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.1963 - val_accuracy: 0.9405\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9482 - val_loss: 0.2119 - val_accuracy: 0.9438\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1906 - accuracy: 0.9483 - val_loss: 0.2231 - val_accuracy: 0.9427\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1635 - accuracy: 0.9562 - val_loss: 0.2225 - val_accuracy: 0.9456\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1658 - accuracy: 0.9567 - val_loss: 0.2191 - val_accuracy: 0.9468\n",
      "Epoch 7/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9584Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.1571 - accuracy: 0.9584 - val_loss: 0.2271 - val_accuracy: 0.9455\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 3.9449 - accuracy: 0.1046 - val_loss: 2.3266 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1023 - val_loss: 2.3123 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1001 - val_loss: 2.3041 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1045 - val_loss: 2.3140 - val_accuracy: 0.0967\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3129 - accuracy: 0.1022 - val_loss: 2.3215 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3099 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3150 - accuracy: 0.1029 - val_loss: 2.3206 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 2.3148 - accuracy: 0.1024Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1023 - val_loss: 2.3183 - val_accuracy: 0.0979\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9674 - accuracy: 0.1047 - val_loss: 2.3260 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1039 - val_loss: 2.3117 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1021 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3170 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9959 - accuracy: 0.1019 - val_loss: 2.3143 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3072 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3148 - accuracy: 0.1017 - val_loss: 2.3152 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1042 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3138 - accuracy: 0.1029 - val_loss: 2.3132 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1026 - val_loss: 2.3141 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1002 - val_loss: 2.3118 - val_accuracy: 0.0978\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1019 - val_loss: 2.3046 - val_accuracy: 0.0995\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1022 - val_loss: 2.3169 - val_accuracy: 0.0978\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1044 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.3136 - accuracy: 0.1048Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3097 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8659 - accuracy: 0.1791 - val_loss: 2.0135 - val_accuracy: 0.2009\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0060 - accuracy: 0.2053 - val_loss: 1.9964 - val_accuracy: 0.2052\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0064 - accuracy: 0.2071 - val_loss: 2.0181 - val_accuracy: 0.2034\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1047 - accuracy: 0.1793 - val_loss: 2.3109 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1031 - val_loss: 2.3091 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3141 - accuracy: 0.1014 - val_loss: 2.3170 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1024Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1024 - val_loss: 2.3188 - val_accuracy: 0.0920\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9759 - accuracy: 0.1911 - val_loss: 2.0848 - val_accuracy: 0.2044\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0529 - accuracy: 0.2068 - val_loss: 2.0623 - val_accuracy: 0.2042\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0733 - accuracy: 0.2015 - val_loss: 2.0538 - val_accuracy: 0.2009\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0909 - accuracy: 0.2024 - val_loss: 2.1011 - val_accuracy: 0.2047\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0716 - accuracy: 0.1993 - val_loss: 2.0792 - val_accuracy: 0.1905\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0668 - accuracy: 0.2039 - val_loss: 2.0714 - val_accuracy: 0.2012\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0629 - accuracy: 0.2005 - val_loss: 2.0759 - val_accuracy: 0.1953\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0433 - accuracy: 0.2058 - val_loss: 2.0430 - val_accuracy: 0.1978\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0410 - accuracy: 0.2051 - val_loss: 2.0384 - val_accuracy: 0.2023\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0407 - accuracy: 0.2076 - val_loss: 2.0646 - val_accuracy: 0.2018\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0424 - accuracy: 0.2030 - val_loss: 2.0348 - val_accuracy: 0.2032\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0428 - accuracy: 0.2021 - val_loss: 2.0411 - val_accuracy: 0.2019\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0424 - accuracy: 0.2046 - val_loss: 2.0483 - val_accuracy: 0.2050\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0434 - accuracy: 0.2021 - val_loss: 2.0586 - val_accuracy: 0.2050\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0422 - accuracy: 0.2063 - val_loss: 2.0472 - val_accuracy: 0.2102\n",
      "Epoch 16/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 2.0430 - accuracy: 0.2048Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0429 - accuracy: 0.2051 - val_loss: 2.0472 - val_accuracy: 0.1978\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0321 - accuracy: 0.3419 - val_loss: 1.4987 - val_accuracy: 0.4034\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8481 - accuracy: 0.2524 - val_loss: 2.0075 - val_accuracy: 0.1774\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9382 - accuracy: 0.1855 - val_loss: 1.9471 - val_accuracy: 0.1867\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9573 - accuracy: 0.1827 - val_loss: 2.0565 - val_accuracy: 0.1787\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9675 - accuracy: 0.1895 - val_loss: 2.0946 - val_accuracy: 0.1880\n",
      "Epoch 6/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 2.0269 - accuracy: 0.1889Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0280 - accuracy: 0.1886 - val_loss: 2.2018 - val_accuracy: 0.1639\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.7269 - accuracy: 0.2225 - val_loss: 1.9766 - val_accuracy: 0.1830\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9827 - accuracy: 0.1851 - val_loss: 2.1262 - val_accuracy: 0.1677\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9581 - accuracy: 0.1840 - val_loss: 1.9530 - val_accuracy: 0.1965\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.9487 - accuracy: 0.1890 - val_loss: 1.9111 - val_accuracy: 0.1888\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9584 - accuracy: 0.1871 - val_loss: 1.8872 - val_accuracy: 0.2011\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9749 - accuracy: 0.1886 - val_loss: 1.8795 - val_accuracy: 0.2069\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9626 - accuracy: 0.1888 - val_loss: 1.9325 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9165 - accuracy: 0.1991 - val_loss: 1.9410 - val_accuracy: 0.1822\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9356 - accuracy: 0.1961 - val_loss: 1.9695 - val_accuracy: 0.1822\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9191 - accuracy: 0.1976 - val_loss: 1.9002 - val_accuracy: 0.1887\n",
      "Epoch 11/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 1.9816 - accuracy: 0.1885Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9813 - accuracy: 0.1882 - val_loss: 1.9729 - val_accuracy: 0.1789\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3696 - accuracy: 0.1052 - val_loss: 2.3141 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1011 - val_loss: 2.3067 - val_accuracy: 0.1103\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1017 - val_loss: 2.3148 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1042 - val_loss: 2.3061 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1029 - val_loss: 2.3125 - val_accuracy: 0.0981\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1026 - val_loss: 2.3136 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1001 - val_loss: 2.3113 - val_accuracy: 0.0981\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1020 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1025 - val_loss: 2.3158 - val_accuracy: 0.0983\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1043 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 2.3136 - accuracy: 0.1045Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3098 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5253 - accuracy: 0.1229 - val_loss: 1.9377 - val_accuracy: 0.2433\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8275 - accuracy: 0.2541 - val_loss: 1.7676 - val_accuracy: 0.2763\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7911 - accuracy: 0.2545 - val_loss: 1.7516 - val_accuracy: 0.2780\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7845 - accuracy: 0.2597 - val_loss: 1.7529 - val_accuracy: 0.2589\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.7745 - accuracy: 0.2618 - val_loss: 1.7667 - val_accuracy: 0.2639\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.7911 - accuracy: 0.2540 - val_loss: 1.7382 - val_accuracy: 0.2952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7795 - accuracy: 0.2591 - val_loss: 1.8752 - val_accuracy: 0.2148\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7794 - accuracy: 0.2596 - val_loss: 1.7822 - val_accuracy: 0.2381\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7973 - accuracy: 0.2561 - val_loss: 1.7798 - val_accuracy: 0.2520\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7740 - accuracy: 0.2630 - val_loss: 1.7762 - val_accuracy: 0.2670\n",
      "Epoch 11/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 1.8001 - accuracy: 0.2517Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.8001 - accuracy: 0.2514 - val_loss: 1.8390 - val_accuracy: 0.2349\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.5624 - accuracy: 0.1870 - val_loss: 2.3174 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3118 - val_accuracy: 0.0920\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1011 - val_loss: 2.3105 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1017 - val_loss: 2.3113 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3081 - val_accuracy: 0.1102\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3128 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3074 - val_accuracy: 0.1082\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3226 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3053 - val_accuracy: 0.1102\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3100 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3125 - val_accuracy: 0.1016\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3198 - val_accuracy: 0.1016\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3105 - val_accuracy: 0.1082\n",
      "Epoch 16/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 2.3137 - accuracy: 0.1005Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3122 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 4.0827 - accuracy: 0.2002 - val_loss: 2.0447 - val_accuracy: 0.1999\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0237 - accuracy: 0.2017 - val_loss: 2.0124 - val_accuracy: 0.2048\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0307 - accuracy: 0.1988 - val_loss: 1.9897 - val_accuracy: 0.2138\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0047 - accuracy: 0.2090 - val_loss: 2.0142 - val_accuracy: 0.2001\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1005 - accuracy: 0.1809 - val_loss: 2.3240 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3150 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1030 - val_loss: 2.3226 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 2.3148 - accuracy: 0.1025Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1024 - val_loss: 2.3203 - val_accuracy: 0.0978\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9379 - accuracy: 0.2077 - val_loss: 2.0524 - val_accuracy: 0.2037\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2196 - accuracy: 0.1426 - val_loss: 2.3119 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3154 - accuracy: 0.1020 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 2.3132 - accuracy: 0.1029Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1030 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.1311 - accuracy: 0.1194 - val_loss: 2.0675 - val_accuracy: 0.1819\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0657 - accuracy: 0.1906 - val_loss: 2.0310 - val_accuracy: 0.2023\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0589 - accuracy: 0.1916 - val_loss: 2.3166 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3140 - accuracy: 0.1028 - val_loss: 2.3070 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3138 - accuracy: 0.1030 - val_loss: 2.3139 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1027 - val_loss: 2.3147 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.3149 - accuracy: 0.1003Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1003 - val_loss: 2.3125 - val_accuracy: 0.0978\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8207 - accuracy: 0.3784 - val_loss: 1.7321 - val_accuracy: 0.3289\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7394 - accuracy: 0.3252 - val_loss: 1.7514 - val_accuracy: 0.3167\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8234 - accuracy: 0.2900 - val_loss: 2.0469 - val_accuracy: 0.2038\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8708 - accuracy: 0.2572 - val_loss: 1.9972 - val_accuracy: 0.2066\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9968 - accuracy: 0.1957 - val_loss: 2.0276 - val_accuracy: 0.1754\n",
      "Epoch 6/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 1.9853 - accuracy: 0.1971Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9855 - accuracy: 0.1970 - val_loss: 2.0659 - val_accuracy: 0.1947\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 4.8139 - accuracy: 0.1633 - val_loss: 2.3086 - val_accuracy: 0.1019\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3126 - accuracy: 0.1323 - val_loss: 2.1684 - val_accuracy: 0.1546\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9926 - accuracy: 0.2362 - val_loss: 1.8754 - val_accuracy: 0.2826\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9731 - accuracy: 0.2675 - val_loss: 1.8808 - val_accuracy: 0.2829\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8282 - accuracy: 0.3005 - val_loss: 1.7420 - val_accuracy: 0.3512\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7215 - accuracy: 0.3159 - val_loss: 1.6269 - val_accuracy: 0.3447\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7034 - accuracy: 0.3083 - val_loss: 2.0062 - val_accuracy: 0.2105\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6709 - accuracy: 0.3202 - val_loss: 1.8166 - val_accuracy: 0.2817\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6604 - accuracy: 0.3230 - val_loss: 1.6822 - val_accuracy: 0.3155\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6403 - accuracy: 0.3285 - val_loss: 1.6392 - val_accuracy: 0.3460\n",
      "Epoch 11/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 1.6233 - accuracy: 0.3393Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6229 - accuracy: 0.3392 - val_loss: 1.6909 - val_accuracy: 0.3278\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.3950 - accuracy: 0.1903 - val_loss: 1.8219 - val_accuracy: 0.2764\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7666 - accuracy: 0.2810 - val_loss: 1.8358 - val_accuracy: 0.2356\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6969 - accuracy: 0.3081 - val_loss: 1.7275 - val_accuracy: 0.3027\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6887 - accuracy: 0.3137 - val_loss: 1.6389 - val_accuracy: 0.3437\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6789 - accuracy: 0.3137 - val_loss: 1.6259 - val_accuracy: 0.3549\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6913 - accuracy: 0.3088 - val_loss: 1.7114 - val_accuracy: 0.2925\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6849 - accuracy: 0.3115 - val_loss: 1.8652 - val_accuracy: 0.2158\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7010 - accuracy: 0.3022 - val_loss: 1.7110 - val_accuracy: 0.2968\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6961 - accuracy: 0.3063 - val_loss: 1.7608 - val_accuracy: 0.2792\n",
      "Epoch 10/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 1.6996 - accuracy: 0.3012Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7004 - accuracy: 0.3006 - val_loss: 1.6640 - val_accuracy: 0.3163\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 4.5883 - accuracy: 0.1083 - val_loss: 2.3258 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3266 - accuracy: 0.1041 - val_loss: 2.3115 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1018 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3127 - accuracy: 0.1066 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.6486 - accuracy: 0.1891 - val_loss: 2.0432 - val_accuracy: 0.2007\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0146 - accuracy: 0.2042 - val_loss: 1.9918 - val_accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0061 - accuracy: 0.2052 - val_loss: 2.0073 - val_accuracy: 0.2125\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0076 - accuracy: 0.2084 - val_loss: 1.9957 - val_accuracy: 0.2132\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0095 - accuracy: 0.2070 - val_loss: 2.0151 - val_accuracy: 0.2001\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0166 - accuracy: 0.2031 - val_loss: 2.1239 - val_accuracy: 0.2142\n",
      "Epoch 7/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 2.0300 - accuracy: 0.2008Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0300 - accuracy: 0.2008 - val_loss: 2.0242 - val_accuracy: 0.1905\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.7907 - accuracy: 0.1976 - val_loss: 2.0010 - val_accuracy: 0.1861\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0666 - accuracy: 0.1931 - val_loss: 1.9935 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9816 - accuracy: 0.1950 - val_loss: 1.9394 - val_accuracy: 0.2033\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9358 - accuracy: 0.1954 - val_loss: 1.9304 - val_accuracy: 0.1867\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9630 - accuracy: 0.1968 - val_loss: 1.9025 - val_accuracy: 0.1898\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9271 - accuracy: 0.1861 - val_loss: 1.9151 - val_accuracy: 0.2008\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9313 - accuracy: 0.1848 - val_loss: 2.1049 - val_accuracy: 0.1588\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0704 - accuracy: 0.1688 - val_loss: 1.9173 - val_accuracy: 0.1895\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9306 - accuracy: 0.1857 - val_loss: 1.9913 - val_accuracy: 0.1844\n",
      "Epoch 10/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 1.9422 - accuracy: 0.1844Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9420 - accuracy: 0.1844 - val_loss: 1.9286 - val_accuracy: 0.1842\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 5.5395 - accuracy: 0.1041 - val_loss: 2.3161 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3134 - accuracy: 0.1032 - val_loss: 2.3123 - val_accuracy: 0.0921\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3111 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1020 - val_loss: 2.3119 - val_accuracy: 0.1017\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3087 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3229 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3134 - val_accuracy: 0.0996\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3089 - val_accuracy: 0.1103\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3080 - val_accuracy: 0.1083\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3232 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3059 - val_accuracy: 0.1103\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3131 - val_accuracy: 0.1017\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3204 - val_accuracy: 0.1017\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3111 - val_accuracy: 0.1083\n",
      "Epoch 16/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1003Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3128 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.4064 - accuracy: 0.1639 - val_loss: 2.0403 - val_accuracy: 0.1985\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0210 - accuracy: 0.2018 - val_loss: 2.0089 - val_accuracy: 0.2057\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0123 - accuracy: 0.2032 - val_loss: 2.0115 - val_accuracy: 0.2088\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0089 - accuracy: 0.2093 - val_loss: 2.0474 - val_accuracy: 0.2006\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0047 - accuracy: 0.2059 - val_loss: 2.0302 - val_accuracy: 0.2023\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0191 - accuracy: 0.2023 - val_loss: 2.0215 - val_accuracy: 0.1992\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.0278 - accuracy: 0.2026Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0278 - accuracy: 0.2026 - val_loss: 2.0147 - val_accuracy: 0.2007\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.5135 - accuracy: 0.1870 - val_loss: 2.5136 - val_accuracy: 0.2005\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0570 - accuracy: 0.1968 - val_loss: 2.0125 - val_accuracy: 0.2040\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0109 - accuracy: 0.2056 - val_loss: 1.9939 - val_accuracy: 0.2132\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9956 - accuracy: 0.2103 - val_loss: 1.9912 - val_accuracy: 0.2233\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0115 - accuracy: 0.2085 - val_loss: 2.0192 - val_accuracy: 0.2070\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0117 - accuracy: 0.2070 - val_loss: 2.0075 - val_accuracy: 0.2113\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0153 - accuracy: 0.2078 - val_loss: 2.0239 - val_accuracy: 0.1943\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0108 - accuracy: 0.2063 - val_loss: 2.0449 - val_accuracy: 0.1972\n",
      "Epoch 9/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 2.2094 - accuracy: 0.1450Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2103 - accuracy: 0.1445 - val_loss: 2.3181 - val_accuracy: 0.0978\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.3511 - accuracy: 0.2167 - val_loss: 1.8078 - val_accuracy: 0.2510\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8392 - accuracy: 0.2537 - val_loss: 2.0643 - val_accuracy: 0.2649\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9743 - accuracy: 0.2144 - val_loss: 2.1184 - val_accuracy: 0.1778\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9591 - accuracy: 0.1921 - val_loss: 1.9318 - val_accuracy: 0.1830\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9092 - accuracy: 0.1969 - val_loss: 1.9062 - val_accuracy: 0.2025\n",
      "Epoch 6/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 1.9137 - accuracy: 0.1929Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9133 - accuracy: 0.1927 - val_loss: 1.9054 - val_accuracy: 0.2053\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.6431 - accuracy: 0.2014 - val_loss: 2.0151 - val_accuracy: 0.2018\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0058 - accuracy: 0.2056 - val_loss: 2.0162 - val_accuracy: 0.2064\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9928 - accuracy: 0.2080 - val_loss: 1.9990 - val_accuracy: 0.2054\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9980 - accuracy: 0.2079 - val_loss: 2.0138 - val_accuracy: 0.2142\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0082 - accuracy: 0.2058 - val_loss: 2.0611 - val_accuracy: 0.2041\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0047 - accuracy: 0.2041 - val_loss: 2.0518 - val_accuracy: 0.2139\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1823 - accuracy: 0.1558 - val_loss: 2.8593 - val_accuracy: 0.1652\n",
      "Epoch 8/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 2.0983 - accuracy: 0.1858Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0971 - accuracy: 0.1863 - val_loss: 2.0269 - val_accuracy: 0.2007\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.1771 - accuracy: 0.1689 - val_loss: 2.0649 - val_accuracy: 0.1941\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0678 - accuracy: 0.1950 - val_loss: 2.0425 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0431 - accuracy: 0.2011 - val_loss: 2.0353 - val_accuracy: 0.1957\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1025 - accuracy: 0.1811 - val_loss: 2.3132 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1025 - val_loss: 2.3082 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3152 - accuracy: 0.1009 - val_loss: 2.3127 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 2.3133 - accuracy: 0.1027Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1029 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 5.7086 - accuracy: 0.2188 - val_loss: 1.9572 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8685 - accuracy: 0.2613 - val_loss: 1.7151 - val_accuracy: 0.3244\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.8747 - accuracy: 0.2660 - val_loss: 1.9195 - val_accuracy: 0.1790\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9888 - accuracy: 0.1872 - val_loss: 1.9455 - val_accuracy: 0.2050\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9157 - accuracy: 0.1956 - val_loss: 1.8756 - val_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8993 - accuracy: 0.1909 - val_loss: 1.8870 - val_accuracy: 0.1910\n",
      "Epoch 7/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 1.9106 - accuracy: 0.1948Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9098 - accuracy: 0.1946 - val_loss: 1.8653 - val_accuracy: 0.1917\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.8365 - accuracy: 0.1752 - val_loss: 2.0623 - val_accuracy: 0.1775\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0252 - accuracy: 0.1853 - val_loss: 2.0176 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0775 - accuracy: 0.1762 - val_loss: 1.9810 - val_accuracy: 0.2003\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0357 - accuracy: 0.1805 - val_loss: 2.0148 - val_accuracy: 0.1921\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9998 - accuracy: 0.1891 - val_loss: 1.9721 - val_accuracy: 0.1851\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9814 - accuracy: 0.1897 - val_loss: 1.9604 - val_accuracy: 0.1970\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9870 - accuracy: 0.1893 - val_loss: 2.0274 - val_accuracy: 0.1691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9607 - accuracy: 0.1895 - val_loss: 2.0739 - val_accuracy: 0.1615\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9657 - accuracy: 0.1914 - val_loss: 1.9493 - val_accuracy: 0.1988\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9316 - accuracy: 0.1891 - val_loss: 1.9634 - val_accuracy: 0.1856\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9402 - accuracy: 0.1896 - val_loss: 2.0579 - val_accuracy: 0.1801\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9771 - accuracy: 0.1841 - val_loss: 2.0527 - val_accuracy: 0.1839\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9487 - accuracy: 0.1874 - val_loss: 1.9899 - val_accuracy: 0.1840\n",
      "Epoch 14/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 2.0162 - accuracy: 0.1858Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0167 - accuracy: 0.1858 - val_loss: 2.1021 - val_accuracy: 0.1815\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.8345 - accuracy: 0.1710 - val_loss: 2.2283 - val_accuracy: 0.1992\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0093 - accuracy: 0.2102 - val_loss: 1.9447 - val_accuracy: 0.2041\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9476 - accuracy: 0.1923 - val_loss: 1.9043 - val_accuracy: 0.1960\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9287 - accuracy: 0.1897 - val_loss: 1.9263 - val_accuracy: 0.1930\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9438 - accuracy: 0.1912 - val_loss: 1.8839 - val_accuracy: 0.1968\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8972 - accuracy: 0.1858 - val_loss: 1.8643 - val_accuracy: 0.1952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9116 - accuracy: 0.1873 - val_loss: 1.9431 - val_accuracy: 0.1813\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9319 - accuracy: 0.1884 - val_loss: 1.8880 - val_accuracy: 0.1943\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8979 - accuracy: 0.1915 - val_loss: 1.9380 - val_accuracy: 0.1867\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8907 - accuracy: 0.1932 - val_loss: 1.9199 - val_accuracy: 0.1945\n",
      "Epoch 11/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.1364 - accuracy: 0.1872Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1359 - accuracy: 0.1873 - val_loss: 2.0936 - val_accuracy: 0.1871\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8422 - accuracy: 0.2063 - val_loss: 1.8672 - val_accuracy: 0.1883\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9205 - accuracy: 0.1900 - val_loss: 2.3110 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1048 - val_loss: 2.3163 - val_accuracy: 0.1083\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3127 - accuracy: 0.1042 - val_loss: 2.3053 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1808 - accuracy: 0.1513 - val_loss: 2.0966 - val_accuracy: 0.2004\n",
      "Epoch 6/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 2.0407 - accuracy: 0.1873Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0420 - accuracy: 0.1874 - val_loss: 2.1843 - val_accuracy: 0.1852\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7303 - accuracy: 0.2774 - val_loss: 2.0490 - val_accuracy: 0.2111\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9522 - accuracy: 0.2672 - val_loss: 1.6941 - val_accuracy: 0.2939\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8989 - accuracy: 0.2725 - val_loss: 1.7249 - val_accuracy: 0.2927\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9825 - accuracy: 0.2173 - val_loss: 1.9297 - val_accuracy: 0.1959\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9757 - accuracy: 0.1931 - val_loss: 1.9397 - val_accuracy: 0.2144\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9405 - accuracy: 0.1958 - val_loss: 1.9242 - val_accuracy: 0.1773\n",
      "Epoch 7/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 1.9190 - accuracy: 0.1966Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9192 - accuracy: 0.1966 - val_loss: 1.9237 - val_accuracy: 0.1772\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9449 - accuracy: 0.1046 - val_loss: 2.3266 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1023 - val_loss: 2.3123 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1001 - val_loss: 2.3041 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1045 - val_loss: 2.3140 - val_accuracy: 0.0967\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3129 - accuracy: 0.1022 - val_loss: 2.3215 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3099 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3150 - accuracy: 0.1029 - val_loss: 2.3206 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 2.3147 - accuracy: 0.1026Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1023 - val_loss: 2.3183 - val_accuracy: 0.0979\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9674 - accuracy: 0.1047 - val_loss: 2.3260 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1039 - val_loss: 2.3117 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1021 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3170 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9959 - accuracy: 0.1019 - val_loss: 2.3143 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3072 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3148 - accuracy: 0.1017 - val_loss: 2.3152 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1042 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3138 - accuracy: 0.1029 - val_loss: 2.3132 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1026 - val_loss: 2.3141 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1002 - val_loss: 2.3118 - val_accuracy: 0.0978\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1019 - val_loss: 2.3046 - val_accuracy: 0.0995\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1022 - val_loss: 2.3169 - val_accuracy: 0.0978\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1044 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 2.3136 - accuracy: 0.1048Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3097 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.8659 - accuracy: 0.1791 - val_loss: 2.0135 - val_accuracy: 0.2009\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0060 - accuracy: 0.2053 - val_loss: 1.9964 - val_accuracy: 0.2052\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0064 - accuracy: 0.2071 - val_loss: 2.0181 - val_accuracy: 0.2034\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1047 - accuracy: 0.1793 - val_loss: 2.3109 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1031 - val_loss: 2.3091 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3141 - accuracy: 0.1014 - val_loss: 2.3170 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1024Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1024 - val_loss: 2.3188 - val_accuracy: 0.0920\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.9759 - accuracy: 0.1911 - val_loss: 2.0848 - val_accuracy: 0.2044\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0529 - accuracy: 0.2068 - val_loss: 2.0623 - val_accuracy: 0.2042\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0733 - accuracy: 0.2015 - val_loss: 2.0538 - val_accuracy: 0.2009\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0909 - accuracy: 0.2024 - val_loss: 2.1011 - val_accuracy: 0.2047\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0716 - accuracy: 0.1993 - val_loss: 2.0792 - val_accuracy: 0.1905\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0668 - accuracy: 0.2039 - val_loss: 2.0714 - val_accuracy: 0.2012\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0629 - accuracy: 0.2005 - val_loss: 2.0759 - val_accuracy: 0.1953\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0433 - accuracy: 0.2058 - val_loss: 2.0430 - val_accuracy: 0.1978\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0410 - accuracy: 0.2051 - val_loss: 2.0384 - val_accuracy: 0.2023\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0407 - accuracy: 0.2076 - val_loss: 2.0646 - val_accuracy: 0.2018\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0424 - accuracy: 0.2030 - val_loss: 2.0348 - val_accuracy: 0.2032\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0428 - accuracy: 0.2021 - val_loss: 2.0411 - val_accuracy: 0.2019\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0424 - accuracy: 0.2046 - val_loss: 2.0483 - val_accuracy: 0.2050\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0434 - accuracy: 0.2021 - val_loss: 2.0586 - val_accuracy: 0.2050\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0422 - accuracy: 0.2063 - val_loss: 2.0472 - val_accuracy: 0.2102\n",
      "Epoch 16/20\n",
      "1186/1200 [============================>.] - ETA: 0s - loss: 2.0432 - accuracy: 0.2048Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0429 - accuracy: 0.2051 - val_loss: 2.0472 - val_accuracy: 0.1978\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 4.0321 - accuracy: 0.3419 - val_loss: 1.4987 - val_accuracy: 0.4034\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8481 - accuracy: 0.2524 - val_loss: 2.0075 - val_accuracy: 0.1774\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9382 - accuracy: 0.1855 - val_loss: 1.9471 - val_accuracy: 0.1867\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9573 - accuracy: 0.1827 - val_loss: 2.0565 - val_accuracy: 0.1787\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9675 - accuracy: 0.1895 - val_loss: 2.0946 - val_accuracy: 0.1880\n",
      "Epoch 6/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 2.0279 - accuracy: 0.1885Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0280 - accuracy: 0.1886 - val_loss: 2.2018 - val_accuracy: 0.1639\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 3.7269 - accuracy: 0.2225 - val_loss: 1.9766 - val_accuracy: 0.1830\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9827 - accuracy: 0.1851 - val_loss: 2.1262 - val_accuracy: 0.1677\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9581 - accuracy: 0.1840 - val_loss: 1.9530 - val_accuracy: 0.1965\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9487 - accuracy: 0.1890 - val_loss: 1.9111 - val_accuracy: 0.1888\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9584 - accuracy: 0.1871 - val_loss: 1.8872 - val_accuracy: 0.2011\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9749 - accuracy: 0.1886 - val_loss: 1.8795 - val_accuracy: 0.2069\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9626 - accuracy: 0.1888 - val_loss: 1.9325 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.9165 - accuracy: 0.1991 - val_loss: 1.9410 - val_accuracy: 0.1822\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9356 - accuracy: 0.1961 - val_loss: 1.9695 - val_accuracy: 0.1822\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9191 - accuracy: 0.1976 - val_loss: 1.9002 - val_accuracy: 0.1887\n",
      "Epoch 11/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 1.9817 - accuracy: 0.1885Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9813 - accuracy: 0.1882 - val_loss: 1.9729 - val_accuracy: 0.1789\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.3696 - accuracy: 0.1052 - val_loss: 2.3141 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1011 - val_loss: 2.3067 - val_accuracy: 0.1103\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1017 - val_loss: 2.3148 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1042 - val_loss: 2.3061 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3135 - accuracy: 0.1029 - val_loss: 2.3125 - val_accuracy: 0.0981\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1026 - val_loss: 2.3136 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1001 - val_loss: 2.3113 - val_accuracy: 0.0981\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1020 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3142 - accuracy: 0.1025 - val_loss: 2.3158 - val_accuracy: 0.0983\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1043 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.3137 - accuracy: 0.1047Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3098 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5253 - accuracy: 0.1229 - val_loss: 1.9377 - val_accuracy: 0.2433\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8275 - accuracy: 0.2541 - val_loss: 1.7676 - val_accuracy: 0.2763\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7911 - accuracy: 0.2545 - val_loss: 1.7516 - val_accuracy: 0.2780\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7845 - accuracy: 0.2597 - val_loss: 1.7529 - val_accuracy: 0.2589\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7745 - accuracy: 0.2618 - val_loss: 1.7667 - val_accuracy: 0.2639\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7911 - accuracy: 0.2540 - val_loss: 1.7382 - val_accuracy: 0.2952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7795 - accuracy: 0.2591 - val_loss: 1.8752 - val_accuracy: 0.2148\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7794 - accuracy: 0.2596 - val_loss: 1.7822 - val_accuracy: 0.2381\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7973 - accuracy: 0.2561 - val_loss: 1.7798 - val_accuracy: 0.2520\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7740 - accuracy: 0.2630 - val_loss: 1.7762 - val_accuracy: 0.2670\n",
      "Epoch 11/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 1.7996 - accuracy: 0.2519Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8001 - accuracy: 0.2514 - val_loss: 1.8390 - val_accuracy: 0.2349\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5624 - accuracy: 0.1870 - val_loss: 2.3174 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3118 - val_accuracy: 0.0920\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1011 - val_loss: 2.3105 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3151 - accuracy: 0.1017 - val_loss: 2.3113 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3081 - val_accuracy: 0.1102\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3128 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3074 - val_accuracy: 0.1082\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3226 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3053 - val_accuracy: 0.1102\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3100 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3125 - val_accuracy: 0.1016\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3198 - val_accuracy: 0.1016\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3105 - val_accuracy: 0.1082\n",
      "Epoch 16/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 2.3137 - accuracy: 0.1006Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3122 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0827 - accuracy: 0.2002 - val_loss: 2.0447 - val_accuracy: 0.1999\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0237 - accuracy: 0.2017 - val_loss: 2.0124 - val_accuracy: 0.2048\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0307 - accuracy: 0.1988 - val_loss: 1.9897 - val_accuracy: 0.2138\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2090 - val_loss: 2.0142 - val_accuracy: 0.2001\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1005 - accuracy: 0.1809 - val_loss: 2.3240 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3150 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1030 - val_loss: 2.3226 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.3148 - accuracy: 0.1024Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1024 - val_loss: 2.3203 - val_accuracy: 0.0978\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9379 - accuracy: 0.2077 - val_loss: 2.0524 - val_accuracy: 0.2037\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2196 - accuracy: 0.1426 - val_loss: 2.3119 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3154 - accuracy: 0.1020 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.3132 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1030 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.1311 - accuracy: 0.1194 - val_loss: 2.0675 - val_accuracy: 0.1819\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0657 - accuracy: 0.1906 - val_loss: 2.0310 - val_accuracy: 0.2023\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0589 - accuracy: 0.1916 - val_loss: 2.3166 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3140 - accuracy: 0.1028 - val_loss: 2.3070 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1030 - val_loss: 2.3139 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1027 - val_loss: 2.3147 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.3149 - accuracy: 0.1002Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1003 - val_loss: 2.3125 - val_accuracy: 0.0978\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8207 - accuracy: 0.3784 - val_loss: 1.7321 - val_accuracy: 0.3289\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7394 - accuracy: 0.3252 - val_loss: 1.7514 - val_accuracy: 0.3167\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8234 - accuracy: 0.2900 - val_loss: 2.0469 - val_accuracy: 0.2038\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8708 - accuracy: 0.2572 - val_loss: 1.9972 - val_accuracy: 0.2066\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9968 - accuracy: 0.1957 - val_loss: 2.0276 - val_accuracy: 0.1754\n",
      "Epoch 6/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 1.9858 - accuracy: 0.1968Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9855 - accuracy: 0.1970 - val_loss: 2.0659 - val_accuracy: 0.1947\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8139 - accuracy: 0.1633 - val_loss: 2.3086 - val_accuracy: 0.1019\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1323 - val_loss: 2.1684 - val_accuracy: 0.1546\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9926 - accuracy: 0.2362 - val_loss: 1.8754 - val_accuracy: 0.2826\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9731 - accuracy: 0.2675 - val_loss: 1.8808 - val_accuracy: 0.2829\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8282 - accuracy: 0.3005 - val_loss: 1.7420 - val_accuracy: 0.3512\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7215 - accuracy: 0.3159 - val_loss: 1.6269 - val_accuracy: 0.3447\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7034 - accuracy: 0.3083 - val_loss: 2.0062 - val_accuracy: 0.2105\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6709 - accuracy: 0.3202 - val_loss: 1.8166 - val_accuracy: 0.2817\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6604 - accuracy: 0.3230 - val_loss: 1.6822 - val_accuracy: 0.3155\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6403 - accuracy: 0.3285 - val_loss: 1.6392 - val_accuracy: 0.3460\n",
      "Epoch 11/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 1.6229 - accuracy: 0.3392Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6229 - accuracy: 0.3392 - val_loss: 1.6909 - val_accuracy: 0.3278\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 5.3950 - accuracy: 0.1903 - val_loss: 1.8219 - val_accuracy: 0.2764\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7666 - accuracy: 0.2810 - val_loss: 1.8358 - val_accuracy: 0.2356\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6969 - accuracy: 0.3081 - val_loss: 1.7275 - val_accuracy: 0.3027\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6887 - accuracy: 0.3137 - val_loss: 1.6389 - val_accuracy: 0.3437\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6789 - accuracy: 0.3137 - val_loss: 1.6259 - val_accuracy: 0.3549\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6913 - accuracy: 0.3088 - val_loss: 1.7114 - val_accuracy: 0.2925\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6849 - accuracy: 0.3115 - val_loss: 1.8652 - val_accuracy: 0.2158\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7010 - accuracy: 0.3022 - val_loss: 1.7110 - val_accuracy: 0.2968\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6961 - accuracy: 0.3063 - val_loss: 1.7608 - val_accuracy: 0.2792\n",
      "Epoch 10/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 1.7003 - accuracy: 0.3008Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7004 - accuracy: 0.3006 - val_loss: 1.6640 - val_accuracy: 0.3163\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5883 - accuracy: 0.1083 - val_loss: 2.3258 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3266 - accuracy: 0.1041 - val_loss: 2.3115 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1018 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1066 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 4.6486 - accuracy: 0.1891 - val_loss: 2.0432 - val_accuracy: 0.2007\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0146 - accuracy: 0.2042 - val_loss: 1.9918 - val_accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0061 - accuracy: 0.2052 - val_loss: 2.0073 - val_accuracy: 0.2125\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0076 - accuracy: 0.2084 - val_loss: 1.9957 - val_accuracy: 0.2132\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0095 - accuracy: 0.2070 - val_loss: 2.0151 - val_accuracy: 0.2001\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0166 - accuracy: 0.2031 - val_loss: 2.1239 - val_accuracy: 0.2142\n",
      "Epoch 7/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 2.0306 - accuracy: 0.2008Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0300 - accuracy: 0.2008 - val_loss: 2.0242 - val_accuracy: 0.1905\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.7907 - accuracy: 0.1976 - val_loss: 2.0010 - val_accuracy: 0.1861\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0666 - accuracy: 0.1931 - val_loss: 1.9935 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9816 - accuracy: 0.1950 - val_loss: 1.9394 - val_accuracy: 0.2033\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9358 - accuracy: 0.1954 - val_loss: 1.9304 - val_accuracy: 0.1867\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9630 - accuracy: 0.1968 - val_loss: 1.9025 - val_accuracy: 0.1898\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9271 - accuracy: 0.1861 - val_loss: 1.9151 - val_accuracy: 0.2008\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9313 - accuracy: 0.1848 - val_loss: 2.1049 - val_accuracy: 0.1588\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0704 - accuracy: 0.1688 - val_loss: 1.9173 - val_accuracy: 0.1895\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9306 - accuracy: 0.1857 - val_loss: 1.9913 - val_accuracy: 0.1844\n",
      "Epoch 10/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 1.9424 - accuracy: 0.1844Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9420 - accuracy: 0.1844 - val_loss: 1.9286 - val_accuracy: 0.1842\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.5395 - accuracy: 0.1041 - val_loss: 2.3161 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3134 - accuracy: 0.1032 - val_loss: 2.3123 - val_accuracy: 0.0921\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3111 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1020 - val_loss: 2.3119 - val_accuracy: 0.1017\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3087 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3229 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3134 - val_accuracy: 0.0996\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3089 - val_accuracy: 0.1103\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3080 - val_accuracy: 0.1083\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3232 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3059 - val_accuracy: 0.1103\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3131 - val_accuracy: 0.1017\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3204 - val_accuracy: 0.1017\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3111 - val_accuracy: 0.1083\n",
      "Epoch 16/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 2.3137 - accuracy: 0.1003Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3128 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.4064 - accuracy: 0.1639 - val_loss: 2.0403 - val_accuracy: 0.1985\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0210 - accuracy: 0.2018 - val_loss: 2.0089 - val_accuracy: 0.2057\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0123 - accuracy: 0.2032 - val_loss: 2.0115 - val_accuracy: 0.2088\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0089 - accuracy: 0.2093 - val_loss: 2.0474 - val_accuracy: 0.2006\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2059 - val_loss: 2.0302 - val_accuracy: 0.2023\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0191 - accuracy: 0.2023 - val_loss: 2.0215 - val_accuracy: 0.1992\n",
      "Epoch 7/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 2.0276 - accuracy: 0.2024Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0278 - accuracy: 0.2026 - val_loss: 2.0147 - val_accuracy: 0.2007\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5135 - accuracy: 0.1870 - val_loss: 2.5136 - val_accuracy: 0.2005\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0570 - accuracy: 0.1968 - val_loss: 2.0125 - val_accuracy: 0.2040\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0109 - accuracy: 0.2056 - val_loss: 1.9939 - val_accuracy: 0.2132\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9956 - accuracy: 0.2103 - val_loss: 1.9912 - val_accuracy: 0.2233\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0115 - accuracy: 0.2085 - val_loss: 2.0192 - val_accuracy: 0.2070\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0117 - accuracy: 0.2070 - val_loss: 2.0075 - val_accuracy: 0.2113\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0153 - accuracy: 0.2078 - val_loss: 2.0239 - val_accuracy: 0.1943\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0108 - accuracy: 0.2063 - val_loss: 2.0449 - val_accuracy: 0.1972\n",
      "Epoch 9/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.2092 - accuracy: 0.1451Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2103 - accuracy: 0.1445 - val_loss: 2.3181 - val_accuracy: 0.0978\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3511 - accuracy: 0.2167 - val_loss: 1.8078 - val_accuracy: 0.2510\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8392 - accuracy: 0.2537 - val_loss: 2.0643 - val_accuracy: 0.2649\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9743 - accuracy: 0.2144 - val_loss: 2.1184 - val_accuracy: 0.1778\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9591 - accuracy: 0.1921 - val_loss: 1.9318 - val_accuracy: 0.1830\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9092 - accuracy: 0.1969 - val_loss: 1.9062 - val_accuracy: 0.2025\n",
      "Epoch 6/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 1.9134 - accuracy: 0.1928Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9133 - accuracy: 0.1927 - val_loss: 1.9054 - val_accuracy: 0.2053\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.6431 - accuracy: 0.2014 - val_loss: 2.0151 - val_accuracy: 0.2018\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0058 - accuracy: 0.2056 - val_loss: 2.0162 - val_accuracy: 0.2064\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9928 - accuracy: 0.2080 - val_loss: 1.9990 - val_accuracy: 0.2054\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9980 - accuracy: 0.2079 - val_loss: 2.0138 - val_accuracy: 0.2142\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0082 - accuracy: 0.2058 - val_loss: 2.0611 - val_accuracy: 0.2041\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0047 - accuracy: 0.2041 - val_loss: 2.0518 - val_accuracy: 0.2139\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1823 - accuracy: 0.1558 - val_loss: 2.8593 - val_accuracy: 0.1652\n",
      "Epoch 8/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.0976 - accuracy: 0.1862Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0971 - accuracy: 0.1863 - val_loss: 2.0269 - val_accuracy: 0.2007\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.1771 - accuracy: 0.1689 - val_loss: 2.0649 - val_accuracy: 0.1941\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0678 - accuracy: 0.1950 - val_loss: 2.0425 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0431 - accuracy: 0.2011 - val_loss: 2.0353 - val_accuracy: 0.1957\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1025 - accuracy: 0.1811 - val_loss: 2.3132 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1025 - val_loss: 2.3082 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1009 - val_loss: 2.3127 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.3133 - accuracy: 0.1027Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1029 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7086 - accuracy: 0.2188 - val_loss: 1.9572 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8685 - accuracy: 0.2613 - val_loss: 1.7151 - val_accuracy: 0.3244\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8747 - accuracy: 0.2660 - val_loss: 1.9195 - val_accuracy: 0.1790\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9888 - accuracy: 0.1872 - val_loss: 1.9455 - val_accuracy: 0.2050\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9157 - accuracy: 0.1956 - val_loss: 1.8756 - val_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8993 - accuracy: 0.1909 - val_loss: 1.8870 - val_accuracy: 0.1910\n",
      "Epoch 7/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 1.9106 - accuracy: 0.1946Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9098 - accuracy: 0.1946 - val_loss: 1.8653 - val_accuracy: 0.1917\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8365 - accuracy: 0.1752 - val_loss: 2.0623 - val_accuracy: 0.1775\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0252 - accuracy: 0.1853 - val_loss: 2.0176 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0775 - accuracy: 0.1762 - val_loss: 1.9810 - val_accuracy: 0.2003\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0357 - accuracy: 0.1805 - val_loss: 2.0148 - val_accuracy: 0.1921\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9998 - accuracy: 0.1891 - val_loss: 1.9721 - val_accuracy: 0.1851\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9814 - accuracy: 0.1897 - val_loss: 1.9604 - val_accuracy: 0.1970\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9870 - accuracy: 0.1893 - val_loss: 2.0274 - val_accuracy: 0.1691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9607 - accuracy: 0.1895 - val_loss: 2.0739 - val_accuracy: 0.1615\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9657 - accuracy: 0.1914 - val_loss: 1.9493 - val_accuracy: 0.1988\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9316 - accuracy: 0.1891 - val_loss: 1.9634 - val_accuracy: 0.1856\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9402 - accuracy: 0.1896 - val_loss: 2.0579 - val_accuracy: 0.1801\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9771 - accuracy: 0.1841 - val_loss: 2.0527 - val_accuracy: 0.1839\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9487 - accuracy: 0.1874 - val_loss: 1.9899 - val_accuracy: 0.1840\n",
      "Epoch 14/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 2.0161 - accuracy: 0.1859Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0167 - accuracy: 0.1858 - val_loss: 2.1021 - val_accuracy: 0.1815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8345 - accuracy: 0.1710 - val_loss: 2.2283 - val_accuracy: 0.1992\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0093 - accuracy: 0.2102 - val_loss: 1.9447 - val_accuracy: 0.2041\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9476 - accuracy: 0.1923 - val_loss: 1.9043 - val_accuracy: 0.1960\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9287 - accuracy: 0.1897 - val_loss: 1.9263 - val_accuracy: 0.1930\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9438 - accuracy: 0.1912 - val_loss: 1.8839 - val_accuracy: 0.1968\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8972 - accuracy: 0.1858 - val_loss: 1.8643 - val_accuracy: 0.1952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9116 - accuracy: 0.1873 - val_loss: 1.9431 - val_accuracy: 0.1813\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9319 - accuracy: 0.1884 - val_loss: 1.8880 - val_accuracy: 0.1943\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8979 - accuracy: 0.1915 - val_loss: 1.9380 - val_accuracy: 0.1867\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8907 - accuracy: 0.1932 - val_loss: 1.9199 - val_accuracy: 0.1945\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.1363 - accuracy: 0.1873Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1359 - accuracy: 0.1873 - val_loss: 2.0936 - val_accuracy: 0.1871\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8422 - accuracy: 0.2063 - val_loss: 1.8672 - val_accuracy: 0.1883\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9205 - accuracy: 0.1900 - val_loss: 2.3110 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1048 - val_loss: 2.3163 - val_accuracy: 0.1083\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1042 - val_loss: 2.3053 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1808 - accuracy: 0.1513 - val_loss: 2.0966 - val_accuracy: 0.2004\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.0420 - accuracy: 0.1874Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0420 - accuracy: 0.1874 - val_loss: 2.1843 - val_accuracy: 0.1852\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7303 - accuracy: 0.2774 - val_loss: 2.0490 - val_accuracy: 0.2111\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9522 - accuracy: 0.2672 - val_loss: 1.6941 - val_accuracy: 0.2939\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8989 - accuracy: 0.2725 - val_loss: 1.7249 - val_accuracy: 0.2927\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9825 - accuracy: 0.2173 - val_loss: 1.9297 - val_accuracy: 0.1959\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9757 - accuracy: 0.1931 - val_loss: 1.9397 - val_accuracy: 0.2144\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9405 - accuracy: 0.1958 - val_loss: 1.9242 - val_accuracy: 0.1773\n",
      "Epoch 7/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 1.9189 - accuracy: 0.1967Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9192 - accuracy: 0.1966 - val_loss: 1.9237 - val_accuracy: 0.1772\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9449 - accuracy: 0.1046 - val_loss: 2.3266 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1023 - val_loss: 2.3123 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1001 - val_loss: 2.3041 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1045 - val_loss: 2.3140 - val_accuracy: 0.0967\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3129 - accuracy: 0.1022 - val_loss: 2.3215 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3099 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3150 - accuracy: 0.1029 - val_loss: 2.3206 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 2.3148 - accuracy: 0.1023Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1023 - val_loss: 2.3183 - val_accuracy: 0.0979\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9674 - accuracy: 0.1047 - val_loss: 2.3260 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1039 - val_loss: 2.3117 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1021 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3170 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1030Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9959 - accuracy: 0.1019 - val_loss: 2.3143 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3072 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3148 - accuracy: 0.1017 - val_loss: 2.3152 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1042 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1029 - val_loss: 2.3132 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1026 - val_loss: 2.3141 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1002 - val_loss: 2.3118 - val_accuracy: 0.0978\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1019 - val_loss: 2.3046 - val_accuracy: 0.0995\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1022 - val_loss: 2.3169 - val_accuracy: 0.0978\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1044 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.3136 - accuracy: 0.1047Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3097 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8659 - accuracy: 0.1791 - val_loss: 2.0135 - val_accuracy: 0.2009\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.2053 - val_loss: 1.9964 - val_accuracy: 0.2052\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0064 - accuracy: 0.2071 - val_loss: 2.0181 - val_accuracy: 0.2034\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1047 - accuracy: 0.1793 - val_loss: 2.3109 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1031 - val_loss: 2.3091 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3141 - accuracy: 0.1014 - val_loss: 2.3170 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1025Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1024 - val_loss: 2.3188 - val_accuracy: 0.0920\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9759 - accuracy: 0.1911 - val_loss: 2.0848 - val_accuracy: 0.2044\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0529 - accuracy: 0.2068 - val_loss: 2.0623 - val_accuracy: 0.2042\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0733 - accuracy: 0.2015 - val_loss: 2.0538 - val_accuracy: 0.2009\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0909 - accuracy: 0.2024 - val_loss: 2.1011 - val_accuracy: 0.2047\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0716 - accuracy: 0.1993 - val_loss: 2.0792 - val_accuracy: 0.1905\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0668 - accuracy: 0.2039 - val_loss: 2.0714 - val_accuracy: 0.2012\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0629 - accuracy: 0.2005 - val_loss: 2.0759 - val_accuracy: 0.1953\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0433 - accuracy: 0.2058 - val_loss: 2.0430 - val_accuracy: 0.1978\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0410 - accuracy: 0.2051 - val_loss: 2.0384 - val_accuracy: 0.2023\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0407 - accuracy: 0.2076 - val_loss: 2.0646 - val_accuracy: 0.2018\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0424 - accuracy: 0.2030 - val_loss: 2.0348 - val_accuracy: 0.2032\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0428 - accuracy: 0.2021 - val_loss: 2.0411 - val_accuracy: 0.2019\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0424 - accuracy: 0.2046 - val_loss: 2.0483 - val_accuracy: 0.2050\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0434 - accuracy: 0.2021 - val_loss: 2.0586 - val_accuracy: 0.2050\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0422 - accuracy: 0.2063 - val_loss: 2.0472 - val_accuracy: 0.2102\n",
      "Epoch 16/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 2.0430 - accuracy: 0.2051Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0429 - accuracy: 0.2051 - val_loss: 2.0472 - val_accuracy: 0.1978\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0321 - accuracy: 0.3419 - val_loss: 1.4987 - val_accuracy: 0.4034\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8481 - accuracy: 0.2524 - val_loss: 2.0075 - val_accuracy: 0.1774\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9382 - accuracy: 0.1855 - val_loss: 1.9471 - val_accuracy: 0.1867\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9573 - accuracy: 0.1827 - val_loss: 2.0565 - val_accuracy: 0.1787\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9675 - accuracy: 0.1895 - val_loss: 2.0946 - val_accuracy: 0.1880\n",
      "Epoch 6/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.0275 - accuracy: 0.1888Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0280 - accuracy: 0.1886 - val_loss: 2.2018 - val_accuracy: 0.1639\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.7269 - accuracy: 0.2225 - val_loss: 1.9766 - val_accuracy: 0.1830\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9827 - accuracy: 0.1851 - val_loss: 2.1262 - val_accuracy: 0.1677\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9581 - accuracy: 0.1840 - val_loss: 1.9530 - val_accuracy: 0.1965\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9487 - accuracy: 0.1890 - val_loss: 1.9111 - val_accuracy: 0.1888\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9584 - accuracy: 0.1871 - val_loss: 1.8872 - val_accuracy: 0.2011\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9749 - accuracy: 0.1886 - val_loss: 1.8795 - val_accuracy: 0.2069\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9626 - accuracy: 0.1888 - val_loss: 1.9325 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9165 - accuracy: 0.1991 - val_loss: 1.9410 - val_accuracy: 0.1822\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9356 - accuracy: 0.1961 - val_loss: 1.9695 - val_accuracy: 0.1822\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9191 - accuracy: 0.1976 - val_loss: 1.9002 - val_accuracy: 0.1887\n",
      "Epoch 11/20\n",
      "1178/1200 [============================>.] - ETA: 0s - loss: 1.9823 - accuracy: 0.1884Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9813 - accuracy: 0.1882 - val_loss: 1.9729 - val_accuracy: 0.1789\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3696 - accuracy: 0.1052 - val_loss: 2.3141 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1011 - val_loss: 2.3067 - val_accuracy: 0.1103\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1017 - val_loss: 2.3148 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1042 - val_loss: 2.3061 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1029 - val_loss: 2.3125 - val_accuracy: 0.0981\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1026 - val_loss: 2.3136 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1001 - val_loss: 2.3113 - val_accuracy: 0.0981\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1020 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1025 - val_loss: 2.3158 - val_accuracy: 0.0983\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1043 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.3136 - accuracy: 0.1048Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3098 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5253 - accuracy: 0.1229 - val_loss: 1.9377 - val_accuracy: 0.2433\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8275 - accuracy: 0.2541 - val_loss: 1.7676 - val_accuracy: 0.2763\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7911 - accuracy: 0.2545 - val_loss: 1.7516 - val_accuracy: 0.2780\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7845 - accuracy: 0.2597 - val_loss: 1.7529 - val_accuracy: 0.2589\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7745 - accuracy: 0.2618 - val_loss: 1.7667 - val_accuracy: 0.2639\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7911 - accuracy: 0.2540 - val_loss: 1.7382 - val_accuracy: 0.2952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7795 - accuracy: 0.2591 - val_loss: 1.8752 - val_accuracy: 0.2148\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7794 - accuracy: 0.2596 - val_loss: 1.7822 - val_accuracy: 0.2381\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7973 - accuracy: 0.2561 - val_loss: 1.7798 - val_accuracy: 0.2520\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7740 - accuracy: 0.2630 - val_loss: 1.7762 - val_accuracy: 0.2670\n",
      "Epoch 11/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 1.7996 - accuracy: 0.2519Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8001 - accuracy: 0.2514 - val_loss: 1.8390 - val_accuracy: 0.2349\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5624 - accuracy: 0.1870 - val_loss: 2.3174 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3118 - val_accuracy: 0.0920\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1011 - val_loss: 2.3105 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1017 - val_loss: 2.3113 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3081 - val_accuracy: 0.1102\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3128 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3074 - val_accuracy: 0.1082\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3226 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3053 - val_accuracy: 0.1102\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3100 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3125 - val_accuracy: 0.1016\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3198 - val_accuracy: 0.1016\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3105 - val_accuracy: 0.1082\n",
      "Epoch 16/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1003Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3122 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0827 - accuracy: 0.2002 - val_loss: 2.0447 - val_accuracy: 0.1999\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0237 - accuracy: 0.2017 - val_loss: 2.0124 - val_accuracy: 0.2048\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0307 - accuracy: 0.1988 - val_loss: 1.9897 - val_accuracy: 0.2138\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2090 - val_loss: 2.0142 - val_accuracy: 0.2001\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1005 - accuracy: 0.1809 - val_loss: 2.3240 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3150 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1030 - val_loss: 2.3226 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1180/1200 [============================>.] - ETA: 0s - loss: 2.3147 - accuracy: 0.1026Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1024 - val_loss: 2.3203 - val_accuracy: 0.0978\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9379 - accuracy: 0.2077 - val_loss: 2.0524 - val_accuracy: 0.2037\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2196 - accuracy: 0.1426 - val_loss: 2.3119 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3154 - accuracy: 0.1020 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1198/1200 [============================>.] - ETA: 0s - loss: 2.3133 - accuracy: 0.1030Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1030 - val_loss: 2.3127 - val_accuracy: 0.1082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.1311 - accuracy: 0.1194 - val_loss: 2.0675 - val_accuracy: 0.1819\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0657 - accuracy: 0.1906 - val_loss: 2.0310 - val_accuracy: 0.2023\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0589 - accuracy: 0.1916 - val_loss: 2.3166 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3140 - accuracy: 0.1028 - val_loss: 2.3070 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1030 - val_loss: 2.3139 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3145 - accuracy: 0.1027 - val_loss: 2.3147 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 2.3149 - accuracy: 0.1002Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3149 - accuracy: 0.1003 - val_loss: 2.3125 - val_accuracy: 0.0978\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8207 - accuracy: 0.3784 - val_loss: 1.7321 - val_accuracy: 0.3289\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7394 - accuracy: 0.3252 - val_loss: 1.7514 - val_accuracy: 0.3167\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8234 - accuracy: 0.2900 - val_loss: 2.0469 - val_accuracy: 0.2038\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8708 - accuracy: 0.2572 - val_loss: 1.9972 - val_accuracy: 0.2066\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9968 - accuracy: 0.1957 - val_loss: 2.0276 - val_accuracy: 0.1754\n",
      "Epoch 6/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 1.9857 - accuracy: 0.1967Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9855 - accuracy: 0.1970 - val_loss: 2.0659 - val_accuracy: 0.1947\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8139 - accuracy: 0.1633 - val_loss: 2.3086 - val_accuracy: 0.1019\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1323 - val_loss: 2.1684 - val_accuracy: 0.1546\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9926 - accuracy: 0.2362 - val_loss: 1.8754 - val_accuracy: 0.2826\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9731 - accuracy: 0.2675 - val_loss: 1.8808 - val_accuracy: 0.2829\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8282 - accuracy: 0.3005 - val_loss: 1.7420 - val_accuracy: 0.3512\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7215 - accuracy: 0.3159 - val_loss: 1.6269 - val_accuracy: 0.3447\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7034 - accuracy: 0.3083 - val_loss: 2.0062 - val_accuracy: 0.2105\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6709 - accuracy: 0.3202 - val_loss: 1.8166 - val_accuracy: 0.2817\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6604 - accuracy: 0.3230 - val_loss: 1.6822 - val_accuracy: 0.3155\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6403 - accuracy: 0.3285 - val_loss: 1.6392 - val_accuracy: 0.3460\n",
      "Epoch 11/20\n",
      "1194/1200 [============================>.] - ETA: 0s - loss: 1.6229 - accuracy: 0.3393Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6229 - accuracy: 0.3392 - val_loss: 1.6909 - val_accuracy: 0.3278\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.3950 - accuracy: 0.1903 - val_loss: 1.8219 - val_accuracy: 0.2764\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7666 - accuracy: 0.2810 - val_loss: 1.8358 - val_accuracy: 0.2356\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6969 - accuracy: 0.3081 - val_loss: 1.7275 - val_accuracy: 0.3027\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6887 - accuracy: 0.3137 - val_loss: 1.6389 - val_accuracy: 0.3437\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6789 - accuracy: 0.3137 - val_loss: 1.6259 - val_accuracy: 0.3549\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6913 - accuracy: 0.3088 - val_loss: 1.7114 - val_accuracy: 0.2925\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6849 - accuracy: 0.3115 - val_loss: 1.8652 - val_accuracy: 0.2158\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7010 - accuracy: 0.3022 - val_loss: 1.7110 - val_accuracy: 0.2968\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6961 - accuracy: 0.3063 - val_loss: 1.7608 - val_accuracy: 0.2792\n",
      "Epoch 10/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 1.7004 - accuracy: 0.3006Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7004 - accuracy: 0.3006 - val_loss: 1.6640 - val_accuracy: 0.3163\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5883 - accuracy: 0.1083 - val_loss: 2.3258 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3266 - accuracy: 0.1041 - val_loss: 2.3115 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1018 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1066 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.6486 - accuracy: 0.1891 - val_loss: 2.0432 - val_accuracy: 0.2007\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0146 - accuracy: 0.2042 - val_loss: 1.9918 - val_accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0061 - accuracy: 0.2052 - val_loss: 2.0073 - val_accuracy: 0.2125\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0076 - accuracy: 0.2084 - val_loss: 1.9957 - val_accuracy: 0.2132\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0095 - accuracy: 0.2070 - val_loss: 2.0151 - val_accuracy: 0.2001\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0166 - accuracy: 0.2031 - val_loss: 2.1239 - val_accuracy: 0.2142\n",
      "Epoch 7/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 2.0300 - accuracy: 0.2008Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0300 - accuracy: 0.2008 - val_loss: 2.0242 - val_accuracy: 0.1905\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.7907 - accuracy: 0.1976 - val_loss: 2.0010 - val_accuracy: 0.1861\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0666 - accuracy: 0.1931 - val_loss: 1.9935 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9816 - accuracy: 0.1950 - val_loss: 1.9394 - val_accuracy: 0.2033\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9358 - accuracy: 0.1954 - val_loss: 1.9304 - val_accuracy: 0.1867\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9630 - accuracy: 0.1968 - val_loss: 1.9025 - val_accuracy: 0.1898\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9271 - accuracy: 0.1861 - val_loss: 1.9151 - val_accuracy: 0.2008\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9313 - accuracy: 0.1848 - val_loss: 2.1049 - val_accuracy: 0.1588\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0704 - accuracy: 0.1688 - val_loss: 1.9173 - val_accuracy: 0.1895\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9306 - accuracy: 0.1857 - val_loss: 1.9913 - val_accuracy: 0.1844\n",
      "Epoch 10/20\n",
      "1196/1200 [============================>.] - ETA: 0s - loss: 1.9422 - accuracy: 0.1844Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9420 - accuracy: 0.1844 - val_loss: 1.9286 - val_accuracy: 0.1842\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.5395 - accuracy: 0.1041 - val_loss: 2.3161 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3134 - accuracy: 0.1032 - val_loss: 2.3123 - val_accuracy: 0.0921\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3111 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1020 - val_loss: 2.3119 - val_accuracy: 0.1017\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3087 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3229 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3134 - val_accuracy: 0.0996\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3089 - val_accuracy: 0.1103\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3080 - val_accuracy: 0.1083\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3232 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3059 - val_accuracy: 0.1103\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3131 - val_accuracy: 0.1017\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3204 - val_accuracy: 0.1017\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3111 - val_accuracy: 0.1083\n",
      "Epoch 16/20\n",
      "1177/1200 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1003Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3128 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.4064 - accuracy: 0.1639 - val_loss: 2.0403 - val_accuracy: 0.1985\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0210 - accuracy: 0.2018 - val_loss: 2.0089 - val_accuracy: 0.2057\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0123 - accuracy: 0.2032 - val_loss: 2.0115 - val_accuracy: 0.2088\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0089 - accuracy: 0.2093 - val_loss: 2.0474 - val_accuracy: 0.2006\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0047 - accuracy: 0.2059 - val_loss: 2.0302 - val_accuracy: 0.2023\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0191 - accuracy: 0.2023 - val_loss: 2.0215 - val_accuracy: 0.1992\n",
      "Epoch 7/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 2.0276 - accuracy: 0.2024Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0278 - accuracy: 0.2026 - val_loss: 2.0147 - val_accuracy: 0.2007\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5135 - accuracy: 0.1870 - val_loss: 2.5136 - val_accuracy: 0.2005\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0570 - accuracy: 0.1968 - val_loss: 2.0125 - val_accuracy: 0.2040\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0109 - accuracy: 0.2056 - val_loss: 1.9939 - val_accuracy: 0.2132\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9956 - accuracy: 0.2103 - val_loss: 1.9912 - val_accuracy: 0.2233\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0115 - accuracy: 0.2085 - val_loss: 2.0192 - val_accuracy: 0.2070\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0117 - accuracy: 0.2070 - val_loss: 2.0075 - val_accuracy: 0.2113\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0153 - accuracy: 0.2078 - val_loss: 2.0239 - val_accuracy: 0.1943\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0108 - accuracy: 0.2063 - val_loss: 2.0449 - val_accuracy: 0.1972\n",
      "Epoch 9/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.2092 - accuracy: 0.1451Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2103 - accuracy: 0.1445 - val_loss: 2.3181 - val_accuracy: 0.0978\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3511 - accuracy: 0.2167 - val_loss: 1.8078 - val_accuracy: 0.2510\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8392 - accuracy: 0.2537 - val_loss: 2.0643 - val_accuracy: 0.2649\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9743 - accuracy: 0.2144 - val_loss: 2.1184 - val_accuracy: 0.1778\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9591 - accuracy: 0.1921 - val_loss: 1.9318 - val_accuracy: 0.1830\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9092 - accuracy: 0.1969 - val_loss: 1.9062 - val_accuracy: 0.2025\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.9133 - accuracy: 0.1927Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9133 - accuracy: 0.1927 - val_loss: 1.9054 - val_accuracy: 0.2053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.6431 - accuracy: 0.2014 - val_loss: 2.0151 - val_accuracy: 0.2018\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0058 - accuracy: 0.2056 - val_loss: 2.0162 - val_accuracy: 0.2064\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9928 - accuracy: 0.2080 - val_loss: 1.9990 - val_accuracy: 0.2054\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9980 - accuracy: 0.2079 - val_loss: 2.0138 - val_accuracy: 0.2142\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0082 - accuracy: 0.2058 - val_loss: 2.0611 - val_accuracy: 0.2041\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2041 - val_loss: 2.0518 - val_accuracy: 0.2139\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1823 - accuracy: 0.1558 - val_loss: 2.8593 - val_accuracy: 0.1652\n",
      "Epoch 8/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 2.0983 - accuracy: 0.1859Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0971 - accuracy: 0.1863 - val_loss: 2.0269 - val_accuracy: 0.2007\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.1771 - accuracy: 0.1689 - val_loss: 2.0649 - val_accuracy: 0.1941\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0678 - accuracy: 0.1950 - val_loss: 2.0425 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0431 - accuracy: 0.2011 - val_loss: 2.0353 - val_accuracy: 0.1957\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1025 - accuracy: 0.1811 - val_loss: 2.3132 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1025 - val_loss: 2.3082 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1009 - val_loss: 2.3127 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 2.3134 - accuracy: 0.1026Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1029 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7086 - accuracy: 0.2188 - val_loss: 1.9572 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8685 - accuracy: 0.2613 - val_loss: 1.7151 - val_accuracy: 0.3244\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8747 - accuracy: 0.2660 - val_loss: 1.9195 - val_accuracy: 0.1790\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9888 - accuracy: 0.1872 - val_loss: 1.9455 - val_accuracy: 0.2050\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9157 - accuracy: 0.1956 - val_loss: 1.8756 - val_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8993 - accuracy: 0.1909 - val_loss: 1.8870 - val_accuracy: 0.1910\n",
      "Epoch 7/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 1.9100 - accuracy: 0.1946Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9098 - accuracy: 0.1946 - val_loss: 1.8653 - val_accuracy: 0.1917\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8365 - accuracy: 0.1752 - val_loss: 2.0623 - val_accuracy: 0.1775\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0252 - accuracy: 0.1853 - val_loss: 2.0176 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0775 - accuracy: 0.1762 - val_loss: 1.9810 - val_accuracy: 0.2003\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0357 - accuracy: 0.1805 - val_loss: 2.0148 - val_accuracy: 0.1921\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9998 - accuracy: 0.1891 - val_loss: 1.9721 - val_accuracy: 0.1851\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9814 - accuracy: 0.1897 - val_loss: 1.9604 - val_accuracy: 0.1970\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9870 - accuracy: 0.1893 - val_loss: 2.0274 - val_accuracy: 0.1691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9607 - accuracy: 0.1895 - val_loss: 2.0739 - val_accuracy: 0.1615\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9657 - accuracy: 0.1914 - val_loss: 1.9493 - val_accuracy: 0.1988\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9316 - accuracy: 0.1891 - val_loss: 1.9634 - val_accuracy: 0.1856\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9402 - accuracy: 0.1896 - val_loss: 2.0579 - val_accuracy: 0.1801\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9771 - accuracy: 0.1841 - val_loss: 2.0527 - val_accuracy: 0.1839\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9487 - accuracy: 0.1874 - val_loss: 1.9899 - val_accuracy: 0.1840\n",
      "Epoch 14/20\n",
      "1199/1200 [============================>.] - ETA: 0s - loss: 2.0167 - accuracy: 0.1858Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0167 - accuracy: 0.1858 - val_loss: 2.1021 - val_accuracy: 0.1815\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8345 - accuracy: 0.1710 - val_loss: 2.2283 - val_accuracy: 0.1992\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0093 - accuracy: 0.2102 - val_loss: 1.9447 - val_accuracy: 0.2041\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9476 - accuracy: 0.1923 - val_loss: 1.9043 - val_accuracy: 0.1960\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9287 - accuracy: 0.1897 - val_loss: 1.9263 - val_accuracy: 0.1930\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9438 - accuracy: 0.1912 - val_loss: 1.8839 - val_accuracy: 0.1968\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8972 - accuracy: 0.1858 - val_loss: 1.8643 - val_accuracy: 0.1952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9116 - accuracy: 0.1873 - val_loss: 1.9431 - val_accuracy: 0.1813\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9319 - accuracy: 0.1884 - val_loss: 1.8880 - val_accuracy: 0.1943\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8979 - accuracy: 0.1915 - val_loss: 1.9380 - val_accuracy: 0.1867\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8907 - accuracy: 0.1932 - val_loss: 1.9199 - val_accuracy: 0.1945\n",
      "Epoch 11/20\n",
      "1193/1200 [============================>.] - ETA: 0s - loss: 2.1363 - accuracy: 0.1872Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1359 - accuracy: 0.1873 - val_loss: 2.0936 - val_accuracy: 0.1871\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8422 - accuracy: 0.2063 - val_loss: 1.8672 - val_accuracy: 0.1883\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9205 - accuracy: 0.1900 - val_loss: 2.3110 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1048 - val_loss: 2.3163 - val_accuracy: 0.1083\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1042 - val_loss: 2.3053 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1808 - accuracy: 0.1513 - val_loss: 2.0966 - val_accuracy: 0.2004\n",
      "Epoch 6/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 2.0399 - accuracy: 0.1872Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0420 - accuracy: 0.1874 - val_loss: 2.1843 - val_accuracy: 0.1852\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7303 - accuracy: 0.2774 - val_loss: 2.0490 - val_accuracy: 0.2111\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9522 - accuracy: 0.2672 - val_loss: 1.6941 - val_accuracy: 0.2939\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8989 - accuracy: 0.2725 - val_loss: 1.7249 - val_accuracy: 0.2927\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9825 - accuracy: 0.2173 - val_loss: 1.9297 - val_accuracy: 0.1959\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9757 - accuracy: 0.1931 - val_loss: 1.9397 - val_accuracy: 0.2144\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9405 - accuracy: 0.1958 - val_loss: 1.9242 - val_accuracy: 0.1773\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 1.9192 - accuracy: 0.1966Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9192 - accuracy: 0.1966 - val_loss: 1.9237 - val_accuracy: 0.1772\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9449 - accuracy: 0.1046 - val_loss: 2.3266 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1023 - val_loss: 2.3123 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1001 - val_loss: 2.3041 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1045 - val_loss: 2.3140 - val_accuracy: 0.0967\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3129 - accuracy: 0.1022 - val_loss: 2.3215 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3099 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3150 - accuracy: 0.1029 - val_loss: 2.3206 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.3147 - accuracy: 0.1025Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1023 - val_loss: 2.3183 - val_accuracy: 0.0979\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9674 - accuracy: 0.1047 - val_loss: 2.3260 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1039 - val_loss: 2.3117 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1021 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3170 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9959 - accuracy: 0.1019 - val_loss: 2.3143 - val_accuracy: 0.0978\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3072 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3148 - accuracy: 0.1017 - val_loss: 2.3152 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1042 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1029 - val_loss: 2.3132 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1026 - val_loss: 2.3141 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1002 - val_loss: 2.3118 - val_accuracy: 0.0978\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1019 - val_loss: 2.3046 - val_accuracy: 0.0995\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1022 - val_loss: 2.3169 - val_accuracy: 0.0978\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1044 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.3137 - accuracy: 0.1048Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3097 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8659 - accuracy: 0.1791 - val_loss: 2.0135 - val_accuracy: 0.2009\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.2053 - val_loss: 1.9964 - val_accuracy: 0.2052\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0064 - accuracy: 0.2071 - val_loss: 2.0181 - val_accuracy: 0.2034\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1047 - accuracy: 0.1793 - val_loss: 2.3109 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1031 - val_loss: 2.3091 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3141 - accuracy: 0.1014 - val_loss: 2.3170 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1026Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1024 - val_loss: 2.3188 - val_accuracy: 0.0920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9759 - accuracy: 0.1911 - val_loss: 2.0848 - val_accuracy: 0.2044\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0529 - accuracy: 0.2068 - val_loss: 2.0623 - val_accuracy: 0.2042\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0733 - accuracy: 0.2015 - val_loss: 2.0538 - val_accuracy: 0.2009\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0909 - accuracy: 0.2024 - val_loss: 2.1011 - val_accuracy: 0.2047\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0716 - accuracy: 0.1993 - val_loss: 2.0792 - val_accuracy: 0.1905\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0668 - accuracy: 0.2039 - val_loss: 2.0714 - val_accuracy: 0.2012\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0629 - accuracy: 0.2005 - val_loss: 2.0759 - val_accuracy: 0.1953\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0433 - accuracy: 0.2058 - val_loss: 2.0430 - val_accuracy: 0.1978\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0410 - accuracy: 0.2051 - val_loss: 2.0384 - val_accuracy: 0.2023\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0407 - accuracy: 0.2076 - val_loss: 2.0646 - val_accuracy: 0.2018\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0424 - accuracy: 0.2030 - val_loss: 2.0348 - val_accuracy: 0.2032\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0428 - accuracy: 0.2021 - val_loss: 2.0411 - val_accuracy: 0.2019\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0424 - accuracy: 0.2046 - val_loss: 2.0483 - val_accuracy: 0.2050\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0434 - accuracy: 0.2021 - val_loss: 2.0586 - val_accuracy: 0.2050\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0422 - accuracy: 0.2063 - val_loss: 2.0472 - val_accuracy: 0.2102\n",
      "Epoch 16/20\n",
      "1182/1200 [============================>.] - ETA: 0s - loss: 2.0429 - accuracy: 0.2049Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0429 - accuracy: 0.2051 - val_loss: 2.0472 - val_accuracy: 0.1978\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0321 - accuracy: 0.3419 - val_loss: 1.4987 - val_accuracy: 0.4034\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8481 - accuracy: 0.2524 - val_loss: 2.0075 - val_accuracy: 0.1774\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9382 - accuracy: 0.1855 - val_loss: 1.9471 - val_accuracy: 0.1867\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9573 - accuracy: 0.1827 - val_loss: 2.0565 - val_accuracy: 0.1787\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9675 - accuracy: 0.1895 - val_loss: 2.0946 - val_accuracy: 0.1880\n",
      "Epoch 6/20\n",
      "1189/1200 [============================>.] - ETA: 0s - loss: 2.0267 - accuracy: 0.1889Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0280 - accuracy: 0.1886 - val_loss: 2.2018 - val_accuracy: 0.1639\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.7269 - accuracy: 0.2225 - val_loss: 1.9766 - val_accuracy: 0.1830\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9827 - accuracy: 0.1851 - val_loss: 2.1262 - val_accuracy: 0.1677\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9581 - accuracy: 0.1840 - val_loss: 1.9530 - val_accuracy: 0.1965\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9487 - accuracy: 0.1890 - val_loss: 1.9111 - val_accuracy: 0.1888\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9584 - accuracy: 0.1871 - val_loss: 1.8872 - val_accuracy: 0.2011\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9749 - accuracy: 0.1886 - val_loss: 1.8795 - val_accuracy: 0.2069\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9626 - accuracy: 0.1888 - val_loss: 1.9325 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9165 - accuracy: 0.1991 - val_loss: 1.9410 - val_accuracy: 0.1822\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9356 - accuracy: 0.1961 - val_loss: 1.9695 - val_accuracy: 0.1822\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9191 - accuracy: 0.1976 - val_loss: 1.9002 - val_accuracy: 0.1887\n",
      "Epoch 11/20\n",
      "1178/1200 [============================>.] - ETA: 0s - loss: 1.9823 - accuracy: 0.1884Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9813 - accuracy: 0.1882 - val_loss: 1.9729 - val_accuracy: 0.1789\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3696 - accuracy: 0.1052 - val_loss: 2.3141 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1011 - val_loss: 2.3067 - val_accuracy: 0.1103\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1017 - val_loss: 2.3148 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1042 - val_loss: 2.3061 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3135 - accuracy: 0.1029 - val_loss: 2.3125 - val_accuracy: 0.0981\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1026 - val_loss: 2.3136 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1001 - val_loss: 2.3113 - val_accuracy: 0.0981\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1020 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1025 - val_loss: 2.3158 - val_accuracy: 0.0983\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1043 - val_loss: 2.3250 - val_accuracy: 0.0979\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1010 - val_loss: 2.3105 - val_accuracy: 0.1016\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1036 - val_loss: 2.3314 - val_accuracy: 0.1016\n",
      "Epoch 13/20\n",
      "1181/1200 [============================>.] - ETA: 0s - loss: 2.3136 - accuracy: 0.1045Restoring model weights from the end of the best epoch: 8.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1047 - val_loss: 2.3098 - val_accuracy: 0.1016\n",
      "Epoch 13: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5253 - accuracy: 0.1229 - val_loss: 1.9377 - val_accuracy: 0.2433\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8275 - accuracy: 0.2541 - val_loss: 1.7676 - val_accuracy: 0.2763\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7911 - accuracy: 0.2545 - val_loss: 1.7516 - val_accuracy: 0.2780\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7845 - accuracy: 0.2597 - val_loss: 1.7529 - val_accuracy: 0.2589\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7745 - accuracy: 0.2618 - val_loss: 1.7667 - val_accuracy: 0.2639\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7911 - accuracy: 0.2540 - val_loss: 1.7382 - val_accuracy: 0.2952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7795 - accuracy: 0.2591 - val_loss: 1.8752 - val_accuracy: 0.2148\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7794 - accuracy: 0.2596 - val_loss: 1.7822 - val_accuracy: 0.2381\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7973 - accuracy: 0.2561 - val_loss: 1.7798 - val_accuracy: 0.2520\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7740 - accuracy: 0.2630 - val_loss: 1.7762 - val_accuracy: 0.2670\n",
      "Epoch 11/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 1.8003 - accuracy: 0.2517Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8001 - accuracy: 0.2514 - val_loss: 1.8390 - val_accuracy: 0.2349\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5624 - accuracy: 0.1870 - val_loss: 2.3174 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3118 - val_accuracy: 0.0920\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1011 - val_loss: 2.3105 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1017 - val_loss: 2.3113 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3081 - val_accuracy: 0.1102\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3128 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3074 - val_accuracy: 0.1082\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3226 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3053 - val_accuracy: 0.1102\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3100 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3125 - val_accuracy: 0.1016\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3198 - val_accuracy: 0.1016\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3105 - val_accuracy: 0.1082\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - ETA: 0s - loss: 2.3137 - accuracy: 0.1005Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3122 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.0827 - accuracy: 0.2002 - val_loss: 2.0447 - val_accuracy: 0.1999\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0237 - accuracy: 0.2017 - val_loss: 2.0124 - val_accuracy: 0.2048\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0307 - accuracy: 0.1988 - val_loss: 1.9897 - val_accuracy: 0.2138\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2090 - val_loss: 2.0142 - val_accuracy: 0.2001\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1005 - accuracy: 0.1809 - val_loss: 2.3240 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3150 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0967\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1030 - val_loss: 2.3226 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1178/1200 [============================>.] - ETA: 0s - loss: 2.3147 - accuracy: 0.1027Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1024 - val_loss: 2.3203 - val_accuracy: 0.0978\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.9379 - accuracy: 0.2077 - val_loss: 2.0524 - val_accuracy: 0.2037\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2196 - accuracy: 0.1426 - val_loss: 2.3119 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3154 - accuracy: 0.1020 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1063 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 2.3133 - accuracy: 0.1028Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1030 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.1311 - accuracy: 0.1194 - val_loss: 2.0675 - val_accuracy: 0.1819\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0657 - accuracy: 0.1906 - val_loss: 2.0310 - val_accuracy: 0.2023\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0589 - accuracy: 0.1916 - val_loss: 2.3166 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3140 - accuracy: 0.1028 - val_loss: 2.3070 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1030 - val_loss: 2.3139 - val_accuracy: 0.0978\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1027 - val_loss: 2.3147 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1190/1200 [============================>.] - ETA: 0s - loss: 2.3149 - accuracy: 0.1002Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3149 - accuracy: 0.1003 - val_loss: 2.3125 - val_accuracy: 0.0978\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 3.8207 - accuracy: 0.3784 - val_loss: 1.7321 - val_accuracy: 0.3289\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7394 - accuracy: 0.3252 - val_loss: 1.7514 - val_accuracy: 0.3167\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8234 - accuracy: 0.2900 - val_loss: 2.0469 - val_accuracy: 0.2038\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8708 - accuracy: 0.2572 - val_loss: 1.9972 - val_accuracy: 0.2066\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9968 - accuracy: 0.1957 - val_loss: 2.0276 - val_accuracy: 0.1754\n",
      "Epoch 6/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 1.9856 - accuracy: 0.1966Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9855 - accuracy: 0.1970 - val_loss: 2.0659 - val_accuracy: 0.1947\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8139 - accuracy: 0.1633 - val_loss: 2.3086 - val_accuracy: 0.1019\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1323 - val_loss: 2.1684 - val_accuracy: 0.1546\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9926 - accuracy: 0.2362 - val_loss: 1.8754 - val_accuracy: 0.2826\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9731 - accuracy: 0.2675 - val_loss: 1.8808 - val_accuracy: 0.2829\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8282 - accuracy: 0.3005 - val_loss: 1.7420 - val_accuracy: 0.3512\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7215 - accuracy: 0.3159 - val_loss: 1.6269 - val_accuracy: 0.3447\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7034 - accuracy: 0.3083 - val_loss: 2.0062 - val_accuracy: 0.2105\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6709 - accuracy: 0.3202 - val_loss: 1.8166 - val_accuracy: 0.2817\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6604 - accuracy: 0.3230 - val_loss: 1.6822 - val_accuracy: 0.3155\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6403 - accuracy: 0.3285 - val_loss: 1.6392 - val_accuracy: 0.3460\n",
      "Epoch 11/20\n",
      "1183/1200 [============================>.] - ETA: 0s - loss: 1.6228 - accuracy: 0.3397Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6229 - accuracy: 0.3392 - val_loss: 1.6909 - val_accuracy: 0.3278\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.3950 - accuracy: 0.1903 - val_loss: 1.8219 - val_accuracy: 0.2764\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7666 - accuracy: 0.2810 - val_loss: 1.8358 - val_accuracy: 0.2356\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6969 - accuracy: 0.3081 - val_loss: 1.7275 - val_accuracy: 0.3027\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6887 - accuracy: 0.3137 - val_loss: 1.6389 - val_accuracy: 0.3437\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6789 - accuracy: 0.3137 - val_loss: 1.6259 - val_accuracy: 0.3549\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6913 - accuracy: 0.3088 - val_loss: 1.7114 - val_accuracy: 0.2925\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6849 - accuracy: 0.3115 - val_loss: 1.8652 - val_accuracy: 0.2158\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7010 - accuracy: 0.3022 - val_loss: 1.7110 - val_accuracy: 0.2968\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.6961 - accuracy: 0.3063 - val_loss: 1.7608 - val_accuracy: 0.2792\n",
      "Epoch 10/20\n",
      "1191/1200 [============================>.] - ETA: 0s - loss: 1.7008 - accuracy: 0.3008Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.7004 - accuracy: 0.3006 - val_loss: 1.6640 - val_accuracy: 0.3163\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5883 - accuracy: 0.1083 - val_loss: 2.3258 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3266 - accuracy: 0.1041 - val_loss: 2.3115 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1018 - val_loss: 2.3065 - val_accuracy: 0.1082\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1066 - val_loss: 2.3169 - val_accuracy: 0.1102\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3137 - accuracy: 0.1052 - val_loss: 2.3183 - val_accuracy: 0.1016\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3132 - accuracy: 0.1029 - val_loss: 2.3127 - val_accuracy: 0.1082\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3086 - val_accuracy: 0.0967\n",
      "Epoch 8/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1031Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1031 - val_loss: 2.3156 - val_accuracy: 0.0980\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.6486 - accuracy: 0.1891 - val_loss: 2.0432 - val_accuracy: 0.2007\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0146 - accuracy: 0.2042 - val_loss: 1.9918 - val_accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0061 - accuracy: 0.2052 - val_loss: 2.0073 - val_accuracy: 0.2125\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0076 - accuracy: 0.2084 - val_loss: 1.9957 - val_accuracy: 0.2132\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0095 - accuracy: 0.2070 - val_loss: 2.0151 - val_accuracy: 0.2001\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0166 - accuracy: 0.2031 - val_loss: 2.1239 - val_accuracy: 0.2142\n",
      "Epoch 7/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.0300 - accuracy: 0.2008Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0300 - accuracy: 0.2008 - val_loss: 2.0242 - val_accuracy: 0.1905\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.7907 - accuracy: 0.1976 - val_loss: 2.0010 - val_accuracy: 0.1861\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0666 - accuracy: 0.1931 - val_loss: 1.9935 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9816 - accuracy: 0.1950 - val_loss: 1.9394 - val_accuracy: 0.2033\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9358 - accuracy: 0.1954 - val_loss: 1.9304 - val_accuracy: 0.1867\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9630 - accuracy: 0.1968 - val_loss: 1.9025 - val_accuracy: 0.1898\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9271 - accuracy: 0.1861 - val_loss: 1.9151 - val_accuracy: 0.2008\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9313 - accuracy: 0.1848 - val_loss: 2.1049 - val_accuracy: 0.1588\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0704 - accuracy: 0.1688 - val_loss: 1.9173 - val_accuracy: 0.1895\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9306 - accuracy: 0.1857 - val_loss: 1.9913 - val_accuracy: 0.1844\n",
      "Epoch 10/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 1.9424 - accuracy: 0.1844Restoring model weights from the end of the best epoch: 5.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9420 - accuracy: 0.1844 - val_loss: 1.9286 - val_accuracy: 0.1842\n",
      "Epoch 10: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.5395 - accuracy: 0.1041 - val_loss: 2.3161 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3134 - accuracy: 0.1032 - val_loss: 2.3123 - val_accuracy: 0.0921\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1011 - val_loss: 2.3111 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3151 - accuracy: 0.1020 - val_loss: 2.3119 - val_accuracy: 0.1017\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3087 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1005 - val_loss: 2.3229 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1008 - val_loss: 2.3134 - val_accuracy: 0.0996\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3133 - accuracy: 0.1027 - val_loss: 2.3089 - val_accuracy: 0.1103\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1020 - val_loss: 2.3080 - val_accuracy: 0.1083\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3232 - val_accuracy: 0.0981\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3144 - accuracy: 0.1036 - val_loss: 2.3059 - val_accuracy: 0.1103\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3132 - accuracy: 0.1048 - val_loss: 2.3131 - val_accuracy: 0.1017\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1019 - val_loss: 2.3204 - val_accuracy: 0.1017\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1051 - val_loss: 2.3111 - val_accuracy: 0.1083\n",
      "Epoch 16/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1004Restoring model weights from the end of the best epoch: 11.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1005 - val_loss: 2.3128 - val_accuracy: 0.0981\n",
      "Epoch 16: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.4064 - accuracy: 0.1639 - val_loss: 2.0403 - val_accuracy: 0.1985\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0210 - accuracy: 0.2018 - val_loss: 2.0089 - val_accuracy: 0.2057\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0123 - accuracy: 0.2032 - val_loss: 2.0115 - val_accuracy: 0.2088\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0089 - accuracy: 0.2093 - val_loss: 2.0474 - val_accuracy: 0.2006\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2059 - val_loss: 2.0302 - val_accuracy: 0.2023\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0191 - accuracy: 0.2023 - val_loss: 2.0215 - val_accuracy: 0.1992\n",
      "Epoch 7/20\n",
      "1184/1200 [============================>.] - ETA: 0s - loss: 2.0276 - accuracy: 0.2023Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0278 - accuracy: 0.2026 - val_loss: 2.0147 - val_accuracy: 0.2007\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.5135 - accuracy: 0.1870 - val_loss: 2.5136 - val_accuracy: 0.2005\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0570 - accuracy: 0.1968 - val_loss: 2.0125 - val_accuracy: 0.2040\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0109 - accuracy: 0.2056 - val_loss: 1.9939 - val_accuracy: 0.2132\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9956 - accuracy: 0.2103 - val_loss: 1.9912 - val_accuracy: 0.2233\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0115 - accuracy: 0.2085 - val_loss: 2.0192 - val_accuracy: 0.2070\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0117 - accuracy: 0.2070 - val_loss: 2.0075 - val_accuracy: 0.2113\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0153 - accuracy: 0.2078 - val_loss: 2.0239 - val_accuracy: 0.1943\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0108 - accuracy: 0.2063 - val_loss: 2.0449 - val_accuracy: 0.1972\n",
      "Epoch 9/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.2100 - accuracy: 0.1446Restoring model weights from the end of the best epoch: 4.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2103 - accuracy: 0.1445 - val_loss: 2.3181 - val_accuracy: 0.0978\n",
      "Epoch 9: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.3511 - accuracy: 0.2167 - val_loss: 1.8078 - val_accuracy: 0.2510\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8392 - accuracy: 0.2537 - val_loss: 2.0643 - val_accuracy: 0.2649\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9743 - accuracy: 0.2144 - val_loss: 2.1184 - val_accuracy: 0.1778\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9591 - accuracy: 0.1921 - val_loss: 1.9318 - val_accuracy: 0.1830\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9092 - accuracy: 0.1969 - val_loss: 1.9062 - val_accuracy: 0.2025\n",
      "Epoch 6/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 1.9134 - accuracy: 0.1928Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9133 - accuracy: 0.1927 - val_loss: 1.9054 - val_accuracy: 0.2053\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.6431 - accuracy: 0.2014 - val_loss: 2.0151 - val_accuracy: 0.2018\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0058 - accuracy: 0.2056 - val_loss: 2.0162 - val_accuracy: 0.2064\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9928 - accuracy: 0.2080 - val_loss: 1.9990 - val_accuracy: 0.2054\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9980 - accuracy: 0.2079 - val_loss: 2.0138 - val_accuracy: 0.2142\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0082 - accuracy: 0.2058 - val_loss: 2.0611 - val_accuracy: 0.2041\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0047 - accuracy: 0.2041 - val_loss: 2.0518 - val_accuracy: 0.2139\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1823 - accuracy: 0.1558 - val_loss: 2.8593 - val_accuracy: 0.1652\n",
      "Epoch 8/20\n",
      "1192/1200 [============================>.] - ETA: 0s - loss: 2.0979 - accuracy: 0.1860Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0971 - accuracy: 0.1863 - val_loss: 2.0269 - val_accuracy: 0.2007\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.1771 - accuracy: 0.1689 - val_loss: 2.0649 - val_accuracy: 0.1941\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0678 - accuracy: 0.1950 - val_loss: 2.0425 - val_accuracy: 0.1934\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0431 - accuracy: 0.2011 - val_loss: 2.0353 - val_accuracy: 0.1957\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1025 - accuracy: 0.1811 - val_loss: 2.3132 - val_accuracy: 0.1016\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3145 - accuracy: 0.1025 - val_loss: 2.3082 - val_accuracy: 0.1103\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1005 - val_loss: 2.3222 - val_accuracy: 0.0980\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3152 - accuracy: 0.1009 - val_loss: 2.3127 - val_accuracy: 0.0995\n",
      "Epoch 8/20\n",
      "1187/1200 [============================>.] - ETA: 0s - loss: 2.3134 - accuracy: 0.1026Restoring model weights from the end of the best epoch: 3.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3133 - accuracy: 0.1029 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 8: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7086 - accuracy: 0.2188 - val_loss: 1.9572 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8685 - accuracy: 0.2613 - val_loss: 1.7151 - val_accuracy: 0.3244\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8747 - accuracy: 0.2660 - val_loss: 1.9195 - val_accuracy: 0.1790\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9888 - accuracy: 0.1872 - val_loss: 1.9455 - val_accuracy: 0.2050\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9157 - accuracy: 0.1956 - val_loss: 1.8756 - val_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8993 - accuracy: 0.1909 - val_loss: 1.8870 - val_accuracy: 0.1910\n",
      "Epoch 7/20\n",
      "1188/1200 [============================>.] - ETA: 0s - loss: 1.9106 - accuracy: 0.1946Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9098 - accuracy: 0.1946 - val_loss: 1.8653 - val_accuracy: 0.1917\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8365 - accuracy: 0.1752 - val_loss: 2.0623 - val_accuracy: 0.1775\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0252 - accuracy: 0.1853 - val_loss: 2.0176 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0775 - accuracy: 0.1762 - val_loss: 1.9810 - val_accuracy: 0.2003\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0357 - accuracy: 0.1805 - val_loss: 2.0148 - val_accuracy: 0.1921\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9998 - accuracy: 0.1891 - val_loss: 1.9721 - val_accuracy: 0.1851\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9814 - accuracy: 0.1897 - val_loss: 1.9604 - val_accuracy: 0.1970\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9870 - accuracy: 0.1893 - val_loss: 2.0274 - val_accuracy: 0.1691\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9607 - accuracy: 0.1895 - val_loss: 2.0739 - val_accuracy: 0.1615\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9657 - accuracy: 0.1914 - val_loss: 1.9493 - val_accuracy: 0.1988\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9316 - accuracy: 0.1891 - val_loss: 1.9634 - val_accuracy: 0.1856\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9402 - accuracy: 0.1896 - val_loss: 2.0579 - val_accuracy: 0.1801\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9771 - accuracy: 0.1841 - val_loss: 2.0527 - val_accuracy: 0.1839\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9487 - accuracy: 0.1874 - val_loss: 1.9899 - val_accuracy: 0.1840\n",
      "Epoch 14/20\n",
      "1195/1200 [============================>.] - ETA: 0s - loss: 2.0163 - accuracy: 0.1859Restoring model weights from the end of the best epoch: 9.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0167 - accuracy: 0.1858 - val_loss: 2.1021 - val_accuracy: 0.1815\n",
      "Epoch 14: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8345 - accuracy: 0.1710 - val_loss: 2.2283 - val_accuracy: 0.1992\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.0093 - accuracy: 0.2102 - val_loss: 1.9447 - val_accuracy: 0.2041\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9476 - accuracy: 0.1923 - val_loss: 1.9043 - val_accuracy: 0.1960\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9287 - accuracy: 0.1897 - val_loss: 1.9263 - val_accuracy: 0.1930\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9438 - accuracy: 0.1912 - val_loss: 1.8839 - val_accuracy: 0.1968\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8972 - accuracy: 0.1858 - val_loss: 1.8643 - val_accuracy: 0.1952\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9116 - accuracy: 0.1873 - val_loss: 1.9431 - val_accuracy: 0.1813\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9319 - accuracy: 0.1884 - val_loss: 1.8880 - val_accuracy: 0.1943\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8979 - accuracy: 0.1915 - val_loss: 1.9380 - val_accuracy: 0.1867\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8907 - accuracy: 0.1932 - val_loss: 1.9199 - val_accuracy: 0.1945\n",
      "Epoch 11/20\n",
      "1197/1200 [============================>.] - ETA: 0s - loss: 2.1362 - accuracy: 0.1873Restoring model weights from the end of the best epoch: 6.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.1359 - accuracy: 0.1873 - val_loss: 2.0936 - val_accuracy: 0.1871\n",
      "Epoch 11: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 4.8422 - accuracy: 0.2063 - val_loss: 1.8672 - val_accuracy: 0.1883\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9205 - accuracy: 0.1900 - val_loss: 2.3110 - val_accuracy: 0.1102\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1048 - val_loss: 2.3163 - val_accuracy: 0.1083\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.3127 - accuracy: 0.1042 - val_loss: 2.3053 - val_accuracy: 0.1082\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1808 - accuracy: 0.1513 - val_loss: 2.0966 - val_accuracy: 0.2004\n",
      "Epoch 6/20\n",
      "1185/1200 [============================>.] - ETA: 0s - loss: 2.0399 - accuracy: 0.1872Restoring model weights from the end of the best epoch: 1.\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0420 - accuracy: 0.1874 - val_loss: 2.1843 - val_accuracy: 0.1852\n",
      "Epoch 6: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 5.7303 - accuracy: 0.2774 - val_loss: 2.0490 - val_accuracy: 0.2111\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9522 - accuracy: 0.2672 - val_loss: 1.6941 - val_accuracy: 0.2939\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.8989 - accuracy: 0.2725 - val_loss: 1.7249 - val_accuracy: 0.2927\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9825 - accuracy: 0.2173 - val_loss: 1.9297 - val_accuracy: 0.1959\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9757 - accuracy: 0.1931 - val_loss: 1.9397 - val_accuracy: 0.2144\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9405 - accuracy: 0.1958 - val_loss: 1.9242 - val_accuracy: 0.1773\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1200 [============================>.] - ETA: 0s - loss: 1.9187 - accuracy: 0.1968Restoring model weights from the end of the best epoch: 2.\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 1.9192 - accuracy: 0.1966 - val_loss: 1.9237 - val_accuracy: 0.1772\n",
      "Epoch 7: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2656 - accuracy: 0.9194 - val_loss: 0.1549 - val_accuracy: 0.9537\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1071 - accuracy: 0.9664 - val_loss: 0.0971 - val_accuracy: 0.9708\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0701 - accuracy: 0.9771 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0786 - val_accuracy: 0.9770\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.1006 - val_accuracy: 0.9738\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.1074 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0852 - val_accuracy: 0.9794\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1116 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1486/1500 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9938Restoring model weights from the end of the best epoch: 4.\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.1010 - val_accuracy: 0.9787\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "# patience: number of epochs with no improvement before stopping\n",
    "# min: training will stop when the quantity monitored has stopped decreasing\n",
    "# monitor: \"val_loss\" measure loss on validation set \n",
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 5,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "RMSprop_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=550,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='RMSprop',\n",
    "    callbacks= earlystopping,\n",
    "    epochs=20,\n",
    ")\n",
    "RMSprop_param_grid = {\n",
    "    'unitsHL1':[550,750,850],\n",
    "    'unitsHL2':[200,400],\n",
    "    'optimizer_learning_rate':[0.001,0.01,0.1],\n",
    "    'optimizer_momentum':[0.0,0.001,0.01,0.1],\n",
    "    \n",
    "}\n",
    "RMSprop_grid = GridSearchCV(\n",
    "    estimator=RMSprop_estimator, \n",
    "    param_grid=RMSprop_param_grid\n",
    ")\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "    RMSprop_grid_result = RMSprop_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c62ee3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.974958 using {'optimizer_learning_rate': 0.001, 'optimizer_momentum': 0.0, 'unitsHL1': 750, 'unitsHL2': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (RMSprop_grid_result.best_score_, RMSprop_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b558500",
   "metadata": {},
   "source": [
    "### Grid search : Layers and SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5100dce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# patience: number of epochs with no improvement before stopping\n",
    "# min: training will stop when the quantity monitored has stopped decreasing\n",
    "# monitor: \"val_loss\" measure loss on validation set \n",
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 3,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "SGD_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=550,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='SGD',\n",
    "    callbacks= earlystopping,\n",
    "    epochs=20,\n",
    "\n",
    ")\n",
    "SGD_param_grid = {\n",
    "    'unitsHL1':[550,750,850],\n",
    "    'unitsHL2':[200,400],\n",
    "    'optimizer_learning_rate':[0.001,0.01,0.1],\n",
    "    'optimizer_momentum':[0.0,0.001,0.01],\n",
    "}\n",
    "SGD_grid = GridSearchCV(\n",
    "    estimator=SGD_estimator, \n",
    "    param_grid=SGD_param_grid,\n",
    "    cv = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8b4400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3254 - accuracy: 0.9012 - val_loss: 0.1737 - val_accuracy: 0.9471\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1296 - accuracy: 0.9608 - val_loss: 0.1385 - val_accuracy: 0.9584\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 0.1007 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 0.1576 - val_accuracy: 0.9564\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0488 - accuracy: 0.9828 - val_loss: 0.1046 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9879Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 0.1134 - val_accuracy: 0.9715\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3178 - accuracy: 0.9046 - val_loss: 0.1759 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1278 - accuracy: 0.9604 - val_loss: 0.1214 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1230 - val_accuracy: 0.9648\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.1151 - val_accuracy: 0.9672\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 0.1171 - val_accuracy: 0.9697\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.1013 - val_accuracy: 0.9716\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1035 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.1121 - val_accuracy: 0.9743\n",
      "Epoch 10/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9937Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.1152 - val_accuracy: 0.9746\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3173 - accuracy: 0.9060 - val_loss: 0.1844 - val_accuracy: 0.9475\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: 0.1245 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9660\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.1347 - val_accuracy: 0.9642\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.1042 - val_accuracy: 0.9711\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.1132 - val_accuracy: 0.9696\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.1080 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.1184 - val_accuracy: 0.9705\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3374 - accuracy: 0.9004 - val_loss: 0.1645 - val_accuracy: 0.9516\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1287 - accuracy: 0.9606 - val_loss: 0.1356 - val_accuracy: 0.9585\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.9727 - val_loss: 0.1068 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.1217 - val_accuracy: 0.9657\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 0.0969 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1135 - val_accuracy: 0.9681\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.1553 - val_accuracy: 0.9613\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1145 - val_accuracy: 0.9714\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3390 - accuracy: 0.9014 - val_loss: 0.1746 - val_accuracy: 0.9463\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1265 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.1288 - val_accuracy: 0.9588\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1189 - val_accuracy: 0.9662\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0998 - val_accuracy: 0.9706\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.1338 - val_accuracy: 0.9660\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.1094 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.1209 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3349 - accuracy: 0.9012 - val_loss: 0.1808 - val_accuracy: 0.9454\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1318 - accuracy: 0.9597 - val_loss: 0.1232 - val_accuracy: 0.9632\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.9733 - val_loss: 0.1053 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9703\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.1066 - val_accuracy: 0.9710\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.0994 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.1110 - val_accuracy: 0.9728\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.1042 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.1344 - val_accuracy: 0.9703\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3228 - accuracy: 0.9005 - val_loss: 0.1699 - val_accuracy: 0.9483\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.1390 - val_accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9730 - val_loss: 0.1051 - val_accuracy: 0.9682\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.1429 - val_accuracy: 0.9578\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.0975 - val_accuracy: 0.9725\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.1067 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
      "Epoch 8/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9910Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.1176 - val_accuracy: 0.9725\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3240 - accuracy: 0.9027 - val_loss: 0.1843 - val_accuracy: 0.9439\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1275 - accuracy: 0.9597 - val_loss: 0.1221 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.1241 - val_accuracy: 0.9613\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.1057 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 0.1032 - val_accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0347 - accuracy: 0.9877 - val_loss: 0.1128 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0910 - val_accuracy: 0.9760\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1307 - val_accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.1229 - val_accuracy: 0.9723\n",
      "Epoch 10/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1220 - val_accuracy: 0.9753\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3250 - accuracy: 0.9014 - val_loss: 0.1830 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.1254 - val_accuracy: 0.9620\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.1089 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.1131 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.1154 - val_accuracy: 0.9702\n",
      "Epoch 6/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9878Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.1253 - val_accuracy: 0.9643\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3352 - accuracy: 0.9025 - val_loss: 0.1686 - val_accuracy: 0.9496\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.9610 - val_loss: 0.1355 - val_accuracy: 0.9590\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.9733 - val_loss: 0.1188 - val_accuracy: 0.9625\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.1299 - val_accuracy: 0.9618\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.0948 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.1264 - val_accuracy: 0.9676\n",
      "Epoch 8/20\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.1122 - val_accuracy: 0.9743\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3358 - accuracy: 0.9046 - val_loss: 0.1790 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9612 - val_loss: 0.1264 - val_accuracy: 0.9596\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9731 - val_loss: 0.1196 - val_accuracy: 0.9627\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.1009 - val_accuracy: 0.9702\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1119 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.1203 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0944 - val_accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.1381 - val_accuracy: 0.9676\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1415 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9925Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.1293 - val_accuracy: 0.9729\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3431 - accuracy: 0.9017 - val_loss: 0.1811 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1293 - accuracy: 0.9603 - val_loss: 0.1164 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.1187 - val_accuracy: 0.9643\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0648 - accuracy: 0.9787 - val_loss: 0.1066 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.1333 - val_accuracy: 0.9657\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.1169 - val_accuracy: 0.9690\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.1013 - val_accuracy: 0.9735\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.1329 - val_accuracy: 0.9691\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.1242 - val_accuracy: 0.9707\n",
      "Epoch 10/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9927Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1384 - val_accuracy: 0.9715\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3136 - accuracy: 0.9050 - val_loss: 0.1683 - val_accuracy: 0.9488\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1257 - accuracy: 0.9612 - val_loss: 0.1350 - val_accuracy: 0.9582\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9729 - val_loss: 0.1112 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.1227 - val_accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0460 - accuracy: 0.9846 - val_loss: 0.0973 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1198 - val_accuracy: 0.9689\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.1249 - val_accuracy: 0.9707\n",
      "Epoch 8/20\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9915Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.1251 - val_accuracy: 0.9718\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3260 - accuracy: 0.9047 - val_loss: 0.1709 - val_accuracy: 0.9490\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1265 - accuracy: 0.9603 - val_loss: 0.1259 - val_accuracy: 0.9607\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.1238 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.1050 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0971 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.1165 - val_accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.1069 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.1259 - val_accuracy: 0.9709\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3234 - accuracy: 0.9043 - val_loss: 0.1816 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1314 - accuracy: 0.9593 - val_loss: 0.1251 - val_accuracy: 0.9613\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.1081 - val_accuracy: 0.9665\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.1106 - val_accuracy: 0.9673\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.1126 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9882Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1325 - val_accuracy: 0.9647\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3268 - accuracy: 0.9055 - val_loss: 0.1638 - val_accuracy: 0.9504\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.9620 - val_loss: 0.1259 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.1095 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.1416 - val_accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0991 - val_accuracy: 0.9721\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.1118 - val_accuracy: 0.9710\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.1296 - val_accuracy: 0.9679\n",
      "Epoch 8/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9909Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.1185 - val_accuracy: 0.9719\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3511 - accuracy: 0.9022 - val_loss: 0.1777 - val_accuracy: 0.9460\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1259 - accuracy: 0.9598 - val_loss: 0.1248 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 0.1065 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.1305 - val_accuracy: 0.9597\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.1147 - val_accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.1122 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.1348 - val_accuracy: 0.9692\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3358 - accuracy: 0.9031 - val_loss: 0.1781 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1282 - accuracy: 0.9607 - val_loss: 0.1168 - val_accuracy: 0.9652\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.1057 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.1183 - val_accuracy: 0.9664\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.1126 - val_accuracy: 0.9691\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9873Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.1118 - val_accuracy: 0.9703\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3254 - accuracy: 0.9012 - val_loss: 0.1737 - val_accuracy: 0.9471\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1296 - accuracy: 0.9608 - val_loss: 0.1385 - val_accuracy: 0.9584\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 0.1007 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 0.1576 - val_accuracy: 0.9564\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0488 - accuracy: 0.9828 - val_loss: 0.1046 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9880Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 0.1134 - val_accuracy: 0.9715\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3178 - accuracy: 0.9046 - val_loss: 0.1759 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1278 - accuracy: 0.9604 - val_loss: 0.1214 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1230 - val_accuracy: 0.9648\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.1151 - val_accuracy: 0.9672\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 0.1171 - val_accuracy: 0.9697\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.1013 - val_accuracy: 0.9716\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1035 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.1121 - val_accuracy: 0.9743\n",
      "Epoch 10/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.1152 - val_accuracy: 0.9746\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3173 - accuracy: 0.9060 - val_loss: 0.1844 - val_accuracy: 0.9475\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: 0.1245 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9660\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.1347 - val_accuracy: 0.9642\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.1042 - val_accuracy: 0.9711\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.1132 - val_accuracy: 0.9696\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.1080 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.1184 - val_accuracy: 0.9705\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3374 - accuracy: 0.9004 - val_loss: 0.1645 - val_accuracy: 0.9516\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1287 - accuracy: 0.9606 - val_loss: 0.1356 - val_accuracy: 0.9585\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.9727 - val_loss: 0.1068 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.1217 - val_accuracy: 0.9657\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 0.0969 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1135 - val_accuracy: 0.9681\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.1553 - val_accuracy: 0.9613\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1145 - val_accuracy: 0.9714\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3390 - accuracy: 0.9014 - val_loss: 0.1746 - val_accuracy: 0.9463\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1265 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.1288 - val_accuracy: 0.9588\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1189 - val_accuracy: 0.9662\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0998 - val_accuracy: 0.9706\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.1338 - val_accuracy: 0.9660\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.1094 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.1209 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3349 - accuracy: 0.9012 - val_loss: 0.1808 - val_accuracy: 0.9454\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1318 - accuracy: 0.9597 - val_loss: 0.1232 - val_accuracy: 0.9632\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.9733 - val_loss: 0.1053 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9703\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.1066 - val_accuracy: 0.9710\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.0994 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.1110 - val_accuracy: 0.9728\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.1042 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.1344 - val_accuracy: 0.9703\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3228 - accuracy: 0.9005 - val_loss: 0.1699 - val_accuracy: 0.9483\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.1390 - val_accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9730 - val_loss: 0.1051 - val_accuracy: 0.9682\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.1429 - val_accuracy: 0.9578\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.0975 - val_accuracy: 0.9725\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.1067 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
      "Epoch 8/20\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9910Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.1176 - val_accuracy: 0.9725\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3240 - accuracy: 0.9027 - val_loss: 0.1843 - val_accuracy: 0.9439\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1275 - accuracy: 0.9597 - val_loss: 0.1221 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.1241 - val_accuracy: 0.9613\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.1057 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 0.1032 - val_accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0347 - accuracy: 0.9877 - val_loss: 0.1128 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0910 - val_accuracy: 0.9760\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1307 - val_accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.1229 - val_accuracy: 0.9723\n",
      "Epoch 10/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9932Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1220 - val_accuracy: 0.9753\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3250 - accuracy: 0.9014 - val_loss: 0.1830 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.1254 - val_accuracy: 0.9620\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.1089 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.1131 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.1154 - val_accuracy: 0.9702\n",
      "Epoch 6/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9878Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.1253 - val_accuracy: 0.9643\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3352 - accuracy: 0.9025 - val_loss: 0.1686 - val_accuracy: 0.9496\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.9610 - val_loss: 0.1355 - val_accuracy: 0.9590\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.9733 - val_loss: 0.1188 - val_accuracy: 0.9625\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.1299 - val_accuracy: 0.9618\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.0948 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.1264 - val_accuracy: 0.9676\n",
      "Epoch 8/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.1122 - val_accuracy: 0.9743\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3358 - accuracy: 0.9046 - val_loss: 0.1790 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9612 - val_loss: 0.1264 - val_accuracy: 0.9596\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9731 - val_loss: 0.1196 - val_accuracy: 0.9627\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.1009 - val_accuracy: 0.9702\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1119 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.1203 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0944 - val_accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.1381 - val_accuracy: 0.9676\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1415 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9925Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.1293 - val_accuracy: 0.9729\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3431 - accuracy: 0.9017 - val_loss: 0.1811 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1293 - accuracy: 0.9603 - val_loss: 0.1164 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.1187 - val_accuracy: 0.9643\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0648 - accuracy: 0.9787 - val_loss: 0.1066 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.1333 - val_accuracy: 0.9657\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.1169 - val_accuracy: 0.9690\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.1013 - val_accuracy: 0.9735\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.1329 - val_accuracy: 0.9691\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.1242 - val_accuracy: 0.9707\n",
      "Epoch 10/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9927Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1384 - val_accuracy: 0.9715\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3136 - accuracy: 0.9050 - val_loss: 0.1683 - val_accuracy: 0.9488\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1257 - accuracy: 0.9612 - val_loss: 0.1350 - val_accuracy: 0.9582\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9729 - val_loss: 0.1112 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.1227 - val_accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0460 - accuracy: 0.9846 - val_loss: 0.0973 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1198 - val_accuracy: 0.9689\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.1249 - val_accuracy: 0.9707\n",
      "Epoch 8/20\n",
      " 981/1000 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9915Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.1251 - val_accuracy: 0.9718\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3260 - accuracy: 0.9047 - val_loss: 0.1709 - val_accuracy: 0.9490\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1265 - accuracy: 0.9603 - val_loss: 0.1259 - val_accuracy: 0.9607\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.1238 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.1050 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0971 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.1165 - val_accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.1069 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.1259 - val_accuracy: 0.9709\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3234 - accuracy: 0.9043 - val_loss: 0.1816 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1314 - accuracy: 0.9593 - val_loss: 0.1251 - val_accuracy: 0.9613\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.1081 - val_accuracy: 0.9665\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.1106 - val_accuracy: 0.9673\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.1126 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9882Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1325 - val_accuracy: 0.9647\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3268 - accuracy: 0.9055 - val_loss: 0.1638 - val_accuracy: 0.9504\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.9620 - val_loss: 0.1259 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.1095 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.1416 - val_accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0991 - val_accuracy: 0.9721\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.1118 - val_accuracy: 0.9710\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.1296 - val_accuracy: 0.9679\n",
      "Epoch 8/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9909Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.1185 - val_accuracy: 0.9719\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3511 - accuracy: 0.9022 - val_loss: 0.1777 - val_accuracy: 0.9460\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1259 - accuracy: 0.9598 - val_loss: 0.1248 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 0.1065 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.1305 - val_accuracy: 0.9597\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.1147 - val_accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.1122 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 981/1000 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.1348 - val_accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3358 - accuracy: 0.9031 - val_loss: 0.1781 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1282 - accuracy: 0.9607 - val_loss: 0.1168 - val_accuracy: 0.9652\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.1057 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.1183 - val_accuracy: 0.9664\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.1126 - val_accuracy: 0.9691\n",
      "Epoch 6/20\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9872Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.1118 - val_accuracy: 0.9703\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3254 - accuracy: 0.9012 - val_loss: 0.1737 - val_accuracy: 0.9471\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1296 - accuracy: 0.9608 - val_loss: 0.1385 - val_accuracy: 0.9584\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 0.1007 - val_accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 0.1576 - val_accuracy: 0.9564\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0488 - accuracy: 0.9828 - val_loss: 0.1046 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9879Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 0.1134 - val_accuracy: 0.9715\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3178 - accuracy: 0.9046 - val_loss: 0.1759 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1278 - accuracy: 0.9604 - val_loss: 0.1214 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.1230 - val_accuracy: 0.9648\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.1151 - val_accuracy: 0.9672\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 0.1171 - val_accuracy: 0.9697\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.1013 - val_accuracy: 0.9716\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1035 - val_accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.1121 - val_accuracy: 0.9743\n",
      "Epoch 10/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.1152 - val_accuracy: 0.9746\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3173 - accuracy: 0.9060 - val_loss: 0.1844 - val_accuracy: 0.9475\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: 0.1245 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9660\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.1347 - val_accuracy: 0.9642\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.1042 - val_accuracy: 0.9711\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.1132 - val_accuracy: 0.9696\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.1080 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.1184 - val_accuracy: 0.9705\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3374 - accuracy: 0.9004 - val_loss: 0.1645 - val_accuracy: 0.9516\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1287 - accuracy: 0.9606 - val_loss: 0.1356 - val_accuracy: 0.9585\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.9727 - val_loss: 0.1068 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.1217 - val_accuracy: 0.9657\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 0.0969 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1135 - val_accuracy: 0.9681\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.1553 - val_accuracy: 0.9613\n",
      "Epoch 8/20\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1145 - val_accuracy: 0.9714\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3390 - accuracy: 0.9014 - val_loss: 0.1746 - val_accuracy: 0.9463\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1265 - val_accuracy: 0.9605\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.1288 - val_accuracy: 0.9588\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.1189 - val_accuracy: 0.9662\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0998 - val_accuracy: 0.9706\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.1338 - val_accuracy: 0.9660\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.1094 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.1209 - val_accuracy: 0.9745\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3349 - accuracy: 0.9012 - val_loss: 0.1808 - val_accuracy: 0.9454\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1318 - accuracy: 0.9597 - val_loss: 0.1232 - val_accuracy: 0.9632\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.9733 - val_loss: 0.1053 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9703\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.1066 - val_accuracy: 0.9710\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.0994 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.1110 - val_accuracy: 0.9728\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.1042 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9925Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.1344 - val_accuracy: 0.9703\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3228 - accuracy: 0.9005 - val_loss: 0.1699 - val_accuracy: 0.9483\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.1390 - val_accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9730 - val_loss: 0.1051 - val_accuracy: 0.9682\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.1429 - val_accuracy: 0.9578\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.0975 - val_accuracy: 0.9725\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.1067 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.1498 - val_accuracy: 0.9630\n",
      "Epoch 8/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9911Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.1176 - val_accuracy: 0.9725\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3240 - accuracy: 0.9027 - val_loss: 0.1843 - val_accuracy: 0.9439\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1275 - accuracy: 0.9597 - val_loss: 0.1221 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.1241 - val_accuracy: 0.9613\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.1057 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9854 - val_loss: 0.1032 - val_accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0347 - accuracy: 0.9877 - val_loss: 0.1128 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0910 - val_accuracy: 0.9760\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1307 - val_accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.1229 - val_accuracy: 0.9723\n",
      "Epoch 10/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1220 - val_accuracy: 0.9753\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3250 - accuracy: 0.9014 - val_loss: 0.1830 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.1254 - val_accuracy: 0.9620\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.1089 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0604 - accuracy: 0.9807 - val_loss: 0.1131 - val_accuracy: 0.9688\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.1154 - val_accuracy: 0.9702\n",
      "Epoch 6/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9878Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.1253 - val_accuracy: 0.9643\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3352 - accuracy: 0.9025 - val_loss: 0.1686 - val_accuracy: 0.9496\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.9610 - val_loss: 0.1355 - val_accuracy: 0.9590\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.9733 - val_loss: 0.1188 - val_accuracy: 0.9625\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.1299 - val_accuracy: 0.9618\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.0948 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.1264 - val_accuracy: 0.9676\n",
      "Epoch 8/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9903Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.1122 - val_accuracy: 0.9743\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3358 - accuracy: 0.9046 - val_loss: 0.1790 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9612 - val_loss: 0.1264 - val_accuracy: 0.9596\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9731 - val_loss: 0.1196 - val_accuracy: 0.9627\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.1009 - val_accuracy: 0.9702\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1119 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.1203 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0944 - val_accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.1381 - val_accuracy: 0.9676\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1415 - val_accuracy: 0.9728\n",
      "Epoch 10/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9925Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.1293 - val_accuracy: 0.9729\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3431 - accuracy: 0.9017 - val_loss: 0.1811 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1293 - accuracy: 0.9603 - val_loss: 0.1164 - val_accuracy: 0.9638\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.1187 - val_accuracy: 0.9643\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0648 - accuracy: 0.9787 - val_loss: 0.1066 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.1333 - val_accuracy: 0.9657\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.1169 - val_accuracy: 0.9690\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.1013 - val_accuracy: 0.9735\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.1329 - val_accuracy: 0.9691\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.1242 - val_accuracy: 0.9707\n",
      "Epoch 10/20\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9928Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1384 - val_accuracy: 0.9715\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3136 - accuracy: 0.9050 - val_loss: 0.1683 - val_accuracy: 0.9488\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1257 - accuracy: 0.9612 - val_loss: 0.1350 - val_accuracy: 0.9582\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9729 - val_loss: 0.1112 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.1227 - val_accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0460 - accuracy: 0.9846 - val_loss: 0.0973 - val_accuracy: 0.9728\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1198 - val_accuracy: 0.9689\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.1249 - val_accuracy: 0.9707\n",
      "Epoch 8/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9915Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.1251 - val_accuracy: 0.9718\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3260 - accuracy: 0.9047 - val_loss: 0.1709 - val_accuracy: 0.9490\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1265 - accuracy: 0.9603 - val_loss: 0.1259 - val_accuracy: 0.9607\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.1238 - val_accuracy: 0.9612\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.1050 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0971 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.1165 - val_accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.1069 - val_accuracy: 0.9739\n",
      "Epoch 8/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.1259 - val_accuracy: 0.9709\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3234 - accuracy: 0.9043 - val_loss: 0.1816 - val_accuracy: 0.9448\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1314 - accuracy: 0.9593 - val_loss: 0.1251 - val_accuracy: 0.9613\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.1081 - val_accuracy: 0.9665\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.1106 - val_accuracy: 0.9673\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.1126 - val_accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9882Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1325 - val_accuracy: 0.9647\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3268 - accuracy: 0.9055 - val_loss: 0.1638 - val_accuracy: 0.9504\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.9620 - val_loss: 0.1259 - val_accuracy: 0.9626\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.1095 - val_accuracy: 0.9657\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.1416 - val_accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0991 - val_accuracy: 0.9721\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.1118 - val_accuracy: 0.9710\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.1296 - val_accuracy: 0.9679\n",
      "Epoch 8/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9909Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.1185 - val_accuracy: 0.9719\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3511 - accuracy: 0.9022 - val_loss: 0.1777 - val_accuracy: 0.9460\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1259 - accuracy: 0.9598 - val_loss: 0.1248 - val_accuracy: 0.9622\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.9741 - val_loss: 0.1065 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.1305 - val_accuracy: 0.9597\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.1147 - val_accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.1122 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.9904 - val_loss: 0.1348 - val_accuracy: 0.9692\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3358 - accuracy: 0.9031 - val_loss: 0.1781 - val_accuracy: 0.9453\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1282 - accuracy: 0.9607 - val_loss: 0.1168 - val_accuracy: 0.9652\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.1057 - val_accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.1183 - val_accuracy: 0.9664\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.1126 - val_accuracy: 0.9691\n",
      "Epoch 6/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9873Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.1118 - val_accuracy: 0.9703\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4226 - accuracy: 0.8986 - val_loss: 0.1952 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2005 - accuracy: 0.9430 - val_loss: 0.1825 - val_accuracy: 0.9503\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1819 - accuracy: 0.9488 - val_loss: 0.2359 - val_accuracy: 0.9393\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1744 - accuracy: 0.9543 - val_loss: 0.2183 - val_accuracy: 0.9479\n",
      "Epoch 5/20\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9556Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1690 - accuracy: 0.9557 - val_loss: 0.2075 - val_accuracy: 0.9467\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4191 - accuracy: 0.9008 - val_loss: 0.2129 - val_accuracy: 0.9443\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2017 - accuracy: 0.9419 - val_loss: 0.2343 - val_accuracy: 0.9372\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1762 - accuracy: 0.9516 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1599 - accuracy: 0.9559 - val_loss: 0.2179 - val_accuracy: 0.9425\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9589 - val_loss: 0.1856 - val_accuracy: 0.9547\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1329 - accuracy: 0.9635 - val_loss: 0.2607 - val_accuracy: 0.9460\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1378 - accuracy: 0.9652 - val_loss: 0.1983 - val_accuracy: 0.9557\n",
      "Epoch 8/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9677Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.2268 - val_accuracy: 0.9506\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4049 - accuracy: 0.9005 - val_loss: 0.2117 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1990 - accuracy: 0.9438 - val_loss: 0.2052 - val_accuracy: 0.9449\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1842 - accuracy: 0.9498 - val_loss: 0.2145 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1557 - accuracy: 0.9593 - val_loss: 0.2050 - val_accuracy: 0.9476\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9635 - val_loss: 0.2122 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9630 - val_loss: 0.2675 - val_accuracy: 0.9433\n",
      "Epoch 7/20\n",
      " 981/1000 [============================>.] - ETA: 0s - loss: 0.1272 - accuracy: 0.9675Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1274 - accuracy: 0.9674 - val_loss: 0.2051 - val_accuracy: 0.9521\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4352 - accuracy: 0.8923 - val_loss: 0.2341 - val_accuracy: 0.9326\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2242 - accuracy: 0.9358 - val_loss: 0.2526 - val_accuracy: 0.9295\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2008 - accuracy: 0.9446 - val_loss: 0.1929 - val_accuracy: 0.9470\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9502 - val_loss: 0.2567 - val_accuracy: 0.9317\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1722 - accuracy: 0.9558 - val_loss: 0.2288 - val_accuracy: 0.9441\n",
      "Epoch 6/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.1600 - accuracy: 0.9585Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.2248 - val_accuracy: 0.9463\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4470 - accuracy: 0.8929 - val_loss: 0.2378 - val_accuracy: 0.9299\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2188 - accuracy: 0.9380 - val_loss: 0.2170 - val_accuracy: 0.9402\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1962 - accuracy: 0.9454 - val_loss: 0.2463 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9518 - val_loss: 0.1830 - val_accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9567 - val_loss: 0.2282 - val_accuracy: 0.9493\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9594 - val_loss: 0.2234 - val_accuracy: 0.9524\n",
      "Epoch 7/20\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9605Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1544 - accuracy: 0.9603 - val_loss: 0.2089 - val_accuracy: 0.9528\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4591 - accuracy: 0.8910 - val_loss: 0.2917 - val_accuracy: 0.9123\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9369 - val_loss: 0.2329 - val_accuracy: 0.9335\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1986 - accuracy: 0.9452 - val_loss: 0.1767 - val_accuracy: 0.9496\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9535 - val_loss: 0.2029 - val_accuracy: 0.9505\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1791 - accuracy: 0.9541 - val_loss: 0.2061 - val_accuracy: 0.9543\n",
      "Epoch 6/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.1444 - accuracy: 0.9608Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1448 - accuracy: 0.9607 - val_loss: 0.2128 - val_accuracy: 0.9468\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4027 - accuracy: 0.9037 - val_loss: 0.2131 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9429 - val_loss: 0.2167 - val_accuracy: 0.9357\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9534 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1521 - accuracy: 0.9597 - val_loss: 0.2601 - val_accuracy: 0.9349\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1426 - accuracy: 0.9639 - val_loss: 0.2146 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9670Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.9670 - val_loss: 0.1970 - val_accuracy: 0.9564\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3979 - accuracy: 0.9023 - val_loss: 0.2233 - val_accuracy: 0.9379\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1894 - accuracy: 0.9474 - val_loss: 0.2573 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1691 - accuracy: 0.9524 - val_loss: 0.2485 - val_accuracy: 0.9383\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1533 - accuracy: 0.9581 - val_loss: 0.2020 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9602 - val_loss: 0.2438 - val_accuracy: 0.9417\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1359 - accuracy: 0.9638 - val_loss: 0.2422 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1302 - accuracy: 0.9671 - val_loss: 0.2017 - val_accuracy: 0.9574\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1224 - accuracy: 0.9682 - val_loss: 0.2283 - val_accuracy: 0.9563\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1206 - accuracy: 0.9712 - val_loss: 0.2381 - val_accuracy: 0.9490\n",
      "Epoch 10/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9732Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1052 - accuracy: 0.9731 - val_loss: 0.2271 - val_accuracy: 0.9602\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4224 - accuracy: 0.9010 - val_loss: 0.2183 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2024 - accuracy: 0.9427 - val_loss: 0.2455 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1838 - accuracy: 0.9499 - val_loss: 0.2165 - val_accuracy: 0.9423\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9545 - val_loss: 0.2359 - val_accuracy: 0.9482\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1665 - accuracy: 0.9568 - val_loss: 0.1972 - val_accuracy: 0.9556\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1421 - accuracy: 0.9635 - val_loss: 0.1994 - val_accuracy: 0.9533\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1350 - accuracy: 0.9648 - val_loss: 0.2156 - val_accuracy: 0.9549\n",
      "Epoch 8/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9678Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9677 - val_loss: 0.2097 - val_accuracy: 0.9540\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5085 - accuracy: 0.8851 - val_loss: 0.2566 - val_accuracy: 0.9224\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2319 - accuracy: 0.9339 - val_loss: 0.2354 - val_accuracy: 0.9353\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2159 - accuracy: 0.9413 - val_loss: 0.2070 - val_accuracy: 0.9442\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1844 - accuracy: 0.9477 - val_loss: 0.2541 - val_accuracy: 0.9352\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9501 - val_loss: 0.2777 - val_accuracy: 0.9363\n",
      "Epoch 6/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9545Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1739 - accuracy: 0.9544 - val_loss: 0.2171 - val_accuracy: 0.9482\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5129 - accuracy: 0.8878 - val_loss: 0.2353 - val_accuracy: 0.9289\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9392 - val_loss: 0.2228 - val_accuracy: 0.9370\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1900 - accuracy: 0.9473 - val_loss: 0.1972 - val_accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1826 - accuracy: 0.9514 - val_loss: 0.2241 - val_accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1667 - accuracy: 0.9550 - val_loss: 0.2104 - val_accuracy: 0.9464\n",
      "Epoch 6/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9577Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 0.1985 - val_accuracy: 0.9535\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4856 - accuracy: 0.8899 - val_loss: 0.2299 - val_accuracy: 0.9319\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2218 - accuracy: 0.9368 - val_loss: 0.2687 - val_accuracy: 0.9251\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1910 - accuracy: 0.9472 - val_loss: 0.1983 - val_accuracy: 0.9465\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1880 - accuracy: 0.9486 - val_loss: 0.2874 - val_accuracy: 0.9422\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1669 - accuracy: 0.9578 - val_loss: 0.2389 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9594Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.1535 - accuracy: 0.9594 - val_loss: 0.2888 - val_accuracy: 0.9378\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4348 - accuracy: 0.8980 - val_loss: 0.2159 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9438 - val_loss: 0.1788 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1790 - accuracy: 0.9500 - val_loss: 0.1991 - val_accuracy: 0.9473\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9566 - val_loss: 0.2451 - val_accuracy: 0.9413\n",
      "Epoch 5/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9594Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1472 - accuracy: 0.9593 - val_loss: 0.2196 - val_accuracy: 0.9480\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4172 - accuracy: 0.9016 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2039 - accuracy: 0.9416 - val_loss: 0.2162 - val_accuracy: 0.9378\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9486 - val_loss: 0.2284 - val_accuracy: 0.9413\n",
      "Epoch 4/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9546Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1719 - accuracy: 0.9545 - val_loss: 0.2309 - val_accuracy: 0.9442\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.8971 - val_loss: 0.2158 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2104 - accuracy: 0.9401 - val_loss: 0.2638 - val_accuracy: 0.9278\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1842 - accuracy: 0.9496 - val_loss: 0.1863 - val_accuracy: 0.9518\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1705 - accuracy: 0.9542 - val_loss: 0.2097 - val_accuracy: 0.9449\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1454 - accuracy: 0.9621 - val_loss: 0.2794 - val_accuracy: 0.9446\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9605Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1506 - accuracy: 0.9605 - val_loss: 0.2327 - val_accuracy: 0.9515\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 5s 4ms/step - loss: 0.4908 - accuracy: 0.8894 - val_loss: 0.2508 - val_accuracy: 0.9266\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2197 - accuracy: 0.9366 - val_loss: 0.2353 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.1994 - val_accuracy: 0.9476\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.9513 - val_loss: 0.2301 - val_accuracy: 0.9436\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1688 - accuracy: 0.9539 - val_loss: 0.2435 - val_accuracy: 0.9427\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1490 - accuracy: 0.9597 - val_loss: 0.1903 - val_accuracy: 0.9554\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1488 - accuracy: 0.9608 - val_loss: 0.2575 - val_accuracy: 0.9509\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1446 - accuracy: 0.9612 - val_loss: 0.2121 - val_accuracy: 0.9520\n",
      "Epoch 9/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9640Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9642 - val_loss: 0.2299 - val_accuracy: 0.9532\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5509 - accuracy: 0.8869 - val_loss: 0.2348 - val_accuracy: 0.9325\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2299 - accuracy: 0.9343 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1961 - accuracy: 0.9447 - val_loss: 0.2266 - val_accuracy: 0.9373\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1812 - accuracy: 0.9484 - val_loss: 0.2027 - val_accuracy: 0.9452\n",
      "Epoch 5/20\n",
      " 981/1000 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9501Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1872 - accuracy: 0.9499 - val_loss: 0.2695 - val_accuracy: 0.9417\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5164 - accuracy: 0.8899 - val_loss: 0.2248 - val_accuracy: 0.9331\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2207 - accuracy: 0.9379 - val_loss: 0.2380 - val_accuracy: 0.9341\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2035 - accuracy: 0.9436 - val_loss: 0.1979 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1743 - accuracy: 0.9517 - val_loss: 0.2050 - val_accuracy: 0.9464\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1677 - accuracy: 0.9550 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9574 - val_loss: 0.2913 - val_accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.9600 - val_loss: 0.1936 - val_accuracy: 0.9512\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1459 - accuracy: 0.9622 - val_loss: 0.1980 - val_accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1317 - accuracy: 0.9648 - val_loss: 0.2164 - val_accuracy: 0.9532\n",
      "Epoch 10/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9664Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1294 - accuracy: 0.9665 - val_loss: 0.2374 - val_accuracy: 0.9458\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4226 - accuracy: 0.8986 - val_loss: 0.1952 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2005 - accuracy: 0.9430 - val_loss: 0.1825 - val_accuracy: 0.9503\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1819 - accuracy: 0.9488 - val_loss: 0.2359 - val_accuracy: 0.9393\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1744 - accuracy: 0.9543 - val_loss: 0.2183 - val_accuracy: 0.9479\n",
      "Epoch 5/20\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9559Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1690 - accuracy: 0.9557 - val_loss: 0.2075 - val_accuracy: 0.9467\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4191 - accuracy: 0.9008 - val_loss: 0.2129 - val_accuracy: 0.9443\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2017 - accuracy: 0.9419 - val_loss: 0.2343 - val_accuracy: 0.9372\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1762 - accuracy: 0.9516 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1599 - accuracy: 0.9559 - val_loss: 0.2179 - val_accuracy: 0.9425\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9589 - val_loss: 0.1856 - val_accuracy: 0.9547\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1329 - accuracy: 0.9635 - val_loss: 0.2607 - val_accuracy: 0.9460\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1378 - accuracy: 0.9652 - val_loss: 0.1983 - val_accuracy: 0.9557\n",
      "Epoch 8/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9677Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.2268 - val_accuracy: 0.9506\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4049 - accuracy: 0.9005 - val_loss: 0.2117 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1990 - accuracy: 0.9438 - val_loss: 0.2052 - val_accuracy: 0.9449\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1842 - accuracy: 0.9498 - val_loss: 0.2145 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1557 - accuracy: 0.9593 - val_loss: 0.2050 - val_accuracy: 0.9476\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9635 - val_loss: 0.2122 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9630 - val_loss: 0.2675 - val_accuracy: 0.9433\n",
      "Epoch 7/20\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1274 - accuracy: 0.9674 - val_loss: 0.2051 - val_accuracy: 0.9521\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4352 - accuracy: 0.8923 - val_loss: 0.2341 - val_accuracy: 0.9326\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2242 - accuracy: 0.9358 - val_loss: 0.2526 - val_accuracy: 0.9295\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2008 - accuracy: 0.9446 - val_loss: 0.1929 - val_accuracy: 0.9470\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9502 - val_loss: 0.2567 - val_accuracy: 0.9317\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1722 - accuracy: 0.9558 - val_loss: 0.2288 - val_accuracy: 0.9441\n",
      "Epoch 6/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9586Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.2248 - val_accuracy: 0.9463\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4470 - accuracy: 0.8929 - val_loss: 0.2378 - val_accuracy: 0.9299\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2188 - accuracy: 0.9380 - val_loss: 0.2170 - val_accuracy: 0.9402\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1962 - accuracy: 0.9454 - val_loss: 0.2463 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9518 - val_loss: 0.1830 - val_accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9567 - val_loss: 0.2282 - val_accuracy: 0.9493\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9594 - val_loss: 0.2234 - val_accuracy: 0.9524\n",
      "Epoch 7/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9604Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1544 - accuracy: 0.9603 - val_loss: 0.2089 - val_accuracy: 0.9528\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4591 - accuracy: 0.8910 - val_loss: 0.2917 - val_accuracy: 0.9123\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9369 - val_loss: 0.2329 - val_accuracy: 0.9335\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1986 - accuracy: 0.9452 - val_loss: 0.1767 - val_accuracy: 0.9496\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9535 - val_loss: 0.2029 - val_accuracy: 0.9505\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1791 - accuracy: 0.9541 - val_loss: 0.2061 - val_accuracy: 0.9543\n",
      "Epoch 6/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9609Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1448 - accuracy: 0.9607 - val_loss: 0.2128 - val_accuracy: 0.9468\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.9037 - val_loss: 0.2131 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9429 - val_loss: 0.2167 - val_accuracy: 0.9357\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9534 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1521 - accuracy: 0.9597 - val_loss: 0.2601 - val_accuracy: 0.9349\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1426 - accuracy: 0.9639 - val_loss: 0.2146 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9671Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1306 - accuracy: 0.9670 - val_loss: 0.1970 - val_accuracy: 0.9564\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.3979 - accuracy: 0.9023 - val_loss: 0.2233 - val_accuracy: 0.9379\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1894 - accuracy: 0.9474 - val_loss: 0.2573 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1691 - accuracy: 0.9524 - val_loss: 0.2485 - val_accuracy: 0.9383\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1533 - accuracy: 0.9581 - val_loss: 0.2020 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9602 - val_loss: 0.2438 - val_accuracy: 0.9417\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1359 - accuracy: 0.9638 - val_loss: 0.2422 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1302 - accuracy: 0.9671 - val_loss: 0.2017 - val_accuracy: 0.9574\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1224 - accuracy: 0.9682 - val_loss: 0.2283 - val_accuracy: 0.9563\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1206 - accuracy: 0.9712 - val_loss: 0.2381 - val_accuracy: 0.9490\n",
      "Epoch 10/20\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9731Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1052 - accuracy: 0.9731 - val_loss: 0.2271 - val_accuracy: 0.9602\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4224 - accuracy: 0.9010 - val_loss: 0.2183 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2024 - accuracy: 0.9427 - val_loss: 0.2455 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1838 - accuracy: 0.9499 - val_loss: 0.2165 - val_accuracy: 0.9423\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9545 - val_loss: 0.2359 - val_accuracy: 0.9482\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1665 - accuracy: 0.9568 - val_loss: 0.1972 - val_accuracy: 0.9556\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1421 - accuracy: 0.9635 - val_loss: 0.1994 - val_accuracy: 0.9533\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1350 - accuracy: 0.9648 - val_loss: 0.2156 - val_accuracy: 0.9549\n",
      "Epoch 8/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9678Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9677 - val_loss: 0.2097 - val_accuracy: 0.9540\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5085 - accuracy: 0.8851 - val_loss: 0.2566 - val_accuracy: 0.9224\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2319 - accuracy: 0.9339 - val_loss: 0.2354 - val_accuracy: 0.9353\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2159 - accuracy: 0.9413 - val_loss: 0.2070 - val_accuracy: 0.9442\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1844 - accuracy: 0.9477 - val_loss: 0.2541 - val_accuracy: 0.9352\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9501 - val_loss: 0.2777 - val_accuracy: 0.9363\n",
      "Epoch 6/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9545Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1739 - accuracy: 0.9544 - val_loss: 0.2171 - val_accuracy: 0.9482\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5129 - accuracy: 0.8878 - val_loss: 0.2353 - val_accuracy: 0.9289\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9392 - val_loss: 0.2228 - val_accuracy: 0.9370\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1900 - accuracy: 0.9473 - val_loss: 0.1972 - val_accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1826 - accuracy: 0.9514 - val_loss: 0.2241 - val_accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1667 - accuracy: 0.9550 - val_loss: 0.2104 - val_accuracy: 0.9464\n",
      "Epoch 6/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 0.1564 - accuracy: 0.9578Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 0.1985 - val_accuracy: 0.9535\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4856 - accuracy: 0.8899 - val_loss: 0.2299 - val_accuracy: 0.9319\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2218 - accuracy: 0.9368 - val_loss: 0.2687 - val_accuracy: 0.9251\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1910 - accuracy: 0.9472 - val_loss: 0.1983 - val_accuracy: 0.9465\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1880 - accuracy: 0.9486 - val_loss: 0.2874 - val_accuracy: 0.9422\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1669 - accuracy: 0.9578 - val_loss: 0.2389 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9595Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9594 - val_loss: 0.2888 - val_accuracy: 0.9378\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4348 - accuracy: 0.8980 - val_loss: 0.2159 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9438 - val_loss: 0.1788 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1790 - accuracy: 0.9500 - val_loss: 0.1991 - val_accuracy: 0.9473\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9566 - val_loss: 0.2451 - val_accuracy: 0.9413\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9593Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1472 - accuracy: 0.9593 - val_loss: 0.2196 - val_accuracy: 0.9480\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4172 - accuracy: 0.9016 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2039 - accuracy: 0.9416 - val_loss: 0.2162 - val_accuracy: 0.9378\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1841 - accuracy: 0.9486 - val_loss: 0.2284 - val_accuracy: 0.9413\n",
      "Epoch 4/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9546Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1719 - accuracy: 0.9545 - val_loss: 0.2309 - val_accuracy: 0.9442\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.8971 - val_loss: 0.2158 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2104 - accuracy: 0.9401 - val_loss: 0.2638 - val_accuracy: 0.9278\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1842 - accuracy: 0.9496 - val_loss: 0.1863 - val_accuracy: 0.9518\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1705 - accuracy: 0.9542 - val_loss: 0.2097 - val_accuracy: 0.9449\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1454 - accuracy: 0.9621 - val_loss: 0.2794 - val_accuracy: 0.9446\n",
      "Epoch 6/20\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9604Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1506 - accuracy: 0.9605 - val_loss: 0.2327 - val_accuracy: 0.9515\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4908 - accuracy: 0.8894 - val_loss: 0.2508 - val_accuracy: 0.9266\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2197 - accuracy: 0.9366 - val_loss: 0.2353 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.1994 - val_accuracy: 0.9476\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.9513 - val_loss: 0.2301 - val_accuracy: 0.9436\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1688 - accuracy: 0.9539 - val_loss: 0.2435 - val_accuracy: 0.9427\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.9597 - val_loss: 0.1903 - val_accuracy: 0.9554\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1488 - accuracy: 0.9608 - val_loss: 0.2575 - val_accuracy: 0.9509\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1446 - accuracy: 0.9612 - val_loss: 0.2121 - val_accuracy: 0.9520\n",
      "Epoch 9/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9641Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9642 - val_loss: 0.2299 - val_accuracy: 0.9532\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5509 - accuracy: 0.8869 - val_loss: 0.2348 - val_accuracy: 0.9325\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2299 - accuracy: 0.9343 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1961 - accuracy: 0.9447 - val_loss: 0.2266 - val_accuracy: 0.9373\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1812 - accuracy: 0.9484 - val_loss: 0.2027 - val_accuracy: 0.9452\n",
      "Epoch 5/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9498Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1872 - accuracy: 0.9499 - val_loss: 0.2695 - val_accuracy: 0.9417\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5164 - accuracy: 0.8899 - val_loss: 0.2248 - val_accuracy: 0.9331\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2207 - accuracy: 0.9379 - val_loss: 0.2380 - val_accuracy: 0.9341\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2035 - accuracy: 0.9436 - val_loss: 0.1979 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1743 - accuracy: 0.9517 - val_loss: 0.2050 - val_accuracy: 0.9464\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1677 - accuracy: 0.9550 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9574 - val_loss: 0.2913 - val_accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.9600 - val_loss: 0.1936 - val_accuracy: 0.9512\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1459 - accuracy: 0.9622 - val_loss: 0.1980 - val_accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1317 - accuracy: 0.9648 - val_loss: 0.2164 - val_accuracy: 0.9532\n",
      "Epoch 10/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9666Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1294 - accuracy: 0.9665 - val_loss: 0.2374 - val_accuracy: 0.9458\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4226 - accuracy: 0.8986 - val_loss: 0.1952 - val_accuracy: 0.9392\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2005 - accuracy: 0.9430 - val_loss: 0.1825 - val_accuracy: 0.9503\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1819 - accuracy: 0.9488 - val_loss: 0.2359 - val_accuracy: 0.9393\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1744 - accuracy: 0.9543 - val_loss: 0.2183 - val_accuracy: 0.9479\n",
      "Epoch 5/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9556Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1690 - accuracy: 0.9557 - val_loss: 0.2075 - val_accuracy: 0.9467\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4191 - accuracy: 0.9008 - val_loss: 0.2129 - val_accuracy: 0.9443\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2017 - accuracy: 0.9419 - val_loss: 0.2343 - val_accuracy: 0.9372\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1762 - accuracy: 0.9516 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1599 - accuracy: 0.9559 - val_loss: 0.2179 - val_accuracy: 0.9425\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9589 - val_loss: 0.1856 - val_accuracy: 0.9547\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1329 - accuracy: 0.9635 - val_loss: 0.2607 - val_accuracy: 0.9460\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1378 - accuracy: 0.9652 - val_loss: 0.1983 - val_accuracy: 0.9557\n",
      "Epoch 8/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9677Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.2268 - val_accuracy: 0.9506\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4049 - accuracy: 0.9005 - val_loss: 0.2117 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1990 - accuracy: 0.9438 - val_loss: 0.2052 - val_accuracy: 0.9449\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1842 - accuracy: 0.9498 - val_loss: 0.2145 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1557 - accuracy: 0.9593 - val_loss: 0.2050 - val_accuracy: 0.9476\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9635 - val_loss: 0.2122 - val_accuracy: 0.9572\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9630 - val_loss: 0.2675 - val_accuracy: 0.9433\n",
      "Epoch 7/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1274 - accuracy: 0.9674 - val_loss: 0.2051 - val_accuracy: 0.9521\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4352 - accuracy: 0.8923 - val_loss: 0.2341 - val_accuracy: 0.9326\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2242 - accuracy: 0.9358 - val_loss: 0.2526 - val_accuracy: 0.9295\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2008 - accuracy: 0.9446 - val_loss: 0.1929 - val_accuracy: 0.9470\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9502 - val_loss: 0.2567 - val_accuracy: 0.9317\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1722 - accuracy: 0.9558 - val_loss: 0.2288 - val_accuracy: 0.9441\n",
      "Epoch 6/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9585Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.2248 - val_accuracy: 0.9463\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4470 - accuracy: 0.8929 - val_loss: 0.2378 - val_accuracy: 0.9299\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2188 - accuracy: 0.9380 - val_loss: 0.2170 - val_accuracy: 0.9402\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1962 - accuracy: 0.9454 - val_loss: 0.2463 - val_accuracy: 0.9378\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9518 - val_loss: 0.1830 - val_accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9567 - val_loss: 0.2282 - val_accuracy: 0.9493\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9594 - val_loss: 0.2234 - val_accuracy: 0.9524\n",
      "Epoch 7/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9605Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1544 - accuracy: 0.9603 - val_loss: 0.2089 - val_accuracy: 0.9528\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4591 - accuracy: 0.8910 - val_loss: 0.2917 - val_accuracy: 0.9123\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9369 - val_loss: 0.2329 - val_accuracy: 0.9335\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1986 - accuracy: 0.9452 - val_loss: 0.1767 - val_accuracy: 0.9496\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9535 - val_loss: 0.2029 - val_accuracy: 0.9505\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1791 - accuracy: 0.9541 - val_loss: 0.2061 - val_accuracy: 0.9543\n",
      "Epoch 6/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9608Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1448 - accuracy: 0.9607 - val_loss: 0.2128 - val_accuracy: 0.9468\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.9037 - val_loss: 0.2131 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9429 - val_loss: 0.2167 - val_accuracy: 0.9357\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9534 - val_loss: 0.1920 - val_accuracy: 0.9475\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1521 - accuracy: 0.9597 - val_loss: 0.2601 - val_accuracy: 0.9349\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1426 - accuracy: 0.9639 - val_loss: 0.2146 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9671Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1306 - accuracy: 0.9670 - val_loss: 0.1970 - val_accuracy: 0.9564\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3979 - accuracy: 0.9023 - val_loss: 0.2233 - val_accuracy: 0.9379\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1894 - accuracy: 0.9474 - val_loss: 0.2573 - val_accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1691 - accuracy: 0.9524 - val_loss: 0.2485 - val_accuracy: 0.9383\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1533 - accuracy: 0.9581 - val_loss: 0.2020 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9602 - val_loss: 0.2438 - val_accuracy: 0.9417\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1359 - accuracy: 0.9638 - val_loss: 0.2422 - val_accuracy: 0.9482\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1302 - accuracy: 0.9671 - val_loss: 0.2017 - val_accuracy: 0.9574\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1224 - accuracy: 0.9682 - val_loss: 0.2283 - val_accuracy: 0.9563\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1206 - accuracy: 0.9712 - val_loss: 0.2381 - val_accuracy: 0.9490\n",
      "Epoch 10/20\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9731Restoring model weights from the end of the best epoch: 7.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1052 - accuracy: 0.9731 - val_loss: 0.2271 - val_accuracy: 0.9602\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4224 - accuracy: 0.9010 - val_loss: 0.2183 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2024 - accuracy: 0.9427 - val_loss: 0.2455 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1838 - accuracy: 0.9499 - val_loss: 0.2165 - val_accuracy: 0.9423\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9545 - val_loss: 0.2359 - val_accuracy: 0.9482\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1665 - accuracy: 0.9568 - val_loss: 0.1972 - val_accuracy: 0.9556\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1421 - accuracy: 0.9635 - val_loss: 0.1994 - val_accuracy: 0.9533\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1350 - accuracy: 0.9648 - val_loss: 0.2156 - val_accuracy: 0.9549\n",
      "Epoch 8/20\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9679Restoring model weights from the end of the best epoch: 5.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1261 - accuracy: 0.9677 - val_loss: 0.2097 - val_accuracy: 0.9540\n",
      "Epoch 8: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5085 - accuracy: 0.8851 - val_loss: 0.2566 - val_accuracy: 0.9224\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2319 - accuracy: 0.9339 - val_loss: 0.2354 - val_accuracy: 0.9353\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2159 - accuracy: 0.9413 - val_loss: 0.2070 - val_accuracy: 0.9442\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1844 - accuracy: 0.9477 - val_loss: 0.2541 - val_accuracy: 0.9352\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9501 - val_loss: 0.2777 - val_accuracy: 0.9363\n",
      "Epoch 6/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 0.1729 - accuracy: 0.9545Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1739 - accuracy: 0.9544 - val_loss: 0.2171 - val_accuracy: 0.9482\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5129 - accuracy: 0.8878 - val_loss: 0.2353 - val_accuracy: 0.9289\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9392 - val_loss: 0.2228 - val_accuracy: 0.9370\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1900 - accuracy: 0.9473 - val_loss: 0.1972 - val_accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1826 - accuracy: 0.9514 - val_loss: 0.2241 - val_accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1667 - accuracy: 0.9550 - val_loss: 0.2104 - val_accuracy: 0.9464\n",
      "Epoch 6/20\n",
      " 977/1000 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9574Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1564 - accuracy: 0.9578 - val_loss: 0.1985 - val_accuracy: 0.9535\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4856 - accuracy: 0.8899 - val_loss: 0.2299 - val_accuracy: 0.9319\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2218 - accuracy: 0.9368 - val_loss: 0.2687 - val_accuracy: 0.9251\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1910 - accuracy: 0.9472 - val_loss: 0.1983 - val_accuracy: 0.9465\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1880 - accuracy: 0.9486 - val_loss: 0.2874 - val_accuracy: 0.9422\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1669 - accuracy: 0.9578 - val_loss: 0.2389 - val_accuracy: 0.9468\n",
      "Epoch 6/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9594Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9594 - val_loss: 0.2888 - val_accuracy: 0.9378\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4348 - accuracy: 0.8980 - val_loss: 0.2159 - val_accuracy: 0.9367\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9438 - val_loss: 0.1788 - val_accuracy: 0.9513\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1790 - accuracy: 0.9500 - val_loss: 0.1991 - val_accuracy: 0.9473\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9566 - val_loss: 0.2451 - val_accuracy: 0.9413\n",
      "Epoch 5/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9593Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1472 - accuracy: 0.9593 - val_loss: 0.2196 - val_accuracy: 0.9480\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4172 - accuracy: 0.9016 - val_loss: 0.2156 - val_accuracy: 0.9362\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2039 - accuracy: 0.9416 - val_loss: 0.2162 - val_accuracy: 0.9378\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9486 - val_loss: 0.2284 - val_accuracy: 0.9413\n",
      "Epoch 4/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9546Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1719 - accuracy: 0.9545 - val_loss: 0.2309 - val_accuracy: 0.9442\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4374 - accuracy: 0.8971 - val_loss: 0.2158 - val_accuracy: 0.9360\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2104 - accuracy: 0.9401 - val_loss: 0.2638 - val_accuracy: 0.9278\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1842 - accuracy: 0.9496 - val_loss: 0.1863 - val_accuracy: 0.9518\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1705 - accuracy: 0.9542 - val_loss: 0.2097 - val_accuracy: 0.9449\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1454 - accuracy: 0.9621 - val_loss: 0.2794 - val_accuracy: 0.9446\n",
      "Epoch 6/20\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9604Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1506 - accuracy: 0.9605 - val_loss: 0.2327 - val_accuracy: 0.9515\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.4908 - accuracy: 0.8894 - val_loss: 0.2508 - val_accuracy: 0.9266\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2197 - accuracy: 0.9366 - val_loss: 0.2353 - val_accuracy: 0.9333\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1947 - accuracy: 0.9449 - val_loss: 0.1994 - val_accuracy: 0.9476\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.9513 - val_loss: 0.2301 - val_accuracy: 0.9436\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1688 - accuracy: 0.9539 - val_loss: 0.2435 - val_accuracy: 0.9427\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.9597 - val_loss: 0.1903 - val_accuracy: 0.9554\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1488 - accuracy: 0.9608 - val_loss: 0.2575 - val_accuracy: 0.9509\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1446 - accuracy: 0.9612 - val_loss: 0.2121 - val_accuracy: 0.9520\n",
      "Epoch 9/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9639Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1369 - accuracy: 0.9642 - val_loss: 0.2299 - val_accuracy: 0.9532\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5509 - accuracy: 0.8869 - val_loss: 0.2348 - val_accuracy: 0.9325\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2299 - accuracy: 0.9343 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1961 - accuracy: 0.9447 - val_loss: 0.2266 - val_accuracy: 0.9373\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1812 - accuracy: 0.9484 - val_loss: 0.2027 - val_accuracy: 0.9452\n",
      "Epoch 5/20\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 0.9499Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1872 - accuracy: 0.9499 - val_loss: 0.2695 - val_accuracy: 0.9417\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 0.5164 - accuracy: 0.8899 - val_loss: 0.2248 - val_accuracy: 0.9331\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2207 - accuracy: 0.9379 - val_loss: 0.2380 - val_accuracy: 0.9341\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2035 - accuracy: 0.9436 - val_loss: 0.1979 - val_accuracy: 0.9449\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1743 - accuracy: 0.9517 - val_loss: 0.2050 - val_accuracy: 0.9464\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1677 - accuracy: 0.9550 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1590 - accuracy: 0.9574 - val_loss: 0.2913 - val_accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.9600 - val_loss: 0.1936 - val_accuracy: 0.9512\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1459 - accuracy: 0.9622 - val_loss: 0.1980 - val_accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1317 - accuracy: 0.9648 - val_loss: 0.2164 - val_accuracy: 0.9532\n",
      "Epoch 10/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9666Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1294 - accuracy: 0.9665 - val_loss: 0.2374 - val_accuracy: 0.9458\n",
      "Epoch 10: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.5593 - accuracy: 0.1127 - val_loss: 2.3061 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3308 - accuracy: 0.1074 - val_loss: 2.3117 - val_accuracy: 0.1018\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1064 - val_loss: 2.3122 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 2.3142 - accuracy: 0.1039Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1035 - val_loss: 2.3186 - val_accuracy: 0.0922\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 3.1788 - accuracy: 0.3647 - val_loss: 1.8440 - val_accuracy: 0.2959\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7855 - accuracy: 0.2948 - val_loss: 1.7761 - val_accuracy: 0.2780\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9747 - accuracy: 0.2158 - val_loss: 1.9386 - val_accuracy: 0.1985\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9439 - accuracy: 0.1914 - val_loss: 1.9673 - val_accuracy: 0.2031\n",
      "Epoch 5/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.9498 - accuracy: 0.2002Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9504 - accuracy: 0.1999 - val_loss: 1.9788 - val_accuracy: 0.1902\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.4617 - accuracy: 0.1779 - val_loss: 2.0311 - val_accuracy: 0.2027\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0130 - accuracy: 0.2032 - val_loss: 2.0374 - val_accuracy: 0.2129\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.2042 - val_loss: 2.0455 - val_accuracy: 0.1922\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0028 - accuracy: 0.2057 - val_loss: 2.0196 - val_accuracy: 0.2046\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0308 - accuracy: 0.2018 - val_loss: 2.0304 - val_accuracy: 0.2003\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0088 - accuracy: 0.2071 - val_loss: 2.0066 - val_accuracy: 0.1991\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0118 - accuracy: 0.2058 - val_loss: 2.0569 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0142 - accuracy: 0.2039 - val_loss: 2.0529 - val_accuracy: 0.1968\n",
      "Epoch 9/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 2.0510 - accuracy: 0.1997Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0512 - accuracy: 0.1996 - val_loss: 2.0691 - val_accuracy: 0.2105\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.3021 - accuracy: 0.1067 - val_loss: 2.3079 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1060 - val_loss: 2.3126 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3132 - val_accuracy: 0.0979\n",
      "Epoch 4/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1034Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3196 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.0352 - accuracy: 0.1090 - val_loss: 2.3137 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3123 - accuracy: 0.1067 - val_loss: 2.3175 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1023 - val_loss: 2.3192 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 2.3131 - accuracy: 0.1036Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3328 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.6637 - accuracy: 0.1010 - val_loss: 2.3196 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3190 - accuracy: 0.1040 - val_loss: 2.3114 - val_accuracy: 0.1083\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3146 - accuracy: 0.1013 - val_loss: 2.3265 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3256 - val_accuracy: 0.0982\n",
      "Epoch 5/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1035 - val_loss: 2.3337 - val_accuracy: 0.0921\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.0823 - accuracy: 0.1712 - val_loss: 2.0584 - val_accuracy: 0.1708\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0646 - accuracy: 0.1894 - val_loss: 1.9772 - val_accuracy: 0.2055\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.1908 - val_loss: 1.9306 - val_accuracy: 0.1781\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9596 - accuracy: 0.1856 - val_loss: 2.0027 - val_accuracy: 0.1832\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9265 - accuracy: 0.1932 - val_loss: 1.9375 - val_accuracy: 0.2002\n",
      "Epoch 6/20\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.9358 - accuracy: 0.1939Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9357 - accuracy: 0.1937 - val_loss: 1.9506 - val_accuracy: 0.1899\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 3.8562 - accuracy: 0.3753 - val_loss: 1.4674 - val_accuracy: 0.4134\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6576 - accuracy: 0.3635 - val_loss: 1.6953 - val_accuracy: 0.3338\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6350 - accuracy: 0.3349 - val_loss: 1.6643 - val_accuracy: 0.2998\n",
      "Epoch 4/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 1.7858 - accuracy: 0.2843Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7854 - accuracy: 0.2841 - val_loss: 1.7529 - val_accuracy: 0.2317\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.8385 - accuracy: 0.3084 - val_loss: 1.7551 - val_accuracy: 0.3402\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6812 - accuracy: 0.3324 - val_loss: 1.7466 - val_accuracy: 0.2679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7869 - accuracy: 0.2438 - val_loss: 1.8375 - val_accuracy: 0.1924\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8278 - accuracy: 0.2005 - val_loss: 1.8167 - val_accuracy: 0.1918\n",
      "Epoch 5/20\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 1.8202 - accuracy: 0.2002Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8239 - accuracy: 0.1992 - val_loss: 1.9457 - val_accuracy: 0.1760\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.4893 - accuracy: 0.1997 - val_loss: 2.0100 - val_accuracy: 0.2116\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.2101 - val_loss: 2.0123 - val_accuracy: 0.2054\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9908 - accuracy: 0.2185 - val_loss: 2.0088 - val_accuracy: 0.2222\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9701 - accuracy: 0.2273 - val_loss: 1.9641 - val_accuracy: 0.2243\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9624 - accuracy: 0.2300 - val_loss: 2.0973 - val_accuracy: 0.1678\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9737 - accuracy: 0.2280 - val_loss: 2.0281 - val_accuracy: 0.2341\n",
      "Epoch 7/20\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.9613 - accuracy: 0.2348Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9615 - accuracy: 0.2346 - val_loss: 2.0091 - val_accuracy: 0.2250\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.6860 - accuracy: 0.1837 - val_loss: 2.1535 - val_accuracy: 0.1628\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0754 - accuracy: 0.1877 - val_loss: 2.0671 - val_accuracy: 0.1848\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1374 - accuracy: 0.1682 - val_loss: 2.0007 - val_accuracy: 0.1767\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9882 - accuracy: 0.1899 - val_loss: 1.9879 - val_accuracy: 0.2048\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0562 - accuracy: 0.1969 - val_loss: 2.1030 - val_accuracy: 0.1950\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0365 - accuracy: 0.1999 - val_loss: 1.9654 - val_accuracy: 0.2022\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0257 - accuracy: 0.1829 - val_loss: 2.1862 - val_accuracy: 0.1513\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9906 - accuracy: 0.1951 - val_loss: 1.9374 - val_accuracy: 0.2052\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9734 - accuracy: 0.1992 - val_loss: 1.9758 - val_accuracy: 0.2043\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9962 - accuracy: 0.1904 - val_loss: 1.9728 - val_accuracy: 0.1899\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9409 - accuracy: 0.1922 - val_loss: 1.9184 - val_accuracy: 0.1853\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9274 - accuracy: 0.1942 - val_loss: 1.9053 - val_accuracy: 0.1858\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9137 - accuracy: 0.1991 - val_loss: 2.0337 - val_accuracy: 0.1844\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9667 - accuracy: 0.1957 - val_loss: 1.9532 - val_accuracy: 0.2033\n",
      "Epoch 15/20\n",
      " 978/1000 [============================>.] - ETA: 0s - loss: 1.9489 - accuracy: 0.1989Restoring model weights from the end of the best epoch: 12.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9482 - accuracy: 0.1991 - val_loss: 1.9386 - val_accuracy: 0.1880\n",
      "Epoch 15: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 6.6868 - accuracy: 0.1501 - val_loss: 2.3219 - val_accuracy: 0.1015\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3251 - accuracy: 0.1115 - val_loss: 2.3108 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1014 - val_loss: 2.3260 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1034 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.2491 - accuracy: 0.1058 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3128 - accuracy: 0.1062 - val_loss: 2.3132 - val_accuracy: 0.1013\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3139 - val_accuracy: 0.0980\n",
      "Epoch 4/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1035 - val_loss: 2.3202 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.3022 - accuracy: 0.2258 - val_loss: 2.0093 - val_accuracy: 0.2374\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8017 - accuracy: 0.2909 - val_loss: 1.7666 - val_accuracy: 0.2988\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7410 - accuracy: 0.3024 - val_loss: 1.7895 - val_accuracy: 0.2937\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7442 - accuracy: 0.2997 - val_loss: 1.7936 - val_accuracy: 0.2953\n",
      "Epoch 5/20\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 1.7949 - accuracy: 0.2882Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7985 - accuracy: 0.2872 - val_loss: 2.0414 - val_accuracy: 0.1961\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.2539 - accuracy: 0.3196 - val_loss: 2.3219 - val_accuracy: 0.0981\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2829 - accuracy: 0.1191 - val_loss: 2.3110 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3148 - accuracy: 0.1011 - val_loss: 2.3262 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1032 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 7.5217 - accuracy: 0.1561 - val_loss: 2.2561 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2853 - accuracy: 0.1190 - val_loss: 2.3181 - val_accuracy: 0.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3122 - accuracy: 0.1061 - val_loss: 2.3188 - val_accuracy: 0.0978\n",
      "Epoch 4/20\n",
      " 988/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3252 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 6.8512 - accuracy: 0.1046 - val_loss: 2.3116 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1071 - val_loss: 2.3143 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3136 - accuracy: 0.1023 - val_loss: 2.3161 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 2.3132 - accuracy: 0.1036Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3295 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 7.7896 - accuracy: 0.1010 - val_loss: 2.3231 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3287 - accuracy: 0.1045 - val_loss: 2.3133 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1016 - val_loss: 2.3279 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3271 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3351 - val_accuracy: 0.0919\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 3.5593 - accuracy: 0.1127 - val_loss: 2.3061 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3308 - accuracy: 0.1074 - val_loss: 2.3117 - val_accuracy: 0.1018\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1064 - val_loss: 2.3122 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 2.3142 - accuracy: 0.1036Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1035 - val_loss: 2.3186 - val_accuracy: 0.0922\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.1788 - accuracy: 0.3647 - val_loss: 1.8440 - val_accuracy: 0.2959\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7855 - accuracy: 0.2948 - val_loss: 1.7761 - val_accuracy: 0.2780\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9747 - accuracy: 0.2158 - val_loss: 1.9386 - val_accuracy: 0.1985\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9439 - accuracy: 0.1914 - val_loss: 1.9673 - val_accuracy: 0.2031\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.9504 - accuracy: 0.1999Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9504 - accuracy: 0.1999 - val_loss: 1.9788 - val_accuracy: 0.1902\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.4617 - accuracy: 0.1779 - val_loss: 2.0311 - val_accuracy: 0.2027\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0130 - accuracy: 0.2032 - val_loss: 2.0374 - val_accuracy: 0.2129\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.2042 - val_loss: 2.0455 - val_accuracy: 0.1922\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0028 - accuracy: 0.2057 - val_loss: 2.0196 - val_accuracy: 0.2046\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0308 - accuracy: 0.2018 - val_loss: 2.0304 - val_accuracy: 0.2003\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0088 - accuracy: 0.2071 - val_loss: 2.0066 - val_accuracy: 0.1991\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0118 - accuracy: 0.2058 - val_loss: 2.0569 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0142 - accuracy: 0.2039 - val_loss: 2.0529 - val_accuracy: 0.1968\n",
      "Epoch 9/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 2.0513 - accuracy: 0.1996Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0512 - accuracy: 0.1996 - val_loss: 2.0691 - val_accuracy: 0.2105\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.3021 - accuracy: 0.1067 - val_loss: 2.3079 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1060 - val_loss: 2.3126 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3132 - val_accuracy: 0.0979\n",
      "Epoch 4/20\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3196 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.0352 - accuracy: 0.1090 - val_loss: 2.3137 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3123 - accuracy: 0.1067 - val_loss: 2.3175 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1023 - val_loss: 2.3192 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2.3131 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3328 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.6637 - accuracy: 0.1010 - val_loss: 2.3196 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3190 - accuracy: 0.1040 - val_loss: 2.3114 - val_accuracy: 0.1083\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1013 - val_loss: 2.3265 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3256 - val_accuracy: 0.0982\n",
      "Epoch 5/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1039Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1035 - val_loss: 2.3337 - val_accuracy: 0.0921\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.0823 - accuracy: 0.1712 - val_loss: 2.0584 - val_accuracy: 0.1708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0646 - accuracy: 0.1894 - val_loss: 1.9772 - val_accuracy: 0.2055\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.1908 - val_loss: 1.9306 - val_accuracy: 0.1781\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9596 - accuracy: 0.1856 - val_loss: 2.0027 - val_accuracy: 0.1832\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9265 - accuracy: 0.1932 - val_loss: 1.9375 - val_accuracy: 0.2002\n",
      "Epoch 6/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.9355 - accuracy: 0.1939Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9357 - accuracy: 0.1937 - val_loss: 1.9506 - val_accuracy: 0.1899\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.8562 - accuracy: 0.3753 - val_loss: 1.4674 - val_accuracy: 0.4134\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6576 - accuracy: 0.3635 - val_loss: 1.6953 - val_accuracy: 0.3338\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6350 - accuracy: 0.3349 - val_loss: 1.6643 - val_accuracy: 0.2998\n",
      "Epoch 4/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 1.7867 - accuracy: 0.2845Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7854 - accuracy: 0.2841 - val_loss: 1.7529 - val_accuracy: 0.2317\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.8385 - accuracy: 0.3084 - val_loss: 1.7551 - val_accuracy: 0.3402\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6812 - accuracy: 0.3324 - val_loss: 1.7466 - val_accuracy: 0.2679\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7869 - accuracy: 0.2438 - val_loss: 1.8375 - val_accuracy: 0.1924\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8278 - accuracy: 0.2005 - val_loss: 1.8167 - val_accuracy: 0.1918\n",
      "Epoch 5/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.8224 - accuracy: 0.1998Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8239 - accuracy: 0.1992 - val_loss: 1.9457 - val_accuracy: 0.1760\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.4893 - accuracy: 0.1997 - val_loss: 2.0100 - val_accuracy: 0.2116\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.2101 - val_loss: 2.0123 - val_accuracy: 0.2054\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9908 - accuracy: 0.2185 - val_loss: 2.0088 - val_accuracy: 0.2222\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9701 - accuracy: 0.2273 - val_loss: 1.9641 - val_accuracy: 0.2243\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9624 - accuracy: 0.2300 - val_loss: 2.0973 - val_accuracy: 0.1678\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9737 - accuracy: 0.2280 - val_loss: 2.0281 - val_accuracy: 0.2341\n",
      "Epoch 7/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.9613 - accuracy: 0.2348Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9615 - accuracy: 0.2346 - val_loss: 2.0091 - val_accuracy: 0.2250\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.6860 - accuracy: 0.1837 - val_loss: 2.1535 - val_accuracy: 0.1628\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0754 - accuracy: 0.1877 - val_loss: 2.0671 - val_accuracy: 0.1848\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1374 - accuracy: 0.1682 - val_loss: 2.0007 - val_accuracy: 0.1767\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9882 - accuracy: 0.1899 - val_loss: 1.9879 - val_accuracy: 0.2048\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0562 - accuracy: 0.1969 - val_loss: 2.1030 - val_accuracy: 0.1950\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0365 - accuracy: 0.1999 - val_loss: 1.9654 - val_accuracy: 0.2022\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0257 - accuracy: 0.1829 - val_loss: 2.1862 - val_accuracy: 0.1513\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9906 - accuracy: 0.1951 - val_loss: 1.9374 - val_accuracy: 0.2052\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9734 - accuracy: 0.1992 - val_loss: 1.9758 - val_accuracy: 0.2043\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9962 - accuracy: 0.1904 - val_loss: 1.9728 - val_accuracy: 0.1899\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9409 - accuracy: 0.1922 - val_loss: 1.9184 - val_accuracy: 0.1853\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9274 - accuracy: 0.1942 - val_loss: 1.9053 - val_accuracy: 0.1858\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9137 - accuracy: 0.1991 - val_loss: 2.0337 - val_accuracy: 0.1844\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9667 - accuracy: 0.1957 - val_loss: 1.9532 - val_accuracy: 0.2033\n",
      "Epoch 15/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 1.9482 - accuracy: 0.1992Restoring model weights from the end of the best epoch: 12.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9482 - accuracy: 0.1991 - val_loss: 1.9386 - val_accuracy: 0.1880\n",
      "Epoch 15: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 6.6868 - accuracy: 0.1501 - val_loss: 2.3219 - val_accuracy: 0.1015\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3251 - accuracy: 0.1115 - val_loss: 2.3108 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1014 - val_loss: 2.3260 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 2.3139 - accuracy: 0.1034Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1034 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 4.2491 - accuracy: 0.1058 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3128 - accuracy: 0.1062 - val_loss: 2.3132 - val_accuracy: 0.1013\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3139 - val_accuracy: 0.0980\n",
      "Epoch 4/20\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1040Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1035 - val_loss: 2.3202 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.3022 - accuracy: 0.2258 - val_loss: 2.0093 - val_accuracy: 0.2374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8017 - accuracy: 0.2909 - val_loss: 1.7666 - val_accuracy: 0.2988\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7410 - accuracy: 0.3024 - val_loss: 1.7895 - val_accuracy: 0.2937\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7442 - accuracy: 0.2997 - val_loss: 1.7936 - val_accuracy: 0.2953\n",
      "Epoch 5/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.7954 - accuracy: 0.2882Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7985 - accuracy: 0.2872 - val_loss: 2.0414 - val_accuracy: 0.1961\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.2539 - accuracy: 0.3196 - val_loss: 2.3219 - val_accuracy: 0.0981\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2829 - accuracy: 0.1191 - val_loss: 2.3110 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3148 - accuracy: 0.1011 - val_loss: 2.3262 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1032 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1036Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 7.5217 - accuracy: 0.1561 - val_loss: 2.2561 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2853 - accuracy: 0.1190 - val_loss: 2.3181 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3122 - accuracy: 0.1061 - val_loss: 2.3188 - val_accuracy: 0.0978\n",
      "Epoch 4/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3252 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 6.8512 - accuracy: 0.1046 - val_loss: 2.3116 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1071 - val_loss: 2.3143 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1023 - val_loss: 2.3161 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 2.3131 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3295 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 7.7896 - accuracy: 0.1010 - val_loss: 2.3231 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3287 - accuracy: 0.1045 - val_loss: 2.3133 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1016 - val_loss: 2.3279 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3271 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1039Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3351 - val_accuracy: 0.0919\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.5593 - accuracy: 0.1127 - val_loss: 2.3061 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3308 - accuracy: 0.1074 - val_loss: 2.3117 - val_accuracy: 0.1018\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1064 - val_loss: 2.3122 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 2.3142 - accuracy: 0.1041Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3142 - accuracy: 0.1035 - val_loss: 2.3186 - val_accuracy: 0.0922\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.1788 - accuracy: 0.3647 - val_loss: 1.8440 - val_accuracy: 0.2959\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7855 - accuracy: 0.2948 - val_loss: 1.7761 - val_accuracy: 0.2780\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9747 - accuracy: 0.2158 - val_loss: 1.9386 - val_accuracy: 0.1985\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9439 - accuracy: 0.1914 - val_loss: 1.9673 - val_accuracy: 0.2031\n",
      "Epoch 5/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.9504 - accuracy: 0.1999Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9504 - accuracy: 0.1999 - val_loss: 1.9788 - val_accuracy: 0.1902\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.4617 - accuracy: 0.1779 - val_loss: 2.0311 - val_accuracy: 0.2027\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0130 - accuracy: 0.2032 - val_loss: 2.0374 - val_accuracy: 0.2129\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.2042 - val_loss: 2.0455 - val_accuracy: 0.1922\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0028 - accuracy: 0.2057 - val_loss: 2.0196 - val_accuracy: 0.2046\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0308 - accuracy: 0.2018 - val_loss: 2.0304 - val_accuracy: 0.2003\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0088 - accuracy: 0.2071 - val_loss: 2.0066 - val_accuracy: 0.1991\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0118 - accuracy: 0.2058 - val_loss: 2.0569 - val_accuracy: 0.2033\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0142 - accuracy: 0.2039 - val_loss: 2.0529 - val_accuracy: 0.1968\n",
      "Epoch 9/20\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 2.0511 - accuracy: 0.1997Restoring model weights from the end of the best epoch: 6.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0512 - accuracy: 0.1996 - val_loss: 2.0691 - val_accuracy: 0.2105\n",
      "Epoch 9: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.3021 - accuracy: 0.1067 - val_loss: 2.3079 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3126 - accuracy: 0.1060 - val_loss: 2.3126 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3132 - val_accuracy: 0.0979\n",
      "Epoch 4/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3196 - val_accuracy: 0.0920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.0352 - accuracy: 0.1090 - val_loss: 2.3137 - val_accuracy: 0.1103\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3123 - accuracy: 0.1067 - val_loss: 2.3175 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3137 - accuracy: 0.1023 - val_loss: 2.3192 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 2.3132 - accuracy: 0.1035Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3328 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.6637 - accuracy: 0.1010 - val_loss: 2.3196 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3190 - accuracy: 0.1040 - val_loss: 2.3114 - val_accuracy: 0.1083\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1013 - val_loss: 2.3265 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3256 - val_accuracy: 0.0982\n",
      "Epoch 5/20\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 2.3139 - accuracy: 0.1036Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1035 - val_loss: 2.3337 - val_accuracy: 0.0921\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.0823 - accuracy: 0.1712 - val_loss: 2.0584 - val_accuracy: 0.1708\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0646 - accuracy: 0.1894 - val_loss: 1.9772 - val_accuracy: 0.2055\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.1908 - val_loss: 1.9306 - val_accuracy: 0.1781\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9596 - accuracy: 0.1856 - val_loss: 2.0027 - val_accuracy: 0.1832\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9265 - accuracy: 0.1932 - val_loss: 1.9375 - val_accuracy: 0.2002\n",
      "Epoch 6/20\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.9360 - accuracy: 0.1938Restoring model weights from the end of the best epoch: 3.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9357 - accuracy: 0.1937 - val_loss: 1.9506 - val_accuracy: 0.1899\n",
      "Epoch 6: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 3.8562 - accuracy: 0.3753 - val_loss: 1.4674 - val_accuracy: 0.4134\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6576 - accuracy: 0.3635 - val_loss: 1.6953 - val_accuracy: 0.3338\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6350 - accuracy: 0.3349 - val_loss: 1.6643 - val_accuracy: 0.2998\n",
      "Epoch 4/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.7861 - accuracy: 0.2844Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7854 - accuracy: 0.2841 - val_loss: 1.7529 - val_accuracy: 0.2317\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.8385 - accuracy: 0.3084 - val_loss: 1.7551 - val_accuracy: 0.3402\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6812 - accuracy: 0.3324 - val_loss: 1.7466 - val_accuracy: 0.2679\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7869 - accuracy: 0.2438 - val_loss: 1.8375 - val_accuracy: 0.1924\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8278 - accuracy: 0.2005 - val_loss: 1.8167 - val_accuracy: 0.1918\n",
      "Epoch 5/20\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.8219 - accuracy: 0.2000Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8239 - accuracy: 0.1992 - val_loss: 1.9457 - val_accuracy: 0.1760\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 5.4893 - accuracy: 0.1997 - val_loss: 2.0100 - val_accuracy: 0.2116\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0020 - accuracy: 0.2101 - val_loss: 2.0123 - val_accuracy: 0.2054\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9908 - accuracy: 0.2185 - val_loss: 2.0088 - val_accuracy: 0.2222\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9701 - accuracy: 0.2273 - val_loss: 1.9641 - val_accuracy: 0.2243\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9624 - accuracy: 0.2300 - val_loss: 2.0973 - val_accuracy: 0.1678\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9737 - accuracy: 0.2280 - val_loss: 2.0281 - val_accuracy: 0.2341\n",
      "Epoch 7/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.9613 - accuracy: 0.2347Restoring model weights from the end of the best epoch: 4.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9615 - accuracy: 0.2346 - val_loss: 2.0091 - val_accuracy: 0.2250\n",
      "Epoch 7: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.6860 - accuracy: 0.1837 - val_loss: 2.1535 - val_accuracy: 0.1628\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0754 - accuracy: 0.1877 - val_loss: 2.0671 - val_accuracy: 0.1848\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1374 - accuracy: 0.1682 - val_loss: 2.0007 - val_accuracy: 0.1767\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9882 - accuracy: 0.1899 - val_loss: 1.9879 - val_accuracy: 0.2048\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0562 - accuracy: 0.1969 - val_loss: 2.1030 - val_accuracy: 0.1950\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0365 - accuracy: 0.1999 - val_loss: 1.9654 - val_accuracy: 0.2022\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0257 - accuracy: 0.1829 - val_loss: 2.1862 - val_accuracy: 0.1513\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9906 - accuracy: 0.1951 - val_loss: 1.9374 - val_accuracy: 0.2052\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9734 - accuracy: 0.1992 - val_loss: 1.9758 - val_accuracy: 0.2043\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9962 - accuracy: 0.1904 - val_loss: 1.9728 - val_accuracy: 0.1899\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9409 - accuracy: 0.1922 - val_loss: 1.9184 - val_accuracy: 0.1853\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9274 - accuracy: 0.1942 - val_loss: 1.9053 - val_accuracy: 0.1858\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9137 - accuracy: 0.1991 - val_loss: 2.0337 - val_accuracy: 0.1844\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9667 - accuracy: 0.1957 - val_loss: 1.9532 - val_accuracy: 0.2033\n",
      "Epoch 15/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.9486 - accuracy: 0.1991Restoring model weights from the end of the best epoch: 12.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.9482 - accuracy: 0.1991 - val_loss: 1.9386 - val_accuracy: 0.1880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 6.6868 - accuracy: 0.1501 - val_loss: 2.3219 - val_accuracy: 0.1015\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3251 - accuracy: 0.1115 - val_loss: 2.3108 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3147 - accuracy: 0.1014 - val_loss: 2.3260 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1030 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1035Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1034 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.2491 - accuracy: 0.1058 - val_loss: 2.3083 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3128 - accuracy: 0.1062 - val_loss: 2.3132 - val_accuracy: 0.1013\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3121 - accuracy: 0.1063 - val_loss: 2.3139 - val_accuracy: 0.0980\n",
      "Epoch 4/20\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 2.3144 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1035 - val_loss: 2.3202 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 4.3022 - accuracy: 0.2258 - val_loss: 2.0093 - val_accuracy: 0.2374\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8017 - accuracy: 0.2909 - val_loss: 1.7666 - val_accuracy: 0.2988\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7410 - accuracy: 0.3024 - val_loss: 1.7895 - val_accuracy: 0.2937\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7442 - accuracy: 0.2997 - val_loss: 1.7936 - val_accuracy: 0.2953\n",
      "Epoch 5/20\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.7950 - accuracy: 0.2882Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.7985 - accuracy: 0.2872 - val_loss: 2.0414 - val_accuracy: 0.1961\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 5.2539 - accuracy: 0.3196 - val_loss: 2.3219 - val_accuracy: 0.0981\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2829 - accuracy: 0.1191 - val_loss: 2.3110 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3148 - accuracy: 0.1011 - val_loss: 2.3262 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1032 - val_loss: 2.3252 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1037Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3331 - val_accuracy: 0.0920\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 7.5217 - accuracy: 0.1561 - val_loss: 2.2561 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2853 - accuracy: 0.1190 - val_loss: 2.3181 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3122 - accuracy: 0.1061 - val_loss: 2.3188 - val_accuracy: 0.0978\n",
      "Epoch 4/20\n",
      " 982/1000 [============================>.] - ETA: 0s - loss: 2.3143 - accuracy: 0.1039Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3143 - accuracy: 0.1034 - val_loss: 2.3252 - val_accuracy: 0.0920\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 6.8512 - accuracy: 0.1046 - val_loss: 2.3116 - val_accuracy: 0.1102\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3120 - accuracy: 0.1071 - val_loss: 2.3143 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3136 - accuracy: 0.1023 - val_loss: 2.3161 - val_accuracy: 0.0967\n",
      "Epoch 4/20\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2.3131 - accuracy: 0.1038Restoring model weights from the end of the best epoch: 1.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3295 - val_accuracy: 0.0981\n",
      "Epoch 4: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 7.7896 - accuracy: 0.1010 - val_loss: 2.3231 - val_accuracy: 0.0979\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3287 - accuracy: 0.1045 - val_loss: 2.3133 - val_accuracy: 0.1082\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3146 - accuracy: 0.1016 - val_loss: 2.3279 - val_accuracy: 0.0981\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3138 - accuracy: 0.1032 - val_loss: 2.3271 - val_accuracy: 0.0981\n",
      "Epoch 5/20\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 2.3138 - accuracy: 0.1039Restoring model weights from the end of the best epoch: 2.\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3139 - accuracy: 0.1035 - val_loss: 2.3351 - val_accuracy: 0.0919\n",
      "Epoch 5: early stopping\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2739 - accuracy: 0.9198 - val_loss: 0.1556 - val_accuracy: 0.9520\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1041 - accuracy: 0.9682 - val_loss: 0.0929 - val_accuracy: 0.9722\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0695 - accuracy: 0.9770 - val_loss: 0.1024 - val_accuracy: 0.9690\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.0868 - val_accuracy: 0.9762\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.1093 - val_accuracy: 0.9720\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 7/20\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9913Restoring model weights from the end of the best epoch: 4.\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.1084 - val_accuracy: 0.9772\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    SGD_grid_result = SGD_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc54290",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.974021 using {'optimizer_learning_rate': 0.001, 'optimizer_momentum': 0.0, 'unitsHL1': 750, 'unitsHL2': 400}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (SGD_grid_result.best_score_, SGD_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46b15a",
   "metadata": {},
   "source": [
    "### Grid search results : Layers and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2400c1",
   "metadata": {},
   "source": [
    "Every Grid search was set to `epochs = 20` with `earlystopping callback` to stop training when the `val_loss` metric stops improving.\n",
    "\n",
    "The `batch_size = 32` is the default if no value is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921db700",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best score</th>\n",
       "      <th>optimizer_learning_rate</th>\n",
       "      <th>unitsHL1</th>\n",
       "      <th>unitsHL2</th>\n",
       "      <th>optimizer_momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>0.974958</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSprop</th>\n",
       "      <td>0.974958</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.974021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>750</td>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         best score  optimizer_learning_rate  unitsHL1  unitsHL2  \\\n",
       "Adam       0.974958                    0.001       750       200   \n",
       "RMSprop    0.974958                    0.001       750       200   \n",
       "SGD        0.974021                    0.001       750       400   \n",
       "\n",
       "         optimizer_momentum  \n",
       "Adam                    NaN  \n",
       "RMSprop                 0.0  \n",
       "SGD                     0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_results = {\"best score\": adam_grid_result.best_score_} | adam_grid_result.best_params_\n",
    "RMSprop_results = {\"best score\": RMSprop_grid_result.best_score_} | RMSprop_grid_result.best_params_\n",
    "SGD_results = {\"best score\": SGD_grid_result.best_score_} | SGD_grid_result.best_params_\n",
    "\n",
    "index_labels = ['Adam','RMSprop','SGD']\n",
    "results = [adam_results,RMSprop_results,SGD_results]\n",
    "pd.DataFrame(results,index=index_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0487f2a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2656 - accuracy: 0.9194 - val_loss: 0.1549 - val_accuracy: 0.9537\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1071 - accuracy: 0.9664 - val_loss: 0.0971 - val_accuracy: 0.9708\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0701 - accuracy: 0.9771 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0786 - val_accuracy: 0.9770\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 0.1006 - val_accuracy: 0.9738\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.1074 - val_accuracy: 0.9721\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0852 - val_accuracy: 0.9794\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.1116 - val_accuracy: 0.9768\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2918 - accuracy: 0.9179 - val_loss: 0.1373 - val_accuracy: 0.9581\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1074 - accuracy: 0.9689 - val_loss: 0.1147 - val_accuracy: 0.9704\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0805 - accuracy: 0.9784 - val_loss: 0.1307 - val_accuracy: 0.9705\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0682 - accuracy: 0.9823 - val_loss: 0.1416 - val_accuracy: 0.9722\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0543 - accuracy: 0.9858 - val_loss: 0.1923 - val_accuracy: 0.9685\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0477 - accuracy: 0.9886 - val_loss: 0.1633 - val_accuracy: 0.9753\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9536 - accuracy: 0.7426 - val_loss: 0.5759 - val_accuracy: 0.8505\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5043 - accuracy: 0.8650 - val_loss: 0.4475 - val_accuracy: 0.8757\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4267 - accuracy: 0.8817 - val_loss: 0.3997 - val_accuracy: 0.8864\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3887 - accuracy: 0.8902 - val_loss: 0.3731 - val_accuracy: 0.8906\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3652 - accuracy: 0.8968 - val_loss: 0.3534 - val_accuracy: 0.8992\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3484 - accuracy: 0.9007 - val_loss: 0.3378 - val_accuracy: 0.9027\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3353 - accuracy: 0.9048 - val_loss: 0.3274 - val_accuracy: 0.9072\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3244 - accuracy: 0.9073 - val_loss: 0.3204 - val_accuracy: 0.9087\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3160 - accuracy: 0.9098 - val_loss: 0.3100 - val_accuracy: 0.9124\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3082 - accuracy: 0.9119 - val_loss: 0.3046 - val_accuracy: 0.9137\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3010 - accuracy: 0.9141 - val_loss: 0.3062 - val_accuracy: 0.9113\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9161 - val_loss: 0.2964 - val_accuracy: 0.9151\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2899 - accuracy: 0.9176 - val_loss: 0.2892 - val_accuracy: 0.9185\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2844 - accuracy: 0.9186 - val_loss: 0.2849 - val_accuracy: 0.9177\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2795 - accuracy: 0.9201 - val_loss: 0.2808 - val_accuracy: 0.9202\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2747 - accuracy: 0.9220 - val_loss: 0.2759 - val_accuracy: 0.9205\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2702 - accuracy: 0.9242 - val_loss: 0.2741 - val_accuracy: 0.9230\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2659 - accuracy: 0.9250 - val_loss: 0.2682 - val_accuracy: 0.9245\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2621 - accuracy: 0.9261 - val_loss: 0.2665 - val_accuracy: 0.9237\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2578 - accuracy: 0.9277 - val_loss: 0.2641 - val_accuracy: 0.9261\n"
     ]
    }
   ],
   "source": [
    "# training results\n",
    "\n",
    "# model : optimizer adam\n",
    "adam_model = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0, \n",
    "    optimizer_learning_rate = 0.001, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='Adam',\n",
    ")\n",
    "adam_model._name = 'adam_lr2'\n",
    "# model : optimizer RMSprop\n",
    "rmsprop_model = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0, \n",
    "    optimizer_learning_rate = 0.001, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='RMSprop',\n",
    ")\n",
    "rmsprop_model._name = 'rmsprop_lr2'\n",
    "# model: optimizer SGD\n",
    "sgd_model = model(\n",
    "    unitsHL1 =750, \n",
    "    unitsHL2 =400, \n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0, \n",
    "    optimizer_learning_rate =0.001, \n",
    "    optimizer_momentum =0.0,\n",
    "    optimizer='SGD',\n",
    ")\n",
    "sgd_model._name = 'sgd_lr2'\n",
    "\n",
    "models = [adam_model,rmsprop_model,sgd_model]\n",
    "\n",
    "# stop training if no improvement\n",
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'min',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 0)\n",
    "callbacks = [earlystopping]\n",
    "\n",
    "train_results = model_train_results(\n",
    "    models=models,\n",
    "    epochs=20,\n",
    "    batch_size=32, #32 default value\n",
    "    X= X_train,\n",
    "    Y= y_train,\n",
    "    X_val = X_validation,\n",
    "    Y_val = y_validation,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe4ceb79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x1300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_results(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a0ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model adam_lr2 validation loss: 0.11157926172018051\n",
      "model adam_lr2 validation accuracy: 0.9767500162124634\n",
      "\n",
      "\n",
      "model rmsprop_lr2 validation loss: 0.16329512000083923\n",
      "model rmsprop_lr2 validation accuracy: 0.9752500057220459\n",
      "\n",
      "\n",
      "model sgd_lr2 validation loss: 0.2640928328037262\n",
      "model sgd_lr2 validation accuracy: 0.9260833263397217\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"model {model.name} validation loss: {train_results[model.name]['val_loss']}\")\n",
    "    print(f\"model {model.name} validation accuracy: {train_results[model.name]['val_accuracy']}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b7dbd",
   "metadata": {},
   "source": [
    "The models with optimizer `Adam` and `RMSprop` show bad performance, models that are good in training but have bad predicting (validation data).\n",
    "\n",
    "The models show a situation where the training loss (`loss`) curves are low and the validation loss (`val_loss`) curves are erratic and increase, which indicates overfitting.\n",
    "\n",
    "The model with optimizer `SGD` in general has a good performance in training and validation.\n",
    "\n",
    "A way to optimize the model performance with overfitting is:\n",
    "- Reduce the training time with a higher `batch size` \n",
    "- Use `regularization` as `dropout` or `L1` or `L2` techniques\n",
    "- Use `earlystopping` to stop the training at a certain `epoch` number "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5246709",
   "metadata": {},
   "source": [
    "## Model Convergence:\n",
    "\n",
    "The `accuracy` is not enough to select the right model, the number of `epochs` plays a significant role in determining the model convergence and performance.\n",
    "\n",
    "A way to find an optimal number of `epochs` is using `early stopping`, this regularization technique stops the training as soon as the validation error reaches a minimum preventing overfitting. Determining an appropriate number of `epochs` also helps manage computational resources effectively by avoiding unnecessary training iterations.\n",
    "\n",
    "The `batch size` hyperparameter also has a significant impact on the model performance and training time. In practice models with a high `batch size` are not generalized as well as models with a low `batch size`.\n",
    "\n",
    "\n",
    "`Convergence` tells us that the model has understood the patterns in the data and is making accurate predictions.\n",
    "\n",
    "*During the training of a machine learning model, the current state of the model at each step of the training algorithm can be evaluated. It can be evaluated on the training dataset to give an idea of how well the model is â€œlearning.â€ It can also be evaluated on a hold-out validation dataset that is not part of the training dataset. Evaluation on the validation dataset gives an idea of how well the model is â€œgeneralizing.â€* **Jason Browlee(Aug 6,2019). [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bcba2",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "*The optimal learning rate depends on the other hyperparametersâ€”\n",
    "especially the batch sizeâ€”so if you modify any hyperparameter,\n",
    "make sure to update the learning rate as well.* **AurÃ©lien GÃ©ron - Hands-on\n",
    "Machine Learning with scikit-learn,keras & tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e6040",
   "metadata": {},
   "source": [
    "### Model Convergence: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc33e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "adam_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='Adam',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=24,\n",
    ")\n",
    "adam_param_grid = {\n",
    "    'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    'batch_size':[275,300,325],\n",
    "}\n",
    "adam_grid = GridSearchCV(\n",
    "    estimator=adam_estimator, \n",
    "    param_grid=adam_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ac946fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.5676 - accuracy: 0.8395 - val_loss: 0.2855 - val_accuracy: 0.9172\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9265 - val_loss: 0.2258 - val_accuracy: 0.9338\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9465 - val_loss: 0.1831 - val_accuracy: 0.9477\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9564 - val_loss: 0.1524 - val_accuracy: 0.9535\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9673 - val_loss: 0.1385 - val_accuracy: 0.9579\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9740 - val_loss: 0.1180 - val_accuracy: 0.9645\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9801 - val_loss: 0.1071 - val_accuracy: 0.9668\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9828 - val_loss: 0.1036 - val_accuracy: 0.9678\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9872 - val_loss: 0.0963 - val_accuracy: 0.9716\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 0.0934 - val_accuracy: 0.9715\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.0897 - val_accuracy: 0.9713\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0876 - val_accuracy: 0.9737\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9959 - val_loss: 0.0903 - val_accuracy: 0.9732\n",
      "Epoch 14/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 15/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0864 - val_accuracy: 0.9760\n",
      "Epoch 16/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.0856 - val_accuracy: 0.9755\n",
      "Epoch 17/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.0907 - val_accuracy: 0.9757\n",
      "Epoch 18/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0973 - val_accuracy: 0.9737\n",
      "Epoch 19/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0923 - val_accuracy: 0.9747\n",
      "Epoch 20/24\n",
      "127/131 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 16.\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0875 - val_accuracy: 0.9770\n",
      "Epoch 20: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.5570 - accuracy: 0.8403 - val_loss: 0.2837 - val_accuracy: 0.9176\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2400 - accuracy: 0.9287 - val_loss: 0.2226 - val_accuracy: 0.9355\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1820 - accuracy: 0.9459 - val_loss: 0.1742 - val_accuracy: 0.9503\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1403 - accuracy: 0.9593 - val_loss: 0.1464 - val_accuracy: 0.9577\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1098 - accuracy: 0.9680 - val_loss: 0.1315 - val_accuracy: 0.9613\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9752 - val_loss: 0.1264 - val_accuracy: 0.9633\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0702 - accuracy: 0.9797 - val_loss: 0.1082 - val_accuracy: 0.9672\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0585 - accuracy: 0.9830 - val_loss: 0.1066 - val_accuracy: 0.9672\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 0.1067 - val_accuracy: 0.9674\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.0999 - val_accuracy: 0.9694\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.1008 - val_accuracy: 0.9702\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9932 - val_loss: 0.0931 - val_accuracy: 0.9729\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9728\n",
      "Epoch 14/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0911 - val_accuracy: 0.9739\n",
      "Epoch 15/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.0974 - val_accuracy: 0.9744\n",
      "Epoch 16/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9984 - val_loss: 0.0927 - val_accuracy: 0.9745\n",
      "Epoch 17/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0944 - val_accuracy: 0.9757\n",
      "Epoch 18/24\n",
      "125/131 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 14.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0977 - val_accuracy: 0.9737\n",
      "Epoch 18: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.5980 - accuracy: 0.8329 - val_loss: 0.2867 - val_accuracy: 0.9167\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2512 - accuracy: 0.9275 - val_loss: 0.2256 - val_accuracy: 0.9354\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1931 - accuracy: 0.9430 - val_loss: 0.1823 - val_accuracy: 0.9473\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9570 - val_loss: 0.1567 - val_accuracy: 0.9548\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9638 - val_loss: 0.1417 - val_accuracy: 0.9587\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.1340 - val_accuracy: 0.9592\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0813 - accuracy: 0.9766 - val_loss: 0.1126 - val_accuracy: 0.9666\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.1102 - val_accuracy: 0.9674\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 0.1043 - val_accuracy: 0.9685\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 0.1020 - val_accuracy: 0.9693\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.0961 - val_accuracy: 0.9718\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.0983 - val_accuracy: 0.9723\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9948 - val_loss: 0.0937 - val_accuracy: 0.9728\n",
      "Epoch 14/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.0901 - val_accuracy: 0.9742\n",
      "Epoch 15/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.1010 - val_accuracy: 0.9717\n",
      "Epoch 16/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.1024 - val_accuracy: 0.9711\n",
      "Epoch 17/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.0884 - val_accuracy: 0.9756\n",
      "Epoch 18/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
      "Epoch 19/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0955 - val_accuracy: 0.9739\n",
      "Epoch 20/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0899 - val_accuracy: 0.9762\n",
      "Epoch 21/24\n",
      "114/131 [=========================>....] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 17.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0932 - val_accuracy: 0.9758\n",
      "Epoch 21: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.5854 - accuracy: 0.8342 - val_loss: 0.2790 - val_accuracy: 0.9214\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2526 - accuracy: 0.9270 - val_loss: 0.2278 - val_accuracy: 0.9352\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1931 - accuracy: 0.9434 - val_loss: 0.1823 - val_accuracy: 0.9478\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9578 - val_loss: 0.1609 - val_accuracy: 0.9529\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9647 - val_loss: 0.1412 - val_accuracy: 0.9592\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9714 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0802 - accuracy: 0.9767 - val_loss: 0.1139 - val_accuracy: 0.9655\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9824 - val_loss: 0.1072 - val_accuracy: 0.9670\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.0978 - val_accuracy: 0.9697\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9910 - val_loss: 0.0942 - val_accuracy: 0.9721\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0938 - val_accuracy: 0.9736\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.0885 - val_accuracy: 0.9743\n",
      "Epoch 14/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.0940 - val_accuracy: 0.9728\n",
      "Epoch 15/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.1031 - val_accuracy: 0.9711\n",
      "Epoch 16/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0961 - val_accuracy: 0.9737\n",
      "Epoch 17/24\n",
      "131/131 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9981Restoring model weights from the end of the best epoch: 13.\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0938 - val_accuracy: 0.9742\n",
      "Epoch 17: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.6242 - accuracy: 0.8394 - val_loss: 0.2566 - val_accuracy: 0.9255\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9373 - val_loss: 0.1958 - val_accuracy: 0.9417\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9561 - val_loss: 0.1509 - val_accuracy: 0.9568\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9674 - val_loss: 0.1364 - val_accuracy: 0.9578\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9755 - val_loss: 0.1142 - val_accuracy: 0.9637\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9811 - val_loss: 0.1005 - val_accuracy: 0.9689\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.0940 - val_accuracy: 0.9720\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9893 - val_loss: 0.0889 - val_accuracy: 0.9727\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0919 - val_accuracy: 0.9727\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0850 - val_accuracy: 0.9751\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.0886 - val_accuracy: 0.9744\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.0862 - val_accuracy: 0.9773\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.0903 - val_accuracy: 0.9758\n",
      "Epoch 14/24\n",
      "123/131 [===========================>..] - ETA: 0s - loss: 0.0071 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 10.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0879 - val_accuracy: 0.9764\n",
      "Epoch 14: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.6471 - accuracy: 0.8349 - val_loss: 0.2676 - val_accuracy: 0.9235\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9362 - val_loss: 0.1953 - val_accuracy: 0.9442\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9540 - val_loss: 0.1569 - val_accuracy: 0.9561\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1206 - accuracy: 0.9646 - val_loss: 0.1332 - val_accuracy: 0.9604\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9741 - val_loss: 0.1149 - val_accuracy: 0.9657\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9797 - val_loss: 0.1228 - val_accuracy: 0.9641\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.0990 - val_accuracy: 0.9700\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 0.1033 - val_accuracy: 0.9680\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 0.1015 - val_accuracy: 0.9691\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.0949 - val_accuracy: 0.9722\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.0972 - val_accuracy: 0.9736\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0954 - val_accuracy: 0.9729\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.1014 - val_accuracy: 0.9723\n",
      "Epoch 14/24\n",
      "126/131 [===========================>..] - ETA: 0s - loss: 0.0088 - accuracy: 0.9983Restoring model weights from the end of the best epoch: 10.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0968 - val_accuracy: 0.9747\n",
      "Epoch 14: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.6951 - accuracy: 0.8250 - val_loss: 0.2809 - val_accuracy: 0.9165\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9351 - val_loss: 0.1951 - val_accuracy: 0.9453\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9527 - val_loss: 0.1565 - val_accuracy: 0.9544\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1214 - accuracy: 0.9650 - val_loss: 0.1318 - val_accuracy: 0.9618\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9730 - val_loss: 0.1176 - val_accuracy: 0.9651\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9779 - val_loss: 0.1090 - val_accuracy: 0.9652\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9836 - val_loss: 0.0996 - val_accuracy: 0.9700\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.1025 - val_accuracy: 0.9686\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 0.0935 - val_accuracy: 0.9708\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9934 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.0991 - val_accuracy: 0.9726\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.0990 - val_accuracy: 0.9728\n",
      "Epoch 13/24\n",
      "130/131 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9972Restoring model weights from the end of the best epoch: 9.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0961 - val_accuracy: 0.9737\n",
      "Epoch 13: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.6703 - accuracy: 0.8256 - val_loss: 0.2654 - val_accuracy: 0.9225\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9345 - val_loss: 0.2012 - val_accuracy: 0.9421\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9522 - val_loss: 0.1577 - val_accuracy: 0.9548\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9669 - val_loss: 0.1352 - val_accuracy: 0.9607\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.1158 - val_accuracy: 0.9673\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9784 - val_loss: 0.1081 - val_accuracy: 0.9674\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 0.0988 - val_accuracy: 0.9705\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9883 - val_loss: 0.0942 - val_accuracy: 0.9722\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0916 - val_accuracy: 0.9733\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9940 - val_loss: 0.0944 - val_accuracy: 0.9718\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.0933 - val_accuracy: 0.9736\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.0974 - val_accuracy: 0.9728\n",
      "Epoch 13/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0902 - val_accuracy: 0.9752\n",
      "Epoch 14/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0951 - val_accuracy: 0.9746\n",
      "Epoch 15/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0976 - val_accuracy: 0.9755\n",
      "Epoch 16/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0981 - val_accuracy: 0.9758\n",
      "Epoch 17/24\n",
      "118/131 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 13.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0923 - val_accuracy: 0.9756\n",
      "Epoch 17: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.7171 - accuracy: 0.8289 - val_loss: 0.2468 - val_accuracy: 0.9287\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.9384 - val_loss: 0.1816 - val_accuracy: 0.9463\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9589 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.1291 - val_accuracy: 0.9614\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0761 - accuracy: 0.9777 - val_loss: 0.1085 - val_accuracy: 0.9647\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9833 - val_loss: 0.0974 - val_accuracy: 0.9697\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.0982 - val_accuracy: 0.9709\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0899 - val_accuracy: 0.9717\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0924 - val_accuracy: 0.9744\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.0919 - val_accuracy: 0.9738\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0907 - val_accuracy: 0.9743\n",
      "Epoch 12/24\n",
      "125/131 [===========================>..] - ETA: 0s - loss: 0.0080 - accuracy: 0.9985Restoring model weights from the end of the best epoch: 8.\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0900 - val_accuracy: 0.9762\n",
      "Epoch 12: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.7385 - accuracy: 0.8264 - val_loss: 0.2570 - val_accuracy: 0.9243\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2042 - accuracy: 0.9398 - val_loss: 0.1791 - val_accuracy: 0.9496\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9575 - val_loss: 0.1408 - val_accuracy: 0.9592\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.9688 - val_loss: 0.1223 - val_accuracy: 0.9635\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9772 - val_loss: 0.1128 - val_accuracy: 0.9664\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9823 - val_loss: 0.1139 - val_accuracy: 0.9659\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 0.0965 - val_accuracy: 0.9718\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.1038 - val_accuracy: 0.9690\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.1018 - val_accuracy: 0.9716\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9955 - val_loss: 0.0991 - val_accuracy: 0.9713\n",
      "Epoch 11/24\n",
      "117/131 [=========================>....] - ETA: 0s - loss: 0.0150 - accuracy: 0.9963Restoring model weights from the end of the best epoch: 7.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0984 - val_accuracy: 0.9751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.7629 - accuracy: 0.8222 - val_loss: 0.2694 - val_accuracy: 0.9200\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9376 - val_loss: 0.1844 - val_accuracy: 0.9464\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1511 - accuracy: 0.9559 - val_loss: 0.1478 - val_accuracy: 0.9580\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9680 - val_loss: 0.1244 - val_accuracy: 0.9636\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9759 - val_loss: 0.1132 - val_accuracy: 0.9667\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9801 - val_loss: 0.1055 - val_accuracy: 0.9684\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.0960 - val_accuracy: 0.9695\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.0970 - val_accuracy: 0.9716\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.0930 - val_accuracy: 0.9728\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.0996 - val_accuracy: 0.9725\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.1037 - val_accuracy: 0.9722\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.1009 - val_accuracy: 0.9732\n",
      "Epoch 13/24\n",
      "123/131 [===========================>..] - ETA: 0s - loss: 0.0082 - accuracy: 0.9984Restoring model weights from the end of the best epoch: 9.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.1017 - val_accuracy: 0.9743\n",
      "Epoch 13: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.7391 - accuracy: 0.8227 - val_loss: 0.2515 - val_accuracy: 0.9260\n",
      "Epoch 2/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9387 - val_loss: 0.1847 - val_accuracy: 0.9450\n",
      "Epoch 3/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9585 - val_loss: 0.1475 - val_accuracy: 0.9572\n",
      "Epoch 4/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9707 - val_loss: 0.1225 - val_accuracy: 0.9629\n",
      "Epoch 5/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9769 - val_loss: 0.1106 - val_accuracy: 0.9674\n",
      "Epoch 6/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9811 - val_loss: 0.1059 - val_accuracy: 0.9690\n",
      "Epoch 7/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0489 - accuracy: 0.9856 - val_loss: 0.0984 - val_accuracy: 0.9708\n",
      "Epoch 8/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 0.0957 - val_accuracy: 0.9724\n",
      "Epoch 9/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.0937 - val_accuracy: 0.9731\n",
      "Epoch 10/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.0968 - val_accuracy: 0.9731\n",
      "Epoch 11/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.1055 - val_accuracy: 0.9718\n",
      "Epoch 12/24\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0945 - val_accuracy: 0.9750\n",
      "Epoch 13/24\n",
      "125/131 [===========================>..] - ETA: 0s - loss: 0.0087 - accuracy: 0.9981Restoring model weights from the end of the best epoch: 9.\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0971 - val_accuracy: 0.9737\n",
      "Epoch 13: early stopping\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5786 - accuracy: 0.8370 - val_loss: 0.2849 - val_accuracy: 0.9174\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9264 - val_loss: 0.2237 - val_accuracy: 0.9348\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9452 - val_loss: 0.1840 - val_accuracy: 0.9472\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9567 - val_loss: 0.1554 - val_accuracy: 0.9538\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9666 - val_loss: 0.1409 - val_accuracy: 0.9582\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9736 - val_loss: 0.1174 - val_accuracy: 0.9658\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9792 - val_loss: 0.1130 - val_accuracy: 0.9651\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9828 - val_loss: 0.1047 - val_accuracy: 0.9676\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9882 - val_loss: 0.0979 - val_accuracy: 0.9701\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0952 - val_accuracy: 0.9698\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.0909 - val_accuracy: 0.9739\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9956 - val_loss: 0.0945 - val_accuracy: 0.9719\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0922 - val_accuracy: 0.9735\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0898 - val_accuracy: 0.9749\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0903 - val_accuracy: 0.9743\n",
      "Epoch 17/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0908 - val_accuracy: 0.9743\n",
      "Epoch 18/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0990 - val_accuracy: 0.9731\n",
      "Epoch 19/24\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9994Restoring model weights from the end of the best epoch: 15.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0965 - val_accuracy: 0.9734\n",
      "Epoch 19: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5779 - accuracy: 0.8352 - val_loss: 0.2970 - val_accuracy: 0.9132\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.9275 - val_loss: 0.2316 - val_accuracy: 0.9324\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9436 - val_loss: 0.1816 - val_accuracy: 0.9480\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9557 - val_loss: 0.1517 - val_accuracy: 0.9558\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9645 - val_loss: 0.1380 - val_accuracy: 0.9600\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9722 - val_loss: 0.1303 - val_accuracy: 0.9621\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9775 - val_loss: 0.1100 - val_accuracy: 0.9665\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9820 - val_loss: 0.1035 - val_accuracy: 0.9692\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.1081 - val_accuracy: 0.9664\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9889 - val_loss: 0.1002 - val_accuracy: 0.9693\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0956 - val_accuracy: 0.9722\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9924 - val_loss: 0.0905 - val_accuracy: 0.9730\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.0928 - val_accuracy: 0.9731\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.0915 - val_accuracy: 0.9722\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0970 - val_accuracy: 0.9732\n",
      "Epoch 16/24\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9982Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0907 - val_accuracy: 0.9747\n",
      "Epoch 16: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 2s 10ms/step - loss: 0.6218 - accuracy: 0.8256 - val_loss: 0.3041 - val_accuracy: 0.9120\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2568 - accuracy: 0.9256 - val_loss: 0.2309 - val_accuracy: 0.9334\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9424 - val_loss: 0.1950 - val_accuracy: 0.9430\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9553 - val_loss: 0.1631 - val_accuracy: 0.9539\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9630 - val_loss: 0.1443 - val_accuracy: 0.9577\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9700 - val_loss: 0.1383 - val_accuracy: 0.9587\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9750 - val_loss: 0.1139 - val_accuracy: 0.9651\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9812 - val_loss: 0.1083 - val_accuracy: 0.9669\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9841 - val_loss: 0.1058 - val_accuracy: 0.9685\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 0.1048 - val_accuracy: 0.9686\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: 0.0971 - val_accuracy: 0.9716\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 0.0995 - val_accuracy: 0.9709\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9935 - val_loss: 0.0937 - val_accuracy: 0.9732\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.0915 - val_accuracy: 0.9733\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0998 - val_accuracy: 0.9718\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0934 - val_accuracy: 0.9730\n",
      "Epoch 17/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0875 - val_accuracy: 0.9749\n",
      "Epoch 18/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0875 - val_accuracy: 0.9761\n",
      "Epoch 19/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0900 - val_accuracy: 0.9748\n",
      "Epoch 20/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.0884 - val_accuracy: 0.9751\n",
      "Epoch 21/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0921 - val_accuracy: 0.9758\n",
      "Epoch 22/24\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 18.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0909 - val_accuracy: 0.9761\n",
      "Epoch 22: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6079 - accuracy: 0.8266 - val_loss: 0.2918 - val_accuracy: 0.9150\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9246 - val_loss: 0.2336 - val_accuracy: 0.9311\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9416 - val_loss: 0.1984 - val_accuracy: 0.9432\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9549 - val_loss: 0.1632 - val_accuracy: 0.9525\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9629 - val_loss: 0.1453 - val_accuracy: 0.9582\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9698 - val_loss: 0.1321 - val_accuracy: 0.9606\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.1179 - val_accuracy: 0.9648\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9803 - val_loss: 0.1090 - val_accuracy: 0.9676\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9835 - val_loss: 0.1022 - val_accuracy: 0.9686\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9876 - val_loss: 0.0983 - val_accuracy: 0.9710\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9898 - val_loss: 0.0977 - val_accuracy: 0.9707\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.0968 - val_accuracy: 0.9708\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.0914 - val_accuracy: 0.9738\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0931 - val_accuracy: 0.9732\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.1012 - val_accuracy: 0.9716\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0950 - val_accuracy: 0.9723\n",
      "Epoch 17/24\n",
      "104/120 [=========================>....] - ETA: 0s - loss: 0.0115 - accuracy: 0.9976Restoring model weights from the end of the best epoch: 13.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.0926 - val_accuracy: 0.9743\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6569 - accuracy: 0.8328 - val_loss: 0.2647 - val_accuracy: 0.9240\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9342 - val_loss: 0.1978 - val_accuracy: 0.9406\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9523 - val_loss: 0.1610 - val_accuracy: 0.9536\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9644 - val_loss: 0.1402 - val_accuracy: 0.9560\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9732 - val_loss: 0.1210 - val_accuracy: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9792 - val_loss: 0.1062 - val_accuracy: 0.9669\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.0986 - val_accuracy: 0.9706\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.0901 - val_accuracy: 0.9722\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9909 - val_loss: 0.0926 - val_accuracy: 0.9728\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0864 - val_accuracy: 0.9745\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.0940 - val_accuracy: 0.9727\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0866 - val_accuracy: 0.9758\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0951 - val_accuracy: 0.9720\n",
      "Epoch 14/24\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.0092 - accuracy: 0.9986Restoring model weights from the end of the best epoch: 10.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0871 - val_accuracy: 0.9761\n",
      "Epoch 14: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6739 - accuracy: 0.8288 - val_loss: 0.2739 - val_accuracy: 0.9202\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9350 - val_loss: 0.1952 - val_accuracy: 0.9445\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9532 - val_loss: 0.1587 - val_accuracy: 0.9550\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9643 - val_loss: 0.1352 - val_accuracy: 0.9588\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9729 - val_loss: 0.1183 - val_accuracy: 0.9633\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9785 - val_loss: 0.1176 - val_accuracy: 0.9653\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.1001 - val_accuracy: 0.9706\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.1002 - val_accuracy: 0.9703\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.0987 - val_accuracy: 0.9707\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.0970 - val_accuracy: 0.9714\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.1015 - val_accuracy: 0.9718\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.0933 - val_accuracy: 0.9744\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0971 - val_accuracy: 0.9737\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.1009 - val_accuracy: 0.9744\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0993 - val_accuracy: 0.9743\n",
      "Epoch 16/24\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0970 - val_accuracy: 0.9759\n",
      "Epoch 16: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7253 - accuracy: 0.8193 - val_loss: 0.2908 - val_accuracy: 0.9130\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9327 - val_loss: 0.2021 - val_accuracy: 0.9433\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9505 - val_loss: 0.1681 - val_accuracy: 0.9504\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9628 - val_loss: 0.1356 - val_accuracy: 0.9588\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.1221 - val_accuracy: 0.9640\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9764 - val_loss: 0.1223 - val_accuracy: 0.9632\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9817 - val_loss: 0.1040 - val_accuracy: 0.9680\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.1019 - val_accuracy: 0.9696\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.0984 - val_accuracy: 0.9701\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0990 - val_accuracy: 0.9717\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.0978 - val_accuracy: 0.9727\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.1020 - val_accuracy: 0.9707\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0952 - val_accuracy: 0.9742\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0921 - val_accuracy: 0.9744\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.0998 - val_accuracy: 0.9728\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0940 - val_accuracy: 0.9754\n",
      "Epoch 17/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0899 - val_accuracy: 0.9766\n",
      "Epoch 18/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0915 - val_accuracy: 0.9772\n",
      "Epoch 19/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0941 - val_accuracy: 0.9768\n",
      "Epoch 20/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0928 - val_accuracy: 0.9765\n",
      "Epoch 21/24\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 17.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9767\n",
      "Epoch 21: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6981 - accuracy: 0.8207 - val_loss: 0.2735 - val_accuracy: 0.9190\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9325 - val_loss: 0.2027 - val_accuracy: 0.9422\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9512 - val_loss: 0.1695 - val_accuracy: 0.9515\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 0.1357 - val_accuracy: 0.9601\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.1225 - val_accuracy: 0.9642\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9768 - val_loss: 0.1150 - val_accuracy: 0.9649\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.1034 - val_accuracy: 0.9684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9868 - val_loss: 0.0970 - val_accuracy: 0.9704\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.0923 - val_accuracy: 0.9733\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0928 - val_accuracy: 0.9735\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.0947 - val_accuracy: 0.9718\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.0926 - val_accuracy: 0.9738\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0900 - val_accuracy: 0.9758\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.0947 - val_accuracy: 0.9738\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0979 - val_accuracy: 0.9746\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0968 - val_accuracy: 0.9754\n",
      "Epoch 17/24\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9985Restoring model weights from the end of the best epoch: 13.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0936 - val_accuracy: 0.9747\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7760 - accuracy: 0.8179 - val_loss: 0.2643 - val_accuracy: 0.9221\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9355 - val_loss: 0.1883 - val_accuracy: 0.9442\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9544 - val_loss: 0.1541 - val_accuracy: 0.9556\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9666 - val_loss: 0.1325 - val_accuracy: 0.9610\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9756 - val_loss: 0.1122 - val_accuracy: 0.9649\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9814 - val_loss: 0.1001 - val_accuracy: 0.9693\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0962 - val_accuracy: 0.9698\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.0858 - val_accuracy: 0.9735\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0931 - val_accuracy: 0.9735\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.0894 - val_accuracy: 0.9743\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0897 - val_accuracy: 0.9761\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0907 - val_accuracy: 0.9767\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0912 - val_accuracy: 0.9773\n",
      "Epoch 16/24\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0943 - val_accuracy: 0.9769\n",
      "Epoch 16: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.7988 - accuracy: 0.8132 - val_loss: 0.2669 - val_accuracy: 0.9218\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9379 - val_loss: 0.1839 - val_accuracy: 0.9482\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9560 - val_loss: 0.1492 - val_accuracy: 0.9571\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9665 - val_loss: 0.1281 - val_accuracy: 0.9622\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9742 - val_loss: 0.1181 - val_accuracy: 0.9639\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.1096 - val_accuracy: 0.9671\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9850 - val_loss: 0.0966 - val_accuracy: 0.9707\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9891 - val_loss: 0.1026 - val_accuracy: 0.9707\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0977 - val_accuracy: 0.9725\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.1018 - val_accuracy: 0.9717\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0937 - val_accuracy: 0.9746\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0947 - val_accuracy: 0.9747\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0991 - val_accuracy: 0.9736\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.1034 - val_accuracy: 0.9732\n",
      "Epoch 15/24\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9985Restoring model weights from the end of the best epoch: 11.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.1004 - val_accuracy: 0.9758\n",
      "Epoch 15: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8010 - accuracy: 0.8155 - val_loss: 0.2710 - val_accuracy: 0.9191\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9358 - val_loss: 0.1872 - val_accuracy: 0.9463\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.9546 - val_loss: 0.1541 - val_accuracy: 0.9554\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9663 - val_loss: 0.1264 - val_accuracy: 0.9617\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9742 - val_loss: 0.1149 - val_accuracy: 0.9657\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 0.0987 - val_accuracy: 0.9690\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.0987 - val_accuracy: 0.9709\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.0935 - val_accuracy: 0.9717\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.1062 - val_accuracy: 0.9697\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.0984 - val_accuracy: 0.9735\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0980 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9978Restoring model weights from the end of the best epoch: 9.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0992 - val_accuracy: 0.9737\n",
      "Epoch 13: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7625 - accuracy: 0.8183 - val_loss: 0.2711 - val_accuracy: 0.9183\n",
      "Epoch 2/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9356 - val_loss: 0.1951 - val_accuracy: 0.9442\n",
      "Epoch 3/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9557 - val_loss: 0.1578 - val_accuracy: 0.9542\n",
      "Epoch 4/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9688 - val_loss: 0.1266 - val_accuracy: 0.9622\n",
      "Epoch 5/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9755 - val_loss: 0.1150 - val_accuracy: 0.9665\n",
      "Epoch 6/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9805 - val_loss: 0.1056 - val_accuracy: 0.9679\n",
      "Epoch 7/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.1035 - val_accuracy: 0.9670\n",
      "Epoch 8/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9893 - val_loss: 0.0942 - val_accuracy: 0.9709\n",
      "Epoch 9/24\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.0931 - val_accuracy: 0.9716\n",
      "Epoch 10/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0938 - val_accuracy: 0.9732\n",
      "Epoch 11/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0999 - val_accuracy: 0.9725\n",
      "Epoch 12/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0916 - val_accuracy: 0.9747\n",
      "Epoch 13/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
      "Epoch 14/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0993 - val_accuracy: 0.9738\n",
      "Epoch 15/24\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.1004 - val_accuracy: 0.9751\n",
      "Epoch 16/24\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0969 - val_accuracy: 0.9762\n",
      "Epoch 16: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.6037 - accuracy: 0.8303 - val_loss: 0.2918 - val_accuracy: 0.9168\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9249 - val_loss: 0.2406 - val_accuracy: 0.9291\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9430 - val_loss: 0.1888 - val_accuracy: 0.9462\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9548 - val_loss: 0.1637 - val_accuracy: 0.9520\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9642 - val_loss: 0.1463 - val_accuracy: 0.9555\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9708 - val_loss: 0.1235 - val_accuracy: 0.9634\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.1180 - val_accuracy: 0.9643\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9807 - val_loss: 0.1038 - val_accuracy: 0.9677\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9848 - val_loss: 0.1061 - val_accuracy: 0.9686\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 0.0970 - val_accuracy: 0.9706\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.0940 - val_accuracy: 0.9712\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0881 - val_accuracy: 0.9743\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.0924 - val_accuracy: 0.9717\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.0897 - val_accuracy: 0.9740\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0882 - val_accuracy: 0.9749\n",
      "Epoch 16/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.0860 - val_accuracy: 0.9757\n",
      "Epoch 17/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.0874 - val_accuracy: 0.9763\n",
      "Epoch 18/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.0948 - val_accuracy: 0.9733\n",
      "Epoch 19/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0924 - val_accuracy: 0.9736\n",
      "Epoch 20/24\n",
      "100/111 [==========================>...] - ETA: 0s - loss: 0.0065 - accuracy: 0.9991Restoring model weights from the end of the best epoch: 16.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.0893 - val_accuracy: 0.9750\n",
      "Epoch 20: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.5923 - accuracy: 0.8321 - val_loss: 0.2985 - val_accuracy: 0.9129\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9273 - val_loss: 0.2299 - val_accuracy: 0.9323\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9422 - val_loss: 0.1862 - val_accuracy: 0.9468\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9546 - val_loss: 0.1564 - val_accuracy: 0.9536\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1254 - accuracy: 0.9626 - val_loss: 0.1403 - val_accuracy: 0.9588\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9719 - val_loss: 0.1318 - val_accuracy: 0.9616\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9762 - val_loss: 0.1107 - val_accuracy: 0.9656\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 0.9811 - val_loss: 0.1081 - val_accuracy: 0.9681\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.1090 - val_accuracy: 0.9670\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9877 - val_loss: 0.1008 - val_accuracy: 0.9695\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 0.0984 - val_accuracy: 0.9697\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9920 - val_loss: 0.0901 - val_accuracy: 0.9713\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 0.0909 - val_accuracy: 0.9732\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.0927 - val_accuracy: 0.9735\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.0947 - val_accuracy: 0.9733\n",
      "Epoch 16/24\n",
      "110/111 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9978Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0918 - val_accuracy: 0.9738\n",
      "Epoch 16: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.6366 - accuracy: 0.8217 - val_loss: 0.3098 - val_accuracy: 0.9078\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9245 - val_loss: 0.2358 - val_accuracy: 0.9327\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2014 - accuracy: 0.9415 - val_loss: 0.1974 - val_accuracy: 0.9433\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.9534 - val_loss: 0.1662 - val_accuracy: 0.9528\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.9614 - val_loss: 0.1462 - val_accuracy: 0.9575\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.9678 - val_loss: 0.1393 - val_accuracy: 0.9589\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.1209 - val_accuracy: 0.9641\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9797 - val_loss: 0.1130 - val_accuracy: 0.9668\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9829 - val_loss: 0.1075 - val_accuracy: 0.9667\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9856 - val_loss: 0.1107 - val_accuracy: 0.9666\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.1043 - val_accuracy: 0.9699\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9898 - val_loss: 0.1036 - val_accuracy: 0.9692\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.0962 - val_accuracy: 0.9718\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0950 - val_accuracy: 0.9724\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.0989 - val_accuracy: 0.9713\n",
      "Epoch 16/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.0974 - val_accuracy: 0.9713\n",
      "Epoch 17/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.0912 - val_accuracy: 0.9750\n",
      "Epoch 18/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.0888 - val_accuracy: 0.9751\n",
      "Epoch 19/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.0906 - val_accuracy: 0.9747\n",
      "Epoch 20/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.0915 - val_accuracy: 0.9749\n",
      "Epoch 21/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0939 - val_accuracy: 0.9758\n",
      "Epoch 22/24\n",
      "105/111 [===========================>..] - ETA: 0s - loss: 0.0038 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 18.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0918 - val_accuracy: 0.9759\n",
      "Epoch 22: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.6225 - accuracy: 0.8219 - val_loss: 0.2967 - val_accuracy: 0.9118\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9229 - val_loss: 0.2387 - val_accuracy: 0.9300\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9406 - val_loss: 0.2061 - val_accuracy: 0.9413\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9534 - val_loss: 0.1660 - val_accuracy: 0.9517\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9615 - val_loss: 0.1467 - val_accuracy: 0.9573\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9691 - val_loss: 0.1321 - val_accuracy: 0.9602\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9746 - val_loss: 0.1201 - val_accuracy: 0.9650\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9800 - val_loss: 0.1113 - val_accuracy: 0.9674\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0606 - accuracy: 0.9830 - val_loss: 0.1023 - val_accuracy: 0.9686\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9871 - val_loss: 0.0993 - val_accuracy: 0.9707\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.0979 - val_accuracy: 0.9712\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 0.0970 - val_accuracy: 0.9712\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0277 - accuracy: 0.9930 - val_loss: 0.0954 - val_accuracy: 0.9725\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.0963 - val_accuracy: 0.9721\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961 - val_loss: 0.1012 - val_accuracy: 0.9719\n",
      "Epoch 16/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.0926 - val_accuracy: 0.9729\n",
      "Epoch 17/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0936 - val_accuracy: 0.9740\n",
      "Epoch 18/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.0927 - val_accuracy: 0.9753\n",
      "Epoch 19/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
      "Epoch 20/24\n",
      " 99/111 [=========================>....] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 16.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.0956 - val_accuracy: 0.9741\n",
      "Epoch 20: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.6885 - accuracy: 0.8253 - val_loss: 0.2723 - val_accuracy: 0.9206\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.2315 - accuracy: 0.9318 - val_loss: 0.2014 - val_accuracy: 0.9413\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1679 - accuracy: 0.9513 - val_loss: 0.1667 - val_accuracy: 0.9522\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9626 - val_loss: 0.1457 - val_accuracy: 0.9564\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0987 - accuracy: 0.9717 - val_loss: 0.1228 - val_accuracy: 0.9615\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9771 - val_loss: 0.1080 - val_accuracy: 0.9671\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.1017 - val_accuracy: 0.9687\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 0.0966 - val_accuracy: 0.9700\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0853 - val_accuracy: 0.9738\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.0893 - val_accuracy: 0.9731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.0850 - val_accuracy: 0.9762\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.0915 - val_accuracy: 0.9726\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0854 - val_accuracy: 0.9757\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0894 - val_accuracy: 0.9753\n",
      "Epoch 16/24\n",
      "106/111 [===========================>..] - ETA: 0s - loss: 0.0063 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 12.\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
      "Epoch 16: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.7192 - accuracy: 0.8163 - val_loss: 0.2783 - val_accuracy: 0.9192\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9318 - val_loss: 0.2047 - val_accuracy: 0.9414\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9502 - val_loss: 0.1691 - val_accuracy: 0.9531\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9612 - val_loss: 0.1397 - val_accuracy: 0.9586\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9698 - val_loss: 0.1260 - val_accuracy: 0.9628\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9771 - val_loss: 0.1185 - val_accuracy: 0.9632\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9812 - val_loss: 0.1042 - val_accuracy: 0.9678\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9858 - val_loss: 0.1040 - val_accuracy: 0.9679\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0402 - accuracy: 0.9889 - val_loss: 0.1002 - val_accuracy: 0.9689\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.0981 - val_accuracy: 0.9706\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 0.0966 - val_accuracy: 0.9718\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 0.0903 - val_accuracy: 0.9743\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0914 - val_accuracy: 0.9745\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.0937 - val_accuracy: 0.9738\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.0974 - val_accuracy: 0.9743\n",
      "Epoch 16/24\n",
      "110/111 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9987Restoring model weights from the end of the best epoch: 12.\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0934 - val_accuracy: 0.9757\n",
      "Epoch 16: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.7219 - accuracy: 0.8189 - val_loss: 0.2827 - val_accuracy: 0.9171\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9319 - val_loss: 0.2059 - val_accuracy: 0.9409\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9504 - val_loss: 0.1702 - val_accuracy: 0.9495\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9617 - val_loss: 0.1391 - val_accuracy: 0.9588\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9697 - val_loss: 0.1275 - val_accuracy: 0.9628\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0817 - accuracy: 0.9763 - val_loss: 0.1183 - val_accuracy: 0.9640\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9817 - val_loss: 0.1073 - val_accuracy: 0.9668\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9864 - val_loss: 0.0990 - val_accuracy: 0.9708\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 0.0994 - val_accuracy: 0.9694\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.1026 - val_accuracy: 0.9700\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.0966 - val_accuracy: 0.9732\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.1047 - val_accuracy: 0.9716\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.0959 - val_accuracy: 0.9737\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0969 - val_accuracy: 0.9737\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.0956 - val_accuracy: 0.9747\n",
      "Epoch 16/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0933 - val_accuracy: 0.9747\n",
      "Epoch 17/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0926 - val_accuracy: 0.9757\n",
      "Epoch 18/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0933 - val_accuracy: 0.9772\n",
      "Epoch 19/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0952 - val_accuracy: 0.9762\n",
      "Epoch 20/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0929 - val_accuracy: 0.9765\n",
      "Epoch 21/24\n",
      "101/111 [==========================>...] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 17.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9762\n",
      "Epoch 21: early stopping\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 0.7064 - accuracy: 0.8199 - val_loss: 0.2778 - val_accuracy: 0.9178\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.2390 - accuracy: 0.9300 - val_loss: 0.2101 - val_accuracy: 0.9387\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9501 - val_loss: 0.1775 - val_accuracy: 0.9488\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.1398 - val_accuracy: 0.9592\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9698 - val_loss: 0.1259 - val_accuracy: 0.9637\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9759 - val_loss: 0.1124 - val_accuracy: 0.9668\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9814 - val_loss: 0.1060 - val_accuracy: 0.9677\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.0990 - val_accuracy: 0.9711\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0935 - val_accuracy: 0.9723\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9923 - val_loss: 0.0951 - val_accuracy: 0.9712\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0943 - val_accuracy: 0.9724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
      "Epoch 13/24\n",
      "105/111 [===========================>..] - ETA: 0s - loss: 0.0161 - accuracy: 0.9965Restoring model weights from the end of the best epoch: 9.\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9965 - val_loss: 0.0968 - val_accuracy: 0.9725\n",
      "Epoch 13: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.8186 - accuracy: 0.8099 - val_loss: 0.2647 - val_accuracy: 0.9223\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.9327 - val_loss: 0.1966 - val_accuracy: 0.9423\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9534 - val_loss: 0.1608 - val_accuracy: 0.9548\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9648 - val_loss: 0.1378 - val_accuracy: 0.9587\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9741 - val_loss: 0.1197 - val_accuracy: 0.9637\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9794 - val_loss: 0.1061 - val_accuracy: 0.9684\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9845 - val_loss: 0.1036 - val_accuracy: 0.9681\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0933 - val_accuracy: 0.9718\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 0.1015 - val_accuracy: 0.9706\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0902 - val_accuracy: 0.9737\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.0965 - val_accuracy: 0.9726\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0907 - val_accuracy: 0.9756\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0948 - val_accuracy: 0.9747\n",
      "Epoch 14/24\n",
      "109/111 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 10.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0924 - val_accuracy: 0.9752\n",
      "Epoch 14: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.8252 - accuracy: 0.8067 - val_loss: 0.2743 - val_accuracy: 0.9187\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9352 - val_loss: 0.1874 - val_accuracy: 0.9463\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9540 - val_loss: 0.1562 - val_accuracy: 0.9554\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9652 - val_loss: 0.1262 - val_accuracy: 0.9627\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9736 - val_loss: 0.1165 - val_accuracy: 0.9662\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9804 - val_loss: 0.1119 - val_accuracy: 0.9660\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9845 - val_loss: 0.1008 - val_accuracy: 0.9692\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 0.1037 - val_accuracy: 0.9687\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.0998 - val_accuracy: 0.9706\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.0997 - val_accuracy: 0.9719\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0998 - val_accuracy: 0.9732\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.0948 - val_accuracy: 0.9736\n",
      "Epoch 13/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0989 - val_accuracy: 0.9744\n",
      "Epoch 14/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0961 - val_accuracy: 0.9753\n",
      "Epoch 15/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0945 - val_accuracy: 0.9772\n",
      "Epoch 16/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0976 - val_accuracy: 0.9761\n",
      "Epoch 17/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 18/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0946 - val_accuracy: 0.9773\n",
      "Epoch 19/24\n",
      "104/111 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 15.\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0969 - val_accuracy: 0.9773\n",
      "Epoch 19: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.7837 - accuracy: 0.8163 - val_loss: 0.2734 - val_accuracy: 0.9185\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.2207 - accuracy: 0.9354 - val_loss: 0.1930 - val_accuracy: 0.9447\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1564 - accuracy: 0.9548 - val_loss: 0.1631 - val_accuracy: 0.9529\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1161 - accuracy: 0.9663 - val_loss: 0.1283 - val_accuracy: 0.9624\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9736 - val_loss: 0.1206 - val_accuracy: 0.9631\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9794 - val_loss: 0.1091 - val_accuracy: 0.9679\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.0988 - val_accuracy: 0.9697\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9894 - val_loss: 0.0934 - val_accuracy: 0.9722\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0935 - val_accuracy: 0.9709\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.1039 - val_accuracy: 0.9713\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.0958 - val_accuracy: 0.9732\n",
      "Epoch 12/24\n",
      "101/111 [==========================>...] - ETA: 0s - loss: 0.0140 - accuracy: 0.9968Restoring model weights from the end of the best epoch: 8.\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.1012 - val_accuracy: 0.9718\n",
      "Epoch 12: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 0.8017 - accuracy: 0.8083 - val_loss: 0.2683 - val_accuracy: 0.9185\n",
      "Epoch 2/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9351 - val_loss: 0.1957 - val_accuracy: 0.9436\n",
      "Epoch 3/24\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9544 - val_loss: 0.1639 - val_accuracy: 0.9521\n",
      "Epoch 4/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.9674 - val_loss: 0.1302 - val_accuracy: 0.9624\n",
      "Epoch 5/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.1177 - val_accuracy: 0.9658\n",
      "Epoch 6/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9799 - val_loss: 0.1054 - val_accuracy: 0.9681\n",
      "Epoch 7/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0993 - val_accuracy: 0.9699\n",
      "Epoch 8/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 0.0985 - val_accuracy: 0.9709\n",
      "Epoch 9/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.0925 - val_accuracy: 0.9729\n",
      "Epoch 10/24\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.0974 - val_accuracy: 0.9711\n",
      "Epoch 11/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.1040 - val_accuracy: 0.9702\n",
      "Epoch 12/24\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0966 - val_accuracy: 0.9734\n",
      "Epoch 13/24\n",
      "100/111 [==========================>...] - ETA: 0s - loss: 0.0112 - accuracy: 0.9974Restoring model weights from the end of the best epoch: 9.\n",
      "111/111 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1048 - val_accuracy: 0.9699\n",
      "Epoch 13: early stopping\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "Epoch 1/24\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.8487 - val_loss: 0.2403 - val_accuracy: 0.9288\n",
      "Epoch 2/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9393 - val_loss: 0.1789 - val_accuracy: 0.9467\n",
      "Epoch 3/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9580 - val_loss: 0.1432 - val_accuracy: 0.9588\n",
      "Epoch 4/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9695 - val_loss: 0.1152 - val_accuracy: 0.9641\n",
      "Epoch 5/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "Epoch 6/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0926 - val_accuracy: 0.9719\n",
      "Epoch 7/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
      "Epoch 8/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.0895 - val_accuracy: 0.9727\n",
      "Epoch 9/24\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0795 - val_accuracy: 0.9757\n",
      "Epoch 10/24\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0838 - val_accuracy: 0.9761\n",
      "Epoch 11/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0890 - val_accuracy: 0.9744\n",
      "Epoch 12/24\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0896 - val_accuracy: 0.9748\n",
      "Epoch 13/24\n",
      "143/160 [=========================>....] - ETA: 0s - loss: 0.0097 - accuracy: 0.9978Restoring model weights from the end of the best epoch: 9.\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0851 - val_accuracy: 0.9766\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    adam_grid_result = adam_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a6fb23d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.973729 using {'batch_size': 300, 'optimizer_learning_rate': 0.0015}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (adam_grid_result.best_score_, adam_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f230d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",adam_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e095fd",
   "metadata": {},
   "source": [
    "### Model Convergence: RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5154f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 5,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "rmsprop_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='RMSprop',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=25,\n",
    ")\n",
    "rmsprop_param_grid = {\n",
    "    'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    'optimizer_momentum':[0.0,0.001],\n",
    "    'batch_size':[350,400,450]\n",
    "}\n",
    "rmsprop_grid = GridSearchCV(\n",
    "    estimator=rmsprop_estimator, \n",
    "    param_grid=rmsprop_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4377420c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.6317 - accuracy: 0.8233 - val_loss: 0.2970 - val_accuracy: 0.9144\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2625 - accuracy: 0.9230 - val_loss: 0.2343 - val_accuracy: 0.9310\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9407 - val_loss: 0.1990 - val_accuracy: 0.9437\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9530 - val_loss: 0.1721 - val_accuracy: 0.9503\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9628 - val_loss: 0.1456 - val_accuracy: 0.9561\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1058 - accuracy: 0.9690 - val_loss: 0.1289 - val_accuracy: 0.9626\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9756 - val_loss: 0.1234 - val_accuracy: 0.9622\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.1041 - val_accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9841 - val_loss: 0.1085 - val_accuracy: 0.9685\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9859 - val_loss: 0.0999 - val_accuracy: 0.9700\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.0953 - val_accuracy: 0.9701\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9921 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 0.0940 - val_accuracy: 0.9713\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0899 - val_accuracy: 0.9746\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0903 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0859 - val_accuracy: 0.9746\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0886 - val_accuracy: 0.9738\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.0926 - val_accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0906 - val_accuracy: 0.9737\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0882 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      " 97/103 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 16.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0892 - val_accuracy: 0.9760\n",
      "Epoch 21: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.6166 - accuracy: 0.8262 - val_loss: 0.3001 - val_accuracy: 0.9133\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2567 - accuracy: 0.9245 - val_loss: 0.2350 - val_accuracy: 0.9321\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2015 - accuracy: 0.9403 - val_loss: 0.1965 - val_accuracy: 0.9438\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9519 - val_loss: 0.1615 - val_accuracy: 0.9547\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9620 - val_loss: 0.1456 - val_accuracy: 0.9572\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9695 - val_loss: 0.1383 - val_accuracy: 0.9602\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0881 - accuracy: 0.9742 - val_loss: 0.1150 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.1148 - val_accuracy: 0.9653\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9834 - val_loss: 0.1116 - val_accuracy: 0.9653\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9866 - val_loss: 0.1056 - val_accuracy: 0.9678\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9888 - val_loss: 0.1043 - val_accuracy: 0.9685\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0944 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.0923 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0930 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0956 - val_accuracy: 0.9723\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.0935 - val_accuracy: 0.9733\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.0936 - val_accuracy: 0.9745\n",
      "Epoch 18/25\n",
      " 99/103 [===========================>..] - ETA: 0s - loss: 0.0092 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 13.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.0925 - val_accuracy: 0.9742\n",
      "Epoch 18: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.6606 - accuracy: 0.8161 - val_loss: 0.3144 - val_accuracy: 0.9063\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2671 - accuracy: 0.9225 - val_loss: 0.2464 - val_accuracy: 0.9293\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.9381 - val_loss: 0.2194 - val_accuracy: 0.9357\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9498 - val_loss: 0.1762 - val_accuracy: 0.9503\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1432 - accuracy: 0.9578 - val_loss: 0.1564 - val_accuracy: 0.9549\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1176 - accuracy: 0.9667 - val_loss: 0.1402 - val_accuracy: 0.9597\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9706 - val_loss: 0.1287 - val_accuracy: 0.9621\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9775 - val_loss: 0.1135 - val_accuracy: 0.9663\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 0.1156 - val_accuracy: 0.9650\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 0.1143 - val_accuracy: 0.9663\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0482 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9686\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.1062 - val_accuracy: 0.9681\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0980 - val_accuracy: 0.9709\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.0983 - val_accuracy: 0.9700\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.0987 - val_accuracy: 0.9709\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0926 - val_accuracy: 0.9729\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0902 - val_accuracy: 0.9745\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0904 - val_accuracy: 0.9744\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.0887 - val_accuracy: 0.9744\n",
      "Epoch 21/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 22/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.0905 - val_accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0931 - val_accuracy: 0.9759\n",
      "Epoch 24/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0948 - val_accuracy: 0.9751\n",
      "Epoch 25/25\n",
      " 90/103 [=========================>....] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0974 - val_accuracy: 0.9747\n",
      "Epoch 25: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.6357 - accuracy: 0.8181 - val_loss: 0.3076 - val_accuracy: 0.9076\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2650 - accuracy: 0.9231 - val_loss: 0.2391 - val_accuracy: 0.9298\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9399 - val_loss: 0.2092 - val_accuracy: 0.9401\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9514 - val_loss: 0.1697 - val_accuracy: 0.9513\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1405 - accuracy: 0.9594 - val_loss: 0.1480 - val_accuracy: 0.9567\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9680 - val_loss: 0.1347 - val_accuracy: 0.9597\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0939 - accuracy: 0.9728 - val_loss: 0.1253 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9781 - val_loss: 0.1142 - val_accuracy: 0.9663\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.1067 - val_accuracy: 0.9666\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9850 - val_loss: 0.1009 - val_accuracy: 0.9698\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 0.1000 - val_accuracy: 0.9693\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9703\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 0.0975 - val_accuracy: 0.9707\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.1002 - val_accuracy: 0.9703\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.1010 - val_accuracy: 0.9717\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.0932 - val_accuracy: 0.9720\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0928 - val_accuracy: 0.9731\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0930 - val_accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.0908 - val_accuracy: 0.9755\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.0922 - val_accuracy: 0.9736\n",
      "Epoch 21/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.0931 - val_accuracy: 0.9750\n",
      "Epoch 22/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0939 - val_accuracy: 0.9761\n",
      "Epoch 23/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0945 - val_accuracy: 0.9764\n",
      "Epoch 24/25\n",
      " 93/103 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 19.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0977 - val_accuracy: 0.9750\n",
      "Epoch 24: early stopping\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.6317 - accuracy: 0.8233 - val_loss: 0.2970 - val_accuracy: 0.9144\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2625 - accuracy: 0.9230 - val_loss: 0.2343 - val_accuracy: 0.9310\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9407 - val_loss: 0.1990 - val_accuracy: 0.9437\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9530 - val_loss: 0.1721 - val_accuracy: 0.9503\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1306 - accuracy: 0.9628 - val_loss: 0.1456 - val_accuracy: 0.9561\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9690 - val_loss: 0.1289 - val_accuracy: 0.9626\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9756 - val_loss: 0.1234 - val_accuracy: 0.9622\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.1041 - val_accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9841 - val_loss: 0.1085 - val_accuracy: 0.9685\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0491 - accuracy: 0.9859 - val_loss: 0.0999 - val_accuracy: 0.9700\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0398 - accuracy: 0.9898 - val_loss: 0.0953 - val_accuracy: 0.9701\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0315 - accuracy: 0.9921 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 0.0940 - val_accuracy: 0.9713\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.0899 - val_accuracy: 0.9746\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0903 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0859 - val_accuracy: 0.9746\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0886 - val_accuracy: 0.9738\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.0926 - val_accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.0906 - val_accuracy: 0.9737\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0882 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98/103 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 16.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0892 - val_accuracy: 0.9760\n",
      "Epoch 21: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.6166 - accuracy: 0.8262 - val_loss: 0.3001 - val_accuracy: 0.9133\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2567 - accuracy: 0.9245 - val_loss: 0.2350 - val_accuracy: 0.9321\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.9403 - val_loss: 0.1965 - val_accuracy: 0.9438\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9519 - val_loss: 0.1615 - val_accuracy: 0.9547\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9620 - val_loss: 0.1456 - val_accuracy: 0.9572\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1051 - accuracy: 0.9695 - val_loss: 0.1383 - val_accuracy: 0.9602\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9742 - val_loss: 0.1150 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.1148 - val_accuracy: 0.9653\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9834 - val_loss: 0.1116 - val_accuracy: 0.9653\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9866 - val_loss: 0.1056 - val_accuracy: 0.9678\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9888 - val_loss: 0.1043 - val_accuracy: 0.9685\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0944 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.0923 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0930 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0956 - val_accuracy: 0.9723\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.0935 - val_accuracy: 0.9733\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.0936 - val_accuracy: 0.9745\n",
      "Epoch 18/25\n",
      " 99/103 [===========================>..] - ETA: 0s - loss: 0.0092 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 13.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.0925 - val_accuracy: 0.9742\n",
      "Epoch 18: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.6606 - accuracy: 0.8161 - val_loss: 0.3144 - val_accuracy: 0.9063\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.9225 - val_loss: 0.2464 - val_accuracy: 0.9293\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2124 - accuracy: 0.9381 - val_loss: 0.2194 - val_accuracy: 0.9357\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9498 - val_loss: 0.1762 - val_accuracy: 0.9503\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1432 - accuracy: 0.9578 - val_loss: 0.1564 - val_accuracy: 0.9549\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9667 - val_loss: 0.1402 - val_accuracy: 0.9597\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9706 - val_loss: 0.1287 - val_accuracy: 0.9621\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9775 - val_loss: 0.1135 - val_accuracy: 0.9663\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 0.1156 - val_accuracy: 0.9650\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 0.1143 - val_accuracy: 0.9663\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9686\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.1062 - val_accuracy: 0.9681\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0980 - val_accuracy: 0.9709\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.0983 - val_accuracy: 0.9700\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.0987 - val_accuracy: 0.9709\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0926 - val_accuracy: 0.9729\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0902 - val_accuracy: 0.9745\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0904 - val_accuracy: 0.9744\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.0887 - val_accuracy: 0.9744\n",
      "Epoch 21/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0925 - val_accuracy: 0.9745\n",
      "Epoch 22/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.0905 - val_accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0931 - val_accuracy: 0.9759\n",
      "Epoch 24/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0948 - val_accuracy: 0.9751\n",
      "Epoch 25/25\n",
      " 99/103 [===========================>..] - ETA: 0s - loss: 0.0031 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0974 - val_accuracy: 0.9747\n",
      "Epoch 25: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.6357 - accuracy: 0.8181 - val_loss: 0.3076 - val_accuracy: 0.9076\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2650 - accuracy: 0.9231 - val_loss: 0.2391 - val_accuracy: 0.9298\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9399 - val_loss: 0.2092 - val_accuracy: 0.9401\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9514 - val_loss: 0.1697 - val_accuracy: 0.9513\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1405 - accuracy: 0.9594 - val_loss: 0.1480 - val_accuracy: 0.9567\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9680 - val_loss: 0.1347 - val_accuracy: 0.9597\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9728 - val_loss: 0.1253 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9781 - val_loss: 0.1142 - val_accuracy: 0.9663\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.1067 - val_accuracy: 0.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9850 - val_loss: 0.1009 - val_accuracy: 0.9698\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 0.1000 - val_accuracy: 0.9693\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9703\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 0.0975 - val_accuracy: 0.9707\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.1002 - val_accuracy: 0.9703\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.1010 - val_accuracy: 0.9717\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.0932 - val_accuracy: 0.9720\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0928 - val_accuracy: 0.9731\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0930 - val_accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.0908 - val_accuracy: 0.9755\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.0922 - val_accuracy: 0.9736\n",
      "Epoch 21/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.0931 - val_accuracy: 0.9750\n",
      "Epoch 22/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0939 - val_accuracy: 0.9761\n",
      "Epoch 23/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0945 - val_accuracy: 0.9764\n",
      "Epoch 24/25\n",
      " 92/103 [=========================>....] - ETA: 0s - loss: 0.0032 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 19.\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0977 - val_accuracy: 0.9750\n",
      "Epoch 24: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.7181 - accuracy: 0.8171 - val_loss: 0.2710 - val_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2359 - accuracy: 0.9309 - val_loss: 0.2062 - val_accuracy: 0.9402\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1734 - accuracy: 0.9496 - val_loss: 0.1724 - val_accuracy: 0.9504\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9612 - val_loss: 0.1449 - val_accuracy: 0.9570\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9710 - val_loss: 0.1248 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9769 - val_loss: 0.1136 - val_accuracy: 0.9664\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0642 - accuracy: 0.9814 - val_loss: 0.1055 - val_accuracy: 0.9672\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9891 - val_loss: 0.0975 - val_accuracy: 0.9703\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0931 - val_accuracy: 0.9719\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0921 - val_accuracy: 0.9727\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 0.0860 - val_accuracy: 0.9744\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0956 - val_accuracy: 0.9712\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.0893 - val_accuracy: 0.9743\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0885 - val_accuracy: 0.9748\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0877 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      " 96/103 [==========================>...] - ETA: 0s - loss: 0.0061 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0874 - val_accuracy: 0.9766\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.7525 - accuracy: 0.8078 - val_loss: 0.2869 - val_accuracy: 0.9166\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.9291 - val_loss: 0.2122 - val_accuracy: 0.9392\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1813 - accuracy: 0.9472 - val_loss: 0.1845 - val_accuracy: 0.9469\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1443 - accuracy: 0.9582 - val_loss: 0.1480 - val_accuracy: 0.9576\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1138 - accuracy: 0.9669 - val_loss: 0.1288 - val_accuracy: 0.9625\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9750 - val_loss: 0.1238 - val_accuracy: 0.9626\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9789 - val_loss: 0.1069 - val_accuracy: 0.9676\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0574 - accuracy: 0.9840 - val_loss: 0.1015 - val_accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.1031 - val_accuracy: 0.9669\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.1006 - val_accuracy: 0.9688\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0989 - val_accuracy: 0.9712\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.0908 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0927 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0892 - val_accuracy: 0.9747\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0971 - val_accuracy: 0.9742\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0918 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0935 - val_accuracy: 0.9761\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0942 - val_accuracy: 0.9758\n",
      "Epoch 19/25\n",
      " 93/103 [==========================>...] - ETA: 0s - loss: 0.0039 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 14.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0949 - val_accuracy: 0.9763\n",
      "Epoch 19: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.7435 - accuracy: 0.8150 - val_loss: 0.2912 - val_accuracy: 0.9141\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.9298 - val_loss: 0.2163 - val_accuracy: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9478 - val_loss: 0.1854 - val_accuracy: 0.9459\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1397 - accuracy: 0.9596 - val_loss: 0.1485 - val_accuracy: 0.9561\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9673 - val_loss: 0.1303 - val_accuracy: 0.9641\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9745 - val_loss: 0.1202 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0724 - accuracy: 0.9792 - val_loss: 0.1129 - val_accuracy: 0.9644\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.1012 - val_accuracy: 0.9702\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 0.1016 - val_accuracy: 0.9696\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9894 - val_loss: 0.1033 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9929 - val_loss: 0.1042 - val_accuracy: 0.9700\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.1065 - val_accuracy: 0.9698\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0961 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 0.1028 - val_accuracy: 0.9714\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.0920 - val_accuracy: 0.9740\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0925 - val_accuracy: 0.9748\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9755\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0973 - val_accuracy: 0.9744\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0924 - val_accuracy: 0.9765\n",
      "Epoch 21/25\n",
      " 97/103 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 16.\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9765\n",
      "Epoch 21: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.7245 - accuracy: 0.8134 - val_loss: 0.2840 - val_accuracy: 0.9167\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9292 - val_loss: 0.2133 - val_accuracy: 0.9377\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1784 - accuracy: 0.9488 - val_loss: 0.1789 - val_accuracy: 0.9488\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1372 - accuracy: 0.9613 - val_loss: 0.1440 - val_accuracy: 0.9569\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9690 - val_loss: 0.1260 - val_accuracy: 0.9632\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0856 - accuracy: 0.9757 - val_loss: 0.1155 - val_accuracy: 0.9655\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9809 - val_loss: 0.1066 - val_accuracy: 0.9671\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9859 - val_loss: 0.0995 - val_accuracy: 0.9708\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.0949 - val_accuracy: 0.9714\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0965 - val_accuracy: 0.9714\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9929 - val_loss: 0.0972 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.0949 - val_accuracy: 0.9721\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0958 - val_accuracy: 0.9728\n",
      "Epoch 14/25\n",
      " 97/103 [===========================>..] - ETA: 0s - loss: 0.0142 - accuracy: 0.9970Restoring model weights from the end of the best epoch: 9.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0993 - val_accuracy: 0.9729\n",
      "Epoch 14: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 2s 9ms/step - loss: 0.7181 - accuracy: 0.8171 - val_loss: 0.2710 - val_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9309 - val_loss: 0.2062 - val_accuracy: 0.9402\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9496 - val_loss: 0.1724 - val_accuracy: 0.9504\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9612 - val_loss: 0.1449 - val_accuracy: 0.9570\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1027 - accuracy: 0.9710 - val_loss: 0.1248 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9769 - val_loss: 0.1136 - val_accuracy: 0.9664\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9814 - val_loss: 0.1055 - val_accuracy: 0.9672\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9891 - val_loss: 0.0975 - val_accuracy: 0.9703\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0931 - val_accuracy: 0.9719\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0921 - val_accuracy: 0.9727\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 0.0860 - val_accuracy: 0.9744\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0956 - val_accuracy: 0.9712\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.0893 - val_accuracy: 0.9743\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0885 - val_accuracy: 0.9748\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0877 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      " 95/103 [==========================>...] - ETA: 0s - loss: 0.0060 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0874 - val_accuracy: 0.9766\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.7525 - accuracy: 0.8078 - val_loss: 0.2869 - val_accuracy: 0.9166\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2404 - accuracy: 0.9291 - val_loss: 0.2122 - val_accuracy: 0.9392\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1813 - accuracy: 0.9472 - val_loss: 0.1845 - val_accuracy: 0.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1443 - accuracy: 0.9582 - val_loss: 0.1480 - val_accuracy: 0.9576\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9669 - val_loss: 0.1288 - val_accuracy: 0.9625\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0890 - accuracy: 0.9750 - val_loss: 0.1238 - val_accuracy: 0.9626\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9789 - val_loss: 0.1069 - val_accuracy: 0.9676\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9840 - val_loss: 0.1015 - val_accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.1031 - val_accuracy: 0.9669\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.1006 - val_accuracy: 0.9688\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0989 - val_accuracy: 0.9712\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.0908 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0927 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0892 - val_accuracy: 0.9747\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0971 - val_accuracy: 0.9742\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0918 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0935 - val_accuracy: 0.9761\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0942 - val_accuracy: 0.9758\n",
      "Epoch 19/25\n",
      " 98/103 [===========================>..] - ETA: 0s - loss: 0.0039 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 14.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0949 - val_accuracy: 0.9763\n",
      "Epoch 19: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.7435 - accuracy: 0.8150 - val_loss: 0.2912 - val_accuracy: 0.9141\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.9298 - val_loss: 0.2163 - val_accuracy: 0.9368\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9478 - val_loss: 0.1854 - val_accuracy: 0.9459\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1397 - accuracy: 0.9596 - val_loss: 0.1485 - val_accuracy: 0.9561\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9673 - val_loss: 0.1303 - val_accuracy: 0.9641\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9745 - val_loss: 0.1202 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9792 - val_loss: 0.1129 - val_accuracy: 0.9644\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.1012 - val_accuracy: 0.9702\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 0.1016 - val_accuracy: 0.9696\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9894 - val_loss: 0.1033 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9929 - val_loss: 0.1042 - val_accuracy: 0.9700\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.1065 - val_accuracy: 0.9698\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0961 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 0.1028 - val_accuracy: 0.9714\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.0920 - val_accuracy: 0.9740\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0925 - val_accuracy: 0.9748\n",
      "Epoch 18/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9755\n",
      "Epoch 19/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0973 - val_accuracy: 0.9744\n",
      "Epoch 20/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0924 - val_accuracy: 0.9765\n",
      "Epoch 21/25\n",
      " 97/103 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 16.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9765\n",
      "Epoch 21: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.7245 - accuracy: 0.8134 - val_loss: 0.2840 - val_accuracy: 0.9167\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2422 - accuracy: 0.9292 - val_loss: 0.2133 - val_accuracy: 0.9377\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1784 - accuracy: 0.9488 - val_loss: 0.1789 - val_accuracy: 0.9488\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1372 - accuracy: 0.9613 - val_loss: 0.1440 - val_accuracy: 0.9569\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9690 - val_loss: 0.1260 - val_accuracy: 0.9632\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9757 - val_loss: 0.1155 - val_accuracy: 0.9655\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9809 - val_loss: 0.1066 - val_accuracy: 0.9671\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9859 - val_loss: 0.0995 - val_accuracy: 0.9708\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.0949 - val_accuracy: 0.9714\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.0965 - val_accuracy: 0.9714\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9929 - val_loss: 0.0972 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.0949 - val_accuracy: 0.9721\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0958 - val_accuracy: 0.9728\n",
      "Epoch 14/25\n",
      " 95/103 [==========================>...] - ETA: 0s - loss: 0.0140 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 9.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0993 - val_accuracy: 0.9729\n",
      "Epoch 14: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8500 - accuracy: 0.8029 - val_loss: 0.2710 - val_accuracy: 0.9214\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2331 - accuracy: 0.9295 - val_loss: 0.2013 - val_accuracy: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1682 - accuracy: 0.9504 - val_loss: 0.1656 - val_accuracy: 0.9531\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9630 - val_loss: 0.1378 - val_accuracy: 0.9598\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0975 - accuracy: 0.9724 - val_loss: 0.1205 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9783 - val_loss: 0.1058 - val_accuracy: 0.9693\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.1044 - val_accuracy: 0.9690\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 0.0947 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.1016 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.0932 - val_accuracy: 0.9731\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.0978 - val_accuracy: 0.9711\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 0.0878 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0963 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.0962 - val_accuracy: 0.9739\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0921 - val_accuracy: 0.9754\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0947 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      " 99/103 [===========================>..] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0970 - val_accuracy: 0.9758\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8759 - accuracy: 0.7962 - val_loss: 0.2801 - val_accuracy: 0.9157\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9320 - val_loss: 0.2021 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9514 - val_loss: 0.1804 - val_accuracy: 0.9462\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9621 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9718 - val_loss: 0.1192 - val_accuracy: 0.9645\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9784 - val_loss: 0.1133 - val_accuracy: 0.9659\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 0.1022 - val_accuracy: 0.9674\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0993 - val_accuracy: 0.9710\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0343 - accuracy: 0.9904 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.1001 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.0959 - val_accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0928 - val_accuracy: 0.9749\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.1003 - val_accuracy: 0.9727\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0998 - val_accuracy: 0.9740\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1034 - val_accuracy: 0.9723\n",
      "Epoch 17/25\n",
      " 96/103 [==========================>...] - ETA: 0s - loss: 0.0042 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0933 - val_accuracy: 0.9765\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8210 - accuracy: 0.8093 - val_loss: 0.2774 - val_accuracy: 0.9177\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2287 - accuracy: 0.9328 - val_loss: 0.2052 - val_accuracy: 0.9404\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9512 - val_loss: 0.1773 - val_accuracy: 0.9468\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9629 - val_loss: 0.1362 - val_accuracy: 0.9599\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9703 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.1062 - val_accuracy: 0.9689\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 0.1039 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0951 - val_accuracy: 0.9716\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.0981 - val_accuracy: 0.9694\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0993 - val_accuracy: 0.9713\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0955 - val_accuracy: 0.9727\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0985 - val_accuracy: 0.9704\n",
      "Epoch 13/25\n",
      "101/103 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9970Restoring model weights from the end of the best epoch: 8.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0966 - val_accuracy: 0.9738\n",
      "Epoch 13: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8254 - accuracy: 0.8050 - val_loss: 0.2707 - val_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2301 - accuracy: 0.9338 - val_loss: 0.2035 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.9516 - val_loss: 0.1721 - val_accuracy: 0.9500\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9647 - val_loss: 0.1382 - val_accuracy: 0.9591\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9722 - val_loss: 0.1201 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9787 - val_loss: 0.1102 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9831 - val_loss: 0.1008 - val_accuracy: 0.9691\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0439 - accuracy: 0.9879 - val_loss: 0.0978 - val_accuracy: 0.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9909 - val_loss: 0.0921 - val_accuracy: 0.9725\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0969 - val_accuracy: 0.9729\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.1008 - val_accuracy: 0.9708\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0941 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.1026 - val_accuracy: 0.9709\n",
      "Epoch 14/25\n",
      " 96/103 [==========================>...] - ETA: 0s - loss: 0.0113 - accuracy: 0.9975Restoring model weights from the end of the best epoch: 9.\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1044 - val_accuracy: 0.9723\n",
      "Epoch 14: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.8500 - accuracy: 0.8029 - val_loss: 0.2710 - val_accuracy: 0.9214\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2331 - accuracy: 0.9295 - val_loss: 0.2013 - val_accuracy: 0.9399\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1682 - accuracy: 0.9504 - val_loss: 0.1656 - val_accuracy: 0.9531\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1283 - accuracy: 0.9630 - val_loss: 0.1378 - val_accuracy: 0.9598\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9724 - val_loss: 0.1205 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0755 - accuracy: 0.9783 - val_loss: 0.1058 - val_accuracy: 0.9693\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.1044 - val_accuracy: 0.9690\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9871 - val_loss: 0.0947 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.1016 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.0932 - val_accuracy: 0.9731\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.0978 - val_accuracy: 0.9711\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9966 - val_loss: 0.0878 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0963 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.0962 - val_accuracy: 0.9739\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0921 - val_accuracy: 0.9754\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0947 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0970 - val_accuracy: 0.9758\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8759 - accuracy: 0.7962 - val_loss: 0.2801 - val_accuracy: 0.9157\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9320 - val_loss: 0.2021 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9514 - val_loss: 0.1804 - val_accuracy: 0.9462\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9621 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9718 - val_loss: 0.1192 - val_accuracy: 0.9645\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9784 - val_loss: 0.1133 - val_accuracy: 0.9659\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 0.1022 - val_accuracy: 0.9674\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0993 - val_accuracy: 0.9710\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0343 - accuracy: 0.9904 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.1001 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.0959 - val_accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.0920 - val_accuracy: 0.9743\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0928 - val_accuracy: 0.9749\n",
      "Epoch 14/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.1003 - val_accuracy: 0.9727\n",
      "Epoch 15/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0998 - val_accuracy: 0.9740\n",
      "Epoch 16/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1034 - val_accuracy: 0.9723\n",
      "Epoch 17/25\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9994Restoring model weights from the end of the best epoch: 12.\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0933 - val_accuracy: 0.9765\n",
      "Epoch 17: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.8210 - accuracy: 0.8093 - val_loss: 0.2774 - val_accuracy: 0.9177\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2287 - accuracy: 0.9328 - val_loss: 0.2052 - val_accuracy: 0.9404\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9512 - val_loss: 0.1773 - val_accuracy: 0.9468\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9629 - val_loss: 0.1362 - val_accuracy: 0.9599\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9703 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.1062 - val_accuracy: 0.9689\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 0.1039 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0951 - val_accuracy: 0.9716\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.0981 - val_accuracy: 0.9694\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0993 - val_accuracy: 0.9713\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0955 - val_accuracy: 0.9727\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0985 - val_accuracy: 0.9704\n",
      "Epoch 13/25\n",
      " 95/103 [==========================>...] - ETA: 0s - loss: 0.0131 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0966 - val_accuracy: 0.9738\n",
      "Epoch 13: early stopping\n",
      "35/35 [==============================] - 0s 3ms/step\n",
      "Epoch 1/25\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.8254 - accuracy: 0.8050 - val_loss: 0.2707 - val_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.2301 - accuracy: 0.9338 - val_loss: 0.2035 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1658 - accuracy: 0.9516 - val_loss: 0.1721 - val_accuracy: 0.9500\n",
      "Epoch 4/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9647 - val_loss: 0.1382 - val_accuracy: 0.9591\n",
      "Epoch 5/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9722 - val_loss: 0.1201 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9787 - val_loss: 0.1102 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9831 - val_loss: 0.1008 - val_accuracy: 0.9691\n",
      "Epoch 8/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9879 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0341 - accuracy: 0.9909 - val_loss: 0.0921 - val_accuracy: 0.9725\n",
      "Epoch 10/25\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0969 - val_accuracy: 0.9729\n",
      "Epoch 11/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.1008 - val_accuracy: 0.9708\n",
      "Epoch 12/25\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0941 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.1026 - val_accuracy: 0.9709\n",
      "Epoch 14/25\n",
      " 96/103 [==========================>...] - ETA: 0s - loss: 0.0113 - accuracy: 0.9975Restoring model weights from the end of the best epoch: 9.\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1044 - val_accuracy: 0.9723\n",
      "Epoch 14: early stopping\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6686 - accuracy: 0.8113 - val_loss: 0.3024 - val_accuracy: 0.9127\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.9184 - val_loss: 0.2487 - val_accuracy: 0.9265\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9370 - val_loss: 0.2104 - val_accuracy: 0.9395\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9482 - val_loss: 0.1848 - val_accuracy: 0.9467\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9577 - val_loss: 0.1526 - val_accuracy: 0.9564\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9658 - val_loss: 0.1476 - val_accuracy: 0.9582\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9719 - val_loss: 0.1289 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9755 - val_loss: 0.1143 - val_accuracy: 0.9652\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9802 - val_loss: 0.1222 - val_accuracy: 0.9637\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9824 - val_loss: 0.1122 - val_accuracy: 0.9667\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9863 - val_loss: 0.1049 - val_accuracy: 0.9682\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0950 - val_accuracy: 0.9716\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.0966 - val_accuracy: 0.9702\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 0.0947 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9946 - val_loss: 0.0909 - val_accuracy: 0.9732\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9746\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0954 - val_accuracy: 0.9730\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0944 - val_accuracy: 0.9727\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.0878 - val_accuracy: 0.9744\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0930 - val_accuracy: 0.9752\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0962 - val_accuracy: 0.9742\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0940 - val_accuracy: 0.9751\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9758\n",
      "Epoch 25/25\n",
      "80/90 [=========================>....] - ETA: 0s - loss: 0.0035 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.6511 - accuracy: 0.8157 - val_loss: 0.3087 - val_accuracy: 0.9115\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9210 - val_loss: 0.2445 - val_accuracy: 0.9287\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9384 - val_loss: 0.2205 - val_accuracy: 0.9342\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9492 - val_loss: 0.1724 - val_accuracy: 0.9501\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9582 - val_loss: 0.1502 - val_accuracy: 0.9573\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9671 - val_loss: 0.1458 - val_accuracy: 0.9564\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9721 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 0.1164 - val_accuracy: 0.9668\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.1212 - val_accuracy: 0.9629\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.1090 - val_accuracy: 0.9671\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.1043 - val_accuracy: 0.9687\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0992 - val_accuracy: 0.9692\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9906 - val_loss: 0.0970 - val_accuracy: 0.9706\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9925 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.0986 - val_accuracy: 0.9711\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9958 - val_loss: 0.0952 - val_accuracy: 0.9725\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0941 - val_accuracy: 0.9737\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.0938 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0948 - val_accuracy: 0.9738\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0969 - val_accuracy: 0.9731\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.0948 - val_accuracy: 0.9733\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.0986 - val_accuracy: 0.9732\n",
      "Epoch 23/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0051 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0957 - val_accuracy: 0.9750\n",
      "Epoch 23: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6757 - accuracy: 0.8127 - val_loss: 0.3165 - val_accuracy: 0.9049\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.9197 - val_loss: 0.2612 - val_accuracy: 0.9227\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9352 - val_loss: 0.2282 - val_accuracy: 0.9327\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9479 - val_loss: 0.1800 - val_accuracy: 0.9489\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9556 - val_loss: 0.1575 - val_accuracy: 0.9534\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9650 - val_loss: 0.1441 - val_accuracy: 0.9583\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9699 - val_loss: 0.1320 - val_accuracy: 0.9609\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 0.1150 - val_accuracy: 0.9667\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.1161 - val_accuracy: 0.9657\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 0.1085 - val_accuracy: 0.9689\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.1063 - val_accuracy: 0.9684\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.0936 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9719\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0879 - val_accuracy: 0.9754\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.0870 - val_accuracy: 0.9755\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0873 - val_accuracy: 0.9756\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.0875 - val_accuracy: 0.9749\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.0910 - val_accuracy: 0.9746\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 23/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0054 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0905 - val_accuracy: 0.9758\n",
      "Epoch 23: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6536 - accuracy: 0.8131 - val_loss: 0.3093 - val_accuracy: 0.9069\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.9211 - val_loss: 0.2472 - val_accuracy: 0.9283\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9367 - val_loss: 0.2112 - val_accuracy: 0.9398\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9481 - val_loss: 0.1830 - val_accuracy: 0.9488\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.1582 - val_accuracy: 0.9539\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9656 - val_loss: 0.1350 - val_accuracy: 0.9590\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9716 - val_loss: 0.1346 - val_accuracy: 0.9589\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9764 - val_loss: 0.1160 - val_accuracy: 0.9658\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9814 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9839 - val_loss: 0.1042 - val_accuracy: 0.9691\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.0981 - val_accuracy: 0.9702\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9898 - val_loss: 0.0995 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0898 - val_accuracy: 0.9730\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.0925 - val_accuracy: 0.9729\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.0904 - val_accuracy: 0.9736\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0896 - val_accuracy: 0.9749\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0896 - val_accuracy: 0.9746\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0899 - val_accuracy: 0.9756\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0927 - val_accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0926 - val_accuracy: 0.9747\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0964 - val_accuracy: 0.9744\n",
      "Epoch 25/25\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0940 - val_accuracy: 0.9749\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6686 - accuracy: 0.8113 - val_loss: 0.3024 - val_accuracy: 0.9127\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.9184 - val_loss: 0.2487 - val_accuracy: 0.9265\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9370 - val_loss: 0.2104 - val_accuracy: 0.9395\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9482 - val_loss: 0.1848 - val_accuracy: 0.9467\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9577 - val_loss: 0.1526 - val_accuracy: 0.9564\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9658 - val_loss: 0.1476 - val_accuracy: 0.9582\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9719 - val_loss: 0.1289 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9755 - val_loss: 0.1143 - val_accuracy: 0.9652\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9802 - val_loss: 0.1222 - val_accuracy: 0.9637\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9824 - val_loss: 0.1122 - val_accuracy: 0.9667\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9863 - val_loss: 0.1049 - val_accuracy: 0.9682\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0950 - val_accuracy: 0.9716\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.0966 - val_accuracy: 0.9702\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 0.0947 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9946 - val_loss: 0.0909 - val_accuracy: 0.9732\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9746\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0954 - val_accuracy: 0.9730\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0944 - val_accuracy: 0.9727\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.0878 - val_accuracy: 0.9744\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0930 - val_accuracy: 0.9752\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0962 - val_accuracy: 0.9742\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0940 - val_accuracy: 0.9751\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9758\n",
      "Epoch 25/25\n",
      "88/90 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6511 - accuracy: 0.8157 - val_loss: 0.3087 - val_accuracy: 0.9115\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9210 - val_loss: 0.2445 - val_accuracy: 0.9287\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9384 - val_loss: 0.2205 - val_accuracy: 0.9342\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9492 - val_loss: 0.1724 - val_accuracy: 0.9501\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9582 - val_loss: 0.1502 - val_accuracy: 0.9573\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9671 - val_loss: 0.1458 - val_accuracy: 0.9564\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9721 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9774 - val_loss: 0.1164 - val_accuracy: 0.9668\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.1212 - val_accuracy: 0.9629\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.1090 - val_accuracy: 0.9671\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.1043 - val_accuracy: 0.9687\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0992 - val_accuracy: 0.9692\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9906 - val_loss: 0.0970 - val_accuracy: 0.9706\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9925 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.0986 - val_accuracy: 0.9711\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9958 - val_loss: 0.0952 - val_accuracy: 0.9725\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0941 - val_accuracy: 0.9737\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.0938 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0948 - val_accuracy: 0.9738\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0969 - val_accuracy: 0.9731\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.0948 - val_accuracy: 0.9733\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.0986 - val_accuracy: 0.9732\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0957 - val_accuracy: 0.9750\n",
      "Epoch 23: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.6757 - accuracy: 0.8127 - val_loss: 0.3165 - val_accuracy: 0.9049\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.9197 - val_loss: 0.2612 - val_accuracy: 0.9227\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9352 - val_loss: 0.2282 - val_accuracy: 0.9327\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9479 - val_loss: 0.1800 - val_accuracy: 0.9489\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9556 - val_loss: 0.1575 - val_accuracy: 0.9534\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9650 - val_loss: 0.1441 - val_accuracy: 0.9583\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9699 - val_loss: 0.1320 - val_accuracy: 0.9609\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 0.1150 - val_accuracy: 0.9667\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.1161 - val_accuracy: 0.9657\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 0.1085 - val_accuracy: 0.9689\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.1063 - val_accuracy: 0.9684\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.0936 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0975 - val_accuracy: 0.9719\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0879 - val_accuracy: 0.9754\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.0870 - val_accuracy: 0.9755\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0873 - val_accuracy: 0.9756\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.0875 - val_accuracy: 0.9749\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.0910 - val_accuracy: 0.9746\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 23/25\n",
      "72/90 [=======================>......] - ETA: 0s - loss: 0.0054 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0905 - val_accuracy: 0.9758\n",
      "Epoch 23: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.6536 - accuracy: 0.8131 - val_loss: 0.3093 - val_accuracy: 0.9069\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.9211 - val_loss: 0.2472 - val_accuracy: 0.9283\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9367 - val_loss: 0.2112 - val_accuracy: 0.9398\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.9481 - val_loss: 0.1830 - val_accuracy: 0.9488\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.1582 - val_accuracy: 0.9539\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9656 - val_loss: 0.1350 - val_accuracy: 0.9590\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9716 - val_loss: 0.1346 - val_accuracy: 0.9589\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9764 - val_loss: 0.1160 - val_accuracy: 0.9658\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9814 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9839 - val_loss: 0.1042 - val_accuracy: 0.9691\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.0981 - val_accuracy: 0.9702\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9898 - val_loss: 0.0995 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0898 - val_accuracy: 0.9730\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.0925 - val_accuracy: 0.9729\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.0904 - val_accuracy: 0.9736\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0896 - val_accuracy: 0.9749\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0896 - val_accuracy: 0.9746\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0899 - val_accuracy: 0.9756\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0927 - val_accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.0926 - val_accuracy: 0.9747\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0964 - val_accuracy: 0.9744\n",
      "Epoch 25/25\n",
      "81/90 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0940 - val_accuracy: 0.9749\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7792 - accuracy: 0.8026 - val_loss: 0.2864 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9250 - val_loss: 0.2195 - val_accuracy: 0.9353\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9448 - val_loss: 0.1852 - val_accuracy: 0.9469\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9570 - val_loss: 0.1516 - val_accuracy: 0.9567\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9666 - val_loss: 0.1339 - val_accuracy: 0.9601\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9731 - val_loss: 0.1239 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9793 - val_loss: 0.1106 - val_accuracy: 0.9663\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 0.1006 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.1087 - val_accuracy: 0.9675\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.0990 - val_accuracy: 0.9708\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9937 - val_loss: 0.0886 - val_accuracy: 0.9745\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0893 - val_accuracy: 0.9747\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0845 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.0867 - val_accuracy: 0.9762\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0912 - val_accuracy: 0.9753\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0912 - val_accuracy: 0.9754\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0854 - val_accuracy: 0.9770\n",
      "Epoch 21/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 16.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0916 - val_accuracy: 0.9763\n",
      "Epoch 21: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8193 - accuracy: 0.7921 - val_loss: 0.2892 - val_accuracy: 0.9153\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9258 - val_loss: 0.2307 - val_accuracy: 0.9347\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9433 - val_loss: 0.1937 - val_accuracy: 0.9444\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9545 - val_loss: 0.1578 - val_accuracy: 0.9555\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9636 - val_loss: 0.1354 - val_accuracy: 0.9608\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9722 - val_loss: 0.1257 - val_accuracy: 0.9621\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9776 - val_loss: 0.1137 - val_accuracy: 0.9658\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9818 - val_loss: 0.1032 - val_accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9854 - val_loss: 0.1044 - val_accuracy: 0.9684\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.1001 - val_accuracy: 0.9693\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9908 - val_loss: 0.1022 - val_accuracy: 0.9689\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.0944 - val_accuracy: 0.9709\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.0949 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.0911 - val_accuracy: 0.9737\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.0985 - val_accuracy: 0.9735\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0885 - val_accuracy: 0.9759\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.0924 - val_accuracy: 0.9751\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0940 - val_accuracy: 0.9752\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0914 - val_accuracy: 0.9747\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.0990 - val_accuracy: 0.9737\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0994 - val_accuracy: 0.9749\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7854 - accuracy: 0.8024 - val_loss: 0.2880 - val_accuracy: 0.9154\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9267 - val_loss: 0.2366 - val_accuracy: 0.9300\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9447 - val_loss: 0.1966 - val_accuracy: 0.9422\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9565 - val_loss: 0.1571 - val_accuracy: 0.9557\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9643 - val_loss: 0.1379 - val_accuracy: 0.9600\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9720 - val_loss: 0.1262 - val_accuracy: 0.9641\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9768 - val_loss: 0.1178 - val_accuracy: 0.9652\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 0.1051 - val_accuracy: 0.9695\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.1067 - val_accuracy: 0.9682\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.1006 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9907 - val_loss: 0.0979 - val_accuracy: 0.9718\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.1055 - val_accuracy: 0.9691\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0971 - val_accuracy: 0.9720\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.0943 - val_accuracy: 0.9732\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0983 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0929 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0933 - val_accuracy: 0.9743\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0931 - val_accuracy: 0.9758\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.0961 - val_accuracy: 0.9736\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0922 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0962 - val_accuracy: 0.9758\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0975 - val_accuracy: 0.9760\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0986 - val_accuracy: 0.9758\n",
      "Epoch 25/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9757\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7661 - accuracy: 0.8007 - val_loss: 0.2898 - val_accuracy: 0.9143\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9273 - val_loss: 0.2302 - val_accuracy: 0.9323\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9442 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9573 - val_loss: 0.1608 - val_accuracy: 0.9531\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9653 - val_loss: 0.1386 - val_accuracy: 0.9596\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9732 - val_loss: 0.1200 - val_accuracy: 0.9654\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9790 - val_loss: 0.1143 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9839 - val_loss: 0.1051 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9871 - val_loss: 0.0979 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9891 - val_loss: 0.0986 - val_accuracy: 0.9709\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0925 - val_accuracy: 0.9726\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9943 - val_loss: 0.0977 - val_accuracy: 0.9713\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.1008 - val_accuracy: 0.9698\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.0980 - val_accuracy: 0.9712\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0944 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.0898 - val_accuracy: 0.9743\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0919 - val_accuracy: 0.9746\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0939 - val_accuracy: 0.9751\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0942 - val_accuracy: 0.9754\n",
      "Epoch 22/25\n",
      "78/90 [=========================>....] - ETA: 0s - loss: 0.0029 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0945 - val_accuracy: 0.9758\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7792 - accuracy: 0.8026 - val_loss: 0.2864 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9250 - val_loss: 0.2195 - val_accuracy: 0.9353\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9448 - val_loss: 0.1852 - val_accuracy: 0.9469\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9570 - val_loss: 0.1516 - val_accuracy: 0.9567\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9666 - val_loss: 0.1339 - val_accuracy: 0.9601\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9731 - val_loss: 0.1239 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9793 - val_loss: 0.1106 - val_accuracy: 0.9663\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 0.1006 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.1087 - val_accuracy: 0.9675\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.0990 - val_accuracy: 0.9708\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9937 - val_loss: 0.0886 - val_accuracy: 0.9745\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0918 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0893 - val_accuracy: 0.9747\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0845 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.0867 - val_accuracy: 0.9762\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0912 - val_accuracy: 0.9753\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0912 - val_accuracy: 0.9754\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0854 - val_accuracy: 0.9770\n",
      "Epoch 21/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0037 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 16.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0916 - val_accuracy: 0.9763\n",
      "Epoch 21: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8193 - accuracy: 0.7921 - val_loss: 0.2892 - val_accuracy: 0.9153\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9258 - val_loss: 0.2307 - val_accuracy: 0.9347\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9433 - val_loss: 0.1937 - val_accuracy: 0.9444\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9545 - val_loss: 0.1578 - val_accuracy: 0.9555\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9636 - val_loss: 0.1354 - val_accuracy: 0.9608\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9722 - val_loss: 0.1257 - val_accuracy: 0.9621\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9776 - val_loss: 0.1137 - val_accuracy: 0.9658\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9818 - val_loss: 0.1032 - val_accuracy: 0.9690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9854 - val_loss: 0.1044 - val_accuracy: 0.9684\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.1001 - val_accuracy: 0.9693\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9908 - val_loss: 0.1022 - val_accuracy: 0.9689\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.0944 - val_accuracy: 0.9709\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9941 - val_loss: 0.0949 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.0911 - val_accuracy: 0.9737\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.0985 - val_accuracy: 0.9735\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0885 - val_accuracy: 0.9759\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.0924 - val_accuracy: 0.9751\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0940 - val_accuracy: 0.9752\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0914 - val_accuracy: 0.9747\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.0990 - val_accuracy: 0.9737\n",
      "Epoch 22/25\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0994 - val_accuracy: 0.9749\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.7854 - accuracy: 0.8024 - val_loss: 0.2880 - val_accuracy: 0.9154\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9267 - val_loss: 0.2366 - val_accuracy: 0.9300\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9447 - val_loss: 0.1966 - val_accuracy: 0.9422\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9565 - val_loss: 0.1571 - val_accuracy: 0.9557\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9643 - val_loss: 0.1379 - val_accuracy: 0.9600\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9720 - val_loss: 0.1262 - val_accuracy: 0.9641\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9768 - val_loss: 0.1178 - val_accuracy: 0.9652\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 0.1051 - val_accuracy: 0.9695\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9855 - val_loss: 0.1067 - val_accuracy: 0.9682\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.1006 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9907 - val_loss: 0.0979 - val_accuracy: 0.9718\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.1055 - val_accuracy: 0.9691\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0971 - val_accuracy: 0.9720\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.0943 - val_accuracy: 0.9732\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0983 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0929 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0933 - val_accuracy: 0.9743\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0931 - val_accuracy: 0.9758\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.0961 - val_accuracy: 0.9736\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0922 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0954 - val_accuracy: 0.9752\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0962 - val_accuracy: 0.9758\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0975 - val_accuracy: 0.9760\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0986 - val_accuracy: 0.9758\n",
      "Epoch 25/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9757\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7661 - accuracy: 0.8007 - val_loss: 0.2898 - val_accuracy: 0.9143\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.9273 - val_loss: 0.2302 - val_accuracy: 0.9323\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9442 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9573 - val_loss: 0.1608 - val_accuracy: 0.9531\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9653 - val_loss: 0.1386 - val_accuracy: 0.9596\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9732 - val_loss: 0.1200 - val_accuracy: 0.9654\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9790 - val_loss: 0.1143 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9839 - val_loss: 0.1051 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9871 - val_loss: 0.0979 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9891 - val_loss: 0.0986 - val_accuracy: 0.9709\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0925 - val_accuracy: 0.9726\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9943 - val_loss: 0.0977 - val_accuracy: 0.9713\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.1008 - val_accuracy: 0.9698\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.0980 - val_accuracy: 0.9712\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0944 - val_accuracy: 0.9731\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.0898 - val_accuracy: 0.9743\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0919 - val_accuracy: 0.9746\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0939 - val_accuracy: 0.9751\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9748\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0942 - val_accuracy: 0.9754\n",
      "Epoch 22/25\n",
      "73/90 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0945 - val_accuracy: 0.9758\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9107 - accuracy: 0.7907 - val_loss: 0.2840 - val_accuracy: 0.9149\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9277 - val_loss: 0.2156 - val_accuracy: 0.9347\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9468 - val_loss: 0.1733 - val_accuracy: 0.9513\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9603 - val_loss: 0.1415 - val_accuracy: 0.9585\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9691 - val_loss: 0.1248 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9761 - val_loss: 0.1096 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.1046 - val_accuracy: 0.9682\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9853 - val_loss: 0.1003 - val_accuracy: 0.9688\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 0.1095 - val_accuracy: 0.9683\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.0992 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.1003 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.0890 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0924 - val_accuracy: 0.9743\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0891 - val_accuracy: 0.9744\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.0893 - val_accuracy: 0.9759\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0911 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 12.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0909 - val_accuracy: 0.9769\n",
      "Epoch 17: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9650 - accuracy: 0.7778 - val_loss: 0.2846 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9282 - val_loss: 0.2197 - val_accuracy: 0.9368\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9479 - val_loss: 0.1804 - val_accuracy: 0.9486\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9587 - val_loss: 0.1443 - val_accuracy: 0.9588\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9684 - val_loss: 0.1262 - val_accuracy: 0.9634\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9754 - val_loss: 0.1153 - val_accuracy: 0.9656\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.1023 - val_accuracy: 0.9693\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.1040 - val_accuracy: 0.9684\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.0958 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0909 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.0982 - val_accuracy: 0.9721\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.0914 - val_accuracy: 0.9742\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0948 - val_accuracy: 0.9744\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0938 - val_accuracy: 0.9749\n",
      "Epoch 17/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0044 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 12.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0939 - val_accuracy: 0.9755\n",
      "Epoch 17: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.9065 - accuracy: 0.7891 - val_loss: 0.2809 - val_accuracy: 0.9158\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9281 - val_loss: 0.2232 - val_accuracy: 0.9351\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9486 - val_loss: 0.1745 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9599 - val_loss: 0.1462 - val_accuracy: 0.9582\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9673 - val_loss: 0.1249 - val_accuracy: 0.9635\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9753 - val_loss: 0.1128 - val_accuracy: 0.9675\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 0.1093 - val_accuracy: 0.9685\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.0982 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 0.1039 - val_accuracy: 0.9688\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0941 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0981 - val_accuracy: 0.9719\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0956 - val_accuracy: 0.9733\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0948 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0990 - val_accuracy: 0.9745\n",
      "Epoch 16/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 11.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0952 - val_accuracy: 0.9758\n",
      "Epoch 16: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8866 - accuracy: 0.7896 - val_loss: 0.2832 - val_accuracy: 0.9175\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9304 - val_loss: 0.2172 - val_accuracy: 0.9348\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9481 - val_loss: 0.1739 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9607 - val_loss: 0.1562 - val_accuracy: 0.9535\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9689 - val_loss: 0.1244 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9762 - val_loss: 0.1134 - val_accuracy: 0.9658\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.1065 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9863 - val_loss: 0.1009 - val_accuracy: 0.9713\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9893 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.0977 - val_accuracy: 0.9698\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9961 - val_loss: 0.0982 - val_accuracy: 0.9716\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.0938 - val_accuracy: 0.9722\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0967 - val_accuracy: 0.9739\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0920 - val_accuracy: 0.9740\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0918 - val_accuracy: 0.9750\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0944 - val_accuracy: 0.9753\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0964 - val_accuracy: 0.9759\n",
      "Epoch 22/25\n",
      "75/90 [========================>.....] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9753\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9107 - accuracy: 0.7907 - val_loss: 0.2840 - val_accuracy: 0.9149\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9277 - val_loss: 0.2156 - val_accuracy: 0.9347\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9468 - val_loss: 0.1733 - val_accuracy: 0.9513\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9603 - val_loss: 0.1415 - val_accuracy: 0.9585\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9691 - val_loss: 0.1248 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9761 - val_loss: 0.1096 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9813 - val_loss: 0.1046 - val_accuracy: 0.9682\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9853 - val_loss: 0.1003 - val_accuracy: 0.9688\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9887 - val_loss: 0.1095 - val_accuracy: 0.9683\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.0992 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.1003 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.0890 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0924 - val_accuracy: 0.9743\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0891 - val_accuracy: 0.9744\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.0893 - val_accuracy: 0.9759\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0911 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "75/90 [========================>.....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 12.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0909 - val_accuracy: 0.9769\n",
      "Epoch 17: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9650 - accuracy: 0.7778 - val_loss: 0.2846 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9282 - val_loss: 0.2197 - val_accuracy: 0.9368\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9479 - val_loss: 0.1804 - val_accuracy: 0.9486\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.9587 - val_loss: 0.1443 - val_accuracy: 0.9588\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9684 - val_loss: 0.1262 - val_accuracy: 0.9634\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9754 - val_loss: 0.1153 - val_accuracy: 0.9656\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.1023 - val_accuracy: 0.9693\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.1040 - val_accuracy: 0.9684\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.0958 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0909 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.0982 - val_accuracy: 0.9721\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.0914 - val_accuracy: 0.9742\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0948 - val_accuracy: 0.9744\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0938 - val_accuracy: 0.9749\n",
      "Epoch 17/25\n",
      "72/90 [=======================>......] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 12.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0939 - val_accuracy: 0.9755\n",
      "Epoch 17: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9065 - accuracy: 0.7891 - val_loss: 0.2809 - val_accuracy: 0.9158\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9281 - val_loss: 0.2232 - val_accuracy: 0.9351\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9486 - val_loss: 0.1745 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9599 - val_loss: 0.1462 - val_accuracy: 0.9582\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9673 - val_loss: 0.1249 - val_accuracy: 0.9635\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9753 - val_loss: 0.1128 - val_accuracy: 0.9675\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 0.1093 - val_accuracy: 0.9685\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.0982 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 0.1039 - val_accuracy: 0.9688\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0941 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0981 - val_accuracy: 0.9719\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0956 - val_accuracy: 0.9733\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0948 - val_accuracy: 0.9743\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0990 - val_accuracy: 0.9745\n",
      "Epoch 16/25\n",
      "75/90 [========================>.....] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 11.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0952 - val_accuracy: 0.9758\n",
      "Epoch 16: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8866 - accuracy: 0.7896 - val_loss: 0.2832 - val_accuracy: 0.9175\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9304 - val_loss: 0.2172 - val_accuracy: 0.9348\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9481 - val_loss: 0.1739 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9607 - val_loss: 0.1562 - val_accuracy: 0.9535\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9689 - val_loss: 0.1244 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9762 - val_loss: 0.1134 - val_accuracy: 0.9658\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.1065 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9863 - val_loss: 0.1009 - val_accuracy: 0.9713\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9893 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.0977 - val_accuracy: 0.9698\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9961 - val_loss: 0.0982 - val_accuracy: 0.9716\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.0938 - val_accuracy: 0.9722\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0967 - val_accuracy: 0.9739\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0920 - val_accuracy: 0.9740\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.0918 - val_accuracy: 0.9750\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0944 - val_accuracy: 0.9753\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0964 - val_accuracy: 0.9759\n",
      "Epoch 22/25\n",
      "74/90 [=======================>......] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9753\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.8016 - val_loss: 0.3048 - val_accuracy: 0.9105\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.9167 - val_loss: 0.2554 - val_accuracy: 0.9242\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9349 - val_loss: 0.2131 - val_accuracy: 0.9403\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9464 - val_loss: 0.1827 - val_accuracy: 0.9477\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9557 - val_loss: 0.1620 - val_accuracy: 0.9526\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9625 - val_loss: 0.1498 - val_accuracy: 0.9553\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9691 - val_loss: 0.1307 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9740 - val_loss: 0.1195 - val_accuracy: 0.9650\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9784 - val_loss: 0.1347 - val_accuracy: 0.9599\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9803 - val_loss: 0.1130 - val_accuracy: 0.9661\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.1052 - val_accuracy: 0.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9877 - val_loss: 0.0977 - val_accuracy: 0.9693\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.0994 - val_accuracy: 0.9698\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 0.0954 - val_accuracy: 0.9713\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9927 - val_loss: 0.0906 - val_accuracy: 0.9735\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.0932 - val_accuracy: 0.9726\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0912 - val_accuracy: 0.9730\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0967 - val_accuracy: 0.9721\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0940 - val_accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0889 - val_accuracy: 0.9749\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0934 - val_accuracy: 0.9751\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0943 - val_accuracy: 0.9744\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0917 - val_accuracy: 0.9762\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0936 - val_accuracy: 0.9745\n",
      "Epoch 25/25\n",
      "76/80 [===========================>..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9751\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6964 - accuracy: 0.8032 - val_loss: 0.3084 - val_accuracy: 0.9111\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9167 - val_loss: 0.2631 - val_accuracy: 0.9226\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9352 - val_loss: 0.2224 - val_accuracy: 0.9355\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9454 - val_loss: 0.1858 - val_accuracy: 0.9469\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9555 - val_loss: 0.1655 - val_accuracy: 0.9532\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9634 - val_loss: 0.1555 - val_accuracy: 0.9541\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9676 - val_loss: 0.1352 - val_accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9746 - val_loss: 0.1197 - val_accuracy: 0.9638\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9783 - val_loss: 0.1297 - val_accuracy: 0.9603\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9804 - val_loss: 0.1153 - val_accuracy: 0.9653\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9838 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9862 - val_loss: 0.0980 - val_accuracy: 0.9694\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0960 - val_accuracy: 0.9710\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.0993 - val_accuracy: 0.9687\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.0968 - val_accuracy: 0.9709\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.0911 - val_accuracy: 0.9727\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.0930 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0917 - val_accuracy: 0.9726\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.0933 - val_accuracy: 0.9723\n",
      "Epoch 22/25\n",
      "72/80 [==========================>...] - ETA: 0s - loss: 0.0086 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 17.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 0.9734\n",
      "Epoch 22: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.7227 - accuracy: 0.7985 - val_loss: 0.3091 - val_accuracy: 0.9103\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.9172 - val_loss: 0.2774 - val_accuracy: 0.9170\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9342 - val_loss: 0.2290 - val_accuracy: 0.9341\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9454 - val_loss: 0.1916 - val_accuracy: 0.9456\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9532 - val_loss: 0.1692 - val_accuracy: 0.9518\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9619 - val_loss: 0.1496 - val_accuracy: 0.9571\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9681 - val_loss: 0.1377 - val_accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9734 - val_loss: 0.1208 - val_accuracy: 0.9652\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9806 - val_loss: 0.1130 - val_accuracy: 0.9654\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9836 - val_loss: 0.1057 - val_accuracy: 0.9693\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.1034 - val_accuracy: 0.9689\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0978 - val_accuracy: 0.9707\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 0.0949 - val_accuracy: 0.9718\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.1021 - val_accuracy: 0.9694\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.0929 - val_accuracy: 0.9718\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 0.0939 - val_accuracy: 0.9718\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.0895 - val_accuracy: 0.9737\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0906 - val_accuracy: 0.9736\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0877 - val_accuracy: 0.9737\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0921 - val_accuracy: 0.9732\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0901 - val_accuracy: 0.9747\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0918 - val_accuracy: 0.9753\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0908 - val_accuracy: 0.9749\n",
      "Epoch 25/25\n",
      "78/80 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0956 - val_accuracy: 0.9739\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.6976 - accuracy: 0.8026 - val_loss: 0.3067 - val_accuracy: 0.9095\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.9181 - val_loss: 0.2627 - val_accuracy: 0.9226\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9347 - val_loss: 0.2160 - val_accuracy: 0.9405\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9467 - val_loss: 0.1979 - val_accuracy: 0.9423\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9544 - val_loss: 0.1669 - val_accuracy: 0.9520\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9622 - val_loss: 0.1431 - val_accuracy: 0.9576\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.1388 - val_accuracy: 0.9578\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9747 - val_loss: 0.1242 - val_accuracy: 0.9634\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9780 - val_loss: 0.1151 - val_accuracy: 0.9657\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9824 - val_loss: 0.1129 - val_accuracy: 0.9655\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9841 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9876 - val_loss: 0.0992 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.1020 - val_accuracy: 0.9691\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9910 - val_loss: 0.0974 - val_accuracy: 0.9699\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0946 - val_accuracy: 0.9721\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9944 - val_loss: 0.0932 - val_accuracy: 0.9715\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0910 - val_accuracy: 0.9728\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.0907 - val_accuracy: 0.9729\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.0901 - val_accuracy: 0.9741\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.0885 - val_accuracy: 0.9735\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.0898 - val_accuracy: 0.9742\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0917 - val_accuracy: 0.9741\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0910 - val_accuracy: 0.9751\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0921 - val_accuracy: 0.9752\n",
      "Epoch 25/25\n",
      "67/80 [========================>.....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0921 - val_accuracy: 0.9743\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6999 - accuracy: 0.8016 - val_loss: 0.3048 - val_accuracy: 0.9105\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.9167 - val_loss: 0.2554 - val_accuracy: 0.9242\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9349 - val_loss: 0.2131 - val_accuracy: 0.9403\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9464 - val_loss: 0.1827 - val_accuracy: 0.9477\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9557 - val_loss: 0.1620 - val_accuracy: 0.9526\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9625 - val_loss: 0.1498 - val_accuracy: 0.9553\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9691 - val_loss: 0.1307 - val_accuracy: 0.9627\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9740 - val_loss: 0.1195 - val_accuracy: 0.9650\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9784 - val_loss: 0.1347 - val_accuracy: 0.9599\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9803 - val_loss: 0.1130 - val_accuracy: 0.9661\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.1052 - val_accuracy: 0.9691\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9877 - val_loss: 0.0977 - val_accuracy: 0.9693\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.0994 - val_accuracy: 0.9698\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 0.0954 - val_accuracy: 0.9713\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9927 - val_loss: 0.0906 - val_accuracy: 0.9735\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.0932 - val_accuracy: 0.9726\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0912 - val_accuracy: 0.9730\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0967 - val_accuracy: 0.9721\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.0940 - val_accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0889 - val_accuracy: 0.9749\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0934 - val_accuracy: 0.9751\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0943 - val_accuracy: 0.9744\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0917 - val_accuracy: 0.9762\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0936 - val_accuracy: 0.9745\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/80 [========================>.....] - ETA: 0s - loss: 0.0048 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9751\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.6964 - accuracy: 0.8032 - val_loss: 0.3084 - val_accuracy: 0.9111\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.9167 - val_loss: 0.2631 - val_accuracy: 0.9226\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9352 - val_loss: 0.2224 - val_accuracy: 0.9355\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9454 - val_loss: 0.1858 - val_accuracy: 0.9469\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9555 - val_loss: 0.1655 - val_accuracy: 0.9532\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9634 - val_loss: 0.1555 - val_accuracy: 0.9541\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9676 - val_loss: 0.1352 - val_accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9746 - val_loss: 0.1197 - val_accuracy: 0.9638\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9783 - val_loss: 0.1297 - val_accuracy: 0.9603\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9804 - val_loss: 0.1153 - val_accuracy: 0.9653\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9838 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9862 - val_loss: 0.0980 - val_accuracy: 0.9694\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0960 - val_accuracy: 0.9710\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.0993 - val_accuracy: 0.9687\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.0968 - val_accuracy: 0.9709\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 0.0914 - val_accuracy: 0.9722\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.0911 - val_accuracy: 0.9727\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.0930 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0917 - val_accuracy: 0.9726\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.0933 - val_accuracy: 0.9723\n",
      "Epoch 22/25\n",
      "71/80 [=========================>....] - ETA: 0s - loss: 0.0086 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 17.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 0.9734\n",
      "Epoch 22: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.7227 - accuracy: 0.7985 - val_loss: 0.3091 - val_accuracy: 0.9103\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.9172 - val_loss: 0.2774 - val_accuracy: 0.9170\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9342 - val_loss: 0.2290 - val_accuracy: 0.9341\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9454 - val_loss: 0.1916 - val_accuracy: 0.9456\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9532 - val_loss: 0.1692 - val_accuracy: 0.9518\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9619 - val_loss: 0.1496 - val_accuracy: 0.9571\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9681 - val_loss: 0.1377 - val_accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9734 - val_loss: 0.1208 - val_accuracy: 0.9652\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9768 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9806 - val_loss: 0.1130 - val_accuracy: 0.9654\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9836 - val_loss: 0.1057 - val_accuracy: 0.9693\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.1034 - val_accuracy: 0.9689\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0978 - val_accuracy: 0.9707\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 0.0949 - val_accuracy: 0.9718\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.1021 - val_accuracy: 0.9694\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9938 - val_loss: 0.0929 - val_accuracy: 0.9718\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 0.0939 - val_accuracy: 0.9718\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 0.0895 - val_accuracy: 0.9737\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0906 - val_accuracy: 0.9736\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0877 - val_accuracy: 0.9737\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0921 - val_accuracy: 0.9732\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0901 - val_accuracy: 0.9747\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0918 - val_accuracy: 0.9753\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0908 - val_accuracy: 0.9749\n",
      "Epoch 25/25\n",
      "73/80 [==========================>...] - ETA: 0s - loss: 0.0052 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0956 - val_accuracy: 0.9739\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.6976 - accuracy: 0.8026 - val_loss: 0.3067 - val_accuracy: 0.9095\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.9181 - val_loss: 0.2627 - val_accuracy: 0.9226\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9347 - val_loss: 0.2160 - val_accuracy: 0.9405\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9467 - val_loss: 0.1979 - val_accuracy: 0.9423\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9544 - val_loss: 0.1669 - val_accuracy: 0.9520\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9622 - val_loss: 0.1431 - val_accuracy: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.1388 - val_accuracy: 0.9578\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9747 - val_loss: 0.1242 - val_accuracy: 0.9634\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9780 - val_loss: 0.1151 - val_accuracy: 0.9657\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9824 - val_loss: 0.1129 - val_accuracy: 0.9655\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9841 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9876 - val_loss: 0.0992 - val_accuracy: 0.9702\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.1020 - val_accuracy: 0.9691\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9910 - val_loss: 0.0974 - val_accuracy: 0.9699\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0946 - val_accuracy: 0.9721\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9944 - val_loss: 0.0932 - val_accuracy: 0.9715\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.0910 - val_accuracy: 0.9728\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.0907 - val_accuracy: 0.9729\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.0901 - val_accuracy: 0.9741\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.0885 - val_accuracy: 0.9735\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.0898 - val_accuracy: 0.9742\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0917 - val_accuracy: 0.9741\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0910 - val_accuracy: 0.9751\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0921 - val_accuracy: 0.9752\n",
      "Epoch 25/25\n",
      "77/80 [===========================>..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0921 - val_accuracy: 0.9743\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.8343 - accuracy: 0.7897 - val_loss: 0.3002 - val_accuracy: 0.9108\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9230 - val_loss: 0.2326 - val_accuracy: 0.9315\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9415 - val_loss: 0.1938 - val_accuracy: 0.9452\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9549 - val_loss: 0.1570 - val_accuracy: 0.9559\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9628 - val_loss: 0.1403 - val_accuracy: 0.9583\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9703 - val_loss: 0.1264 - val_accuracy: 0.9630\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 0.1161 - val_accuracy: 0.9660\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.1047 - val_accuracy: 0.9697\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9844 - val_loss: 0.1161 - val_accuracy: 0.9640\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.1000 - val_accuracy: 0.9694\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0964 - val_accuracy: 0.9700\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0911 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.0945 - val_accuracy: 0.9719\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0901 - val_accuracy: 0.9735\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.0879 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0868 - val_accuracy: 0.9750\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0877 - val_accuracy: 0.9758\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.0957 - val_accuracy: 0.9725\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0906 - val_accuracy: 0.9748\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0872 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "74/80 [==========================>...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0931 - val_accuracy: 0.9748\n",
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.8670 - accuracy: 0.7844 - val_loss: 0.2933 - val_accuracy: 0.9141\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.9252 - val_loss: 0.2373 - val_accuracy: 0.9308\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.1942 - val_accuracy: 0.9452\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9548 - val_loss: 0.1564 - val_accuracy: 0.9551\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9642 - val_loss: 0.1397 - val_accuracy: 0.9599\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9713 - val_loss: 0.1262 - val_accuracy: 0.9627\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9758 - val_loss: 0.1172 - val_accuracy: 0.9652\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9823 - val_loss: 0.1063 - val_accuracy: 0.9687\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9834 - val_loss: 0.1135 - val_accuracy: 0.9658\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.1060 - val_accuracy: 0.9682\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.1054 - val_accuracy: 0.9684\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.0924 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.0937 - val_accuracy: 0.9723\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.0976 - val_accuracy: 0.9719\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0923 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0920 - val_accuracy: 0.9753\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.0948 - val_accuracy: 0.9740\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0951 - val_accuracy: 0.9748\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0954 - val_accuracy: 0.9751\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.1013 - val_accuracy: 0.9733\n",
      "Epoch 22/25\n",
      "77/80 [===========================>..] - ETA: 0s - loss: 0.0044 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 17.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0986 - val_accuracy: 0.9747\n",
      "Epoch 22: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.8571 - accuracy: 0.7876 - val_loss: 0.2994 - val_accuracy: 0.9103\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9224 - val_loss: 0.2511 - val_accuracy: 0.9249\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9414 - val_loss: 0.2036 - val_accuracy: 0.9409\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9534 - val_loss: 0.1681 - val_accuracy: 0.9509\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9615 - val_loss: 0.1533 - val_accuracy: 0.9541\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9697 - val_loss: 0.1318 - val_accuracy: 0.9616\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9747 - val_loss: 0.1203 - val_accuracy: 0.9646\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.1078 - val_accuracy: 0.9682\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9828 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.1061 - val_accuracy: 0.9695\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.0992 - val_accuracy: 0.9714\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0994 - val_accuracy: 0.9708\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0937 - val_accuracy: 0.9727\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.1015 - val_accuracy: 0.9721\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.0918 - val_accuracy: 0.9733\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.0943 - val_accuracy: 0.9731\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.0929 - val_accuracy: 0.9744\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0930 - val_accuracy: 0.9732\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0907 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0931 - val_accuracy: 0.9753\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0949 - val_accuracy: 0.9749\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0944 - val_accuracy: 0.9753\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0963 - val_accuracy: 0.9753\n",
      "Epoch 25/25\n",
      "72/80 [==========================>...] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.1001 - val_accuracy: 0.9752\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.8196 - accuracy: 0.7900 - val_loss: 0.2959 - val_accuracy: 0.9133\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9245 - val_loss: 0.2386 - val_accuracy: 0.9312\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9425 - val_loss: 0.1944 - val_accuracy: 0.9444\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9544 - val_loss: 0.1757 - val_accuracy: 0.9489\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9622 - val_loss: 0.1450 - val_accuracy: 0.9574\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9708 - val_loss: 0.1271 - val_accuracy: 0.9624\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9764 - val_loss: 0.1231 - val_accuracy: 0.9632\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9812 - val_loss: 0.1107 - val_accuracy: 0.9679\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9839 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9875 - val_loss: 0.1046 - val_accuracy: 0.9692\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0975 - val_accuracy: 0.9705\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0981 - val_accuracy: 0.9711\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9923 - val_loss: 0.1007 - val_accuracy: 0.9687\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0961 - val_accuracy: 0.9714\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0997 - val_accuracy: 0.9718\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0929 - val_accuracy: 0.9729\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0932 - val_accuracy: 0.9725\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0962 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0953 - val_accuracy: 0.9752\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0948 - val_accuracy: 0.9742\n",
      "Epoch 21/25\n",
      "66/80 [=======================>......] - ETA: 0s - loss: 0.0052 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0955 - val_accuracy: 0.9746\n",
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 8ms/step - loss: 0.8343 - accuracy: 0.7897 - val_loss: 0.3002 - val_accuracy: 0.9108\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9230 - val_loss: 0.2326 - val_accuracy: 0.9315\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9415 - val_loss: 0.1938 - val_accuracy: 0.9452\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9549 - val_loss: 0.1570 - val_accuracy: 0.9559\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9628 - val_loss: 0.1403 - val_accuracy: 0.9583\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9703 - val_loss: 0.1264 - val_accuracy: 0.9630\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 0.1161 - val_accuracy: 0.9660\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.1047 - val_accuracy: 0.9697\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9844 - val_loss: 0.1161 - val_accuracy: 0.9640\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.1000 - val_accuracy: 0.9694\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.0964 - val_accuracy: 0.9700\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0911 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.0945 - val_accuracy: 0.9719\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0901 - val_accuracy: 0.9735\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.0879 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0868 - val_accuracy: 0.9750\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0877 - val_accuracy: 0.9758\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.0957 - val_accuracy: 0.9725\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0906 - val_accuracy: 0.9748\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0872 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "75/80 [===========================>..] - ETA: 0s - loss: 0.0044 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0931 - val_accuracy: 0.9748\n",
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.8670 - accuracy: 0.7844 - val_loss: 0.2933 - val_accuracy: 0.9141\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9252 - val_loss: 0.2373 - val_accuracy: 0.9308\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9434 - val_loss: 0.1942 - val_accuracy: 0.9452\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9548 - val_loss: 0.1564 - val_accuracy: 0.9551\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9642 - val_loss: 0.1397 - val_accuracy: 0.9599\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9713 - val_loss: 0.1262 - val_accuracy: 0.9627\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9758 - val_loss: 0.1172 - val_accuracy: 0.9652\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9823 - val_loss: 0.1063 - val_accuracy: 0.9687\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9834 - val_loss: 0.1135 - val_accuracy: 0.9658\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.1060 - val_accuracy: 0.9682\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.1054 - val_accuracy: 0.9684\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.0924 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.0937 - val_accuracy: 0.9723\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.0976 - val_accuracy: 0.9719\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0923 - val_accuracy: 0.9738\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.0920 - val_accuracy: 0.9753\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.0948 - val_accuracy: 0.9740\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.0951 - val_accuracy: 0.9748\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0954 - val_accuracy: 0.9751\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.1013 - val_accuracy: 0.9733\n",
      "Epoch 22/25\n",
      "67/80 [========================>.....] - ETA: 0s - loss: 0.0044 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 17.\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0986 - val_accuracy: 0.9747\n",
      "Epoch 22: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.8571 - accuracy: 0.7876 - val_loss: 0.2994 - val_accuracy: 0.9103\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2642 - accuracy: 0.9224 - val_loss: 0.2511 - val_accuracy: 0.9249\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9414 - val_loss: 0.2036 - val_accuracy: 0.9409\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9534 - val_loss: 0.1681 - val_accuracy: 0.9509\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9615 - val_loss: 0.1533 - val_accuracy: 0.9541\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9697 - val_loss: 0.1318 - val_accuracy: 0.9616\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9747 - val_loss: 0.1203 - val_accuracy: 0.9646\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.1078 - val_accuracy: 0.9682\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9828 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.1061 - val_accuracy: 0.9695\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.0992 - val_accuracy: 0.9714\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9910 - val_loss: 0.0994 - val_accuracy: 0.9708\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.0937 - val_accuracy: 0.9727\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.1015 - val_accuracy: 0.9721\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.0918 - val_accuracy: 0.9733\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.0943 - val_accuracy: 0.9731\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.0929 - val_accuracy: 0.9744\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0930 - val_accuracy: 0.9732\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0907 - val_accuracy: 0.9759\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0931 - val_accuracy: 0.9753\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0949 - val_accuracy: 0.9749\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0944 - val_accuracy: 0.9753\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0963 - val_accuracy: 0.9753\n",
      "Epoch 25/25\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 20.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.1001 - val_accuracy: 0.9752\n",
      "Epoch 25: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.8196 - accuracy: 0.7900 - val_loss: 0.2959 - val_accuracy: 0.9133\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9245 - val_loss: 0.2386 - val_accuracy: 0.9312\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9425 - val_loss: 0.1944 - val_accuracy: 0.9444\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9544 - val_loss: 0.1757 - val_accuracy: 0.9489\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9622 - val_loss: 0.1450 - val_accuracy: 0.9574\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9708 - val_loss: 0.1271 - val_accuracy: 0.9624\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9764 - val_loss: 0.1231 - val_accuracy: 0.9632\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9812 - val_loss: 0.1107 - val_accuracy: 0.9679\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9839 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9875 - val_loss: 0.1046 - val_accuracy: 0.9692\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9890 - val_loss: 0.0975 - val_accuracy: 0.9705\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0981 - val_accuracy: 0.9711\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9923 - val_loss: 0.1007 - val_accuracy: 0.9687\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0961 - val_accuracy: 0.9714\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0997 - val_accuracy: 0.9718\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0929 - val_accuracy: 0.9729\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0932 - val_accuracy: 0.9725\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0962 - val_accuracy: 0.9735\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0953 - val_accuracy: 0.9752\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0948 - val_accuracy: 0.9742\n",
      "Epoch 21/25\n",
      "74/80 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9995Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0955 - val_accuracy: 0.9746\n",
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.9444 - accuracy: 0.7858 - val_loss: 0.2923 - val_accuracy: 0.9140\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.9263 - val_loss: 0.2264 - val_accuracy: 0.9316\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9454 - val_loss: 0.1799 - val_accuracy: 0.9482\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9591 - val_loss: 0.1441 - val_accuracy: 0.9588\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9681 - val_loss: 0.1284 - val_accuracy: 0.9620\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9746 - val_loss: 0.1125 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9804 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.1018 - val_accuracy: 0.9683\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9878 - val_loss: 0.1151 - val_accuracy: 0.9651\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.1015 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0926 - val_accuracy: 0.9723\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0881 - val_accuracy: 0.9743\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.0916 - val_accuracy: 0.9740\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0895 - val_accuracy: 0.9745\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.0856 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0899 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0873 - val_accuracy: 0.9768\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.0999 - val_accuracy: 0.9741\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0906 - val_accuracy: 0.9770\n",
      "Epoch 20/25\n",
      "72/80 [==========================>...] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 15.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0874 - val_accuracy: 0.9768\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 1.0448 - accuracy: 0.7660 - val_loss: 0.2979 - val_accuracy: 0.9126\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9258 - val_loss: 0.2246 - val_accuracy: 0.9342\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9451 - val_loss: 0.1862 - val_accuracy: 0.9472\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9656 - val_loss: 0.1362 - val_accuracy: 0.9603\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9733 - val_loss: 0.1208 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9782 - val_loss: 0.1138 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 0.1018 - val_accuracy: 0.9696\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9863 - val_loss: 0.1100 - val_accuracy: 0.9682\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0995 - val_accuracy: 0.9708\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.0972 - val_accuracy: 0.9713\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 0.0913 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0967 - val_accuracy: 0.9724\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0953 - val_accuracy: 0.9736\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0996 - val_accuracy: 0.9737\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0930 - val_accuracy: 0.9743\n",
      "Epoch 17/25\n",
      "74/80 [==========================>...] - ETA: 0s - loss: 0.0068 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 12.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0944 - val_accuracy: 0.9755\n",
      "Epoch 17: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 1.0101 - accuracy: 0.7714 - val_loss: 0.2898 - val_accuracy: 0.9136\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9255 - val_loss: 0.2309 - val_accuracy: 0.9318\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.9458 - val_loss: 0.1828 - val_accuracy: 0.9481\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9583 - val_loss: 0.1578 - val_accuracy: 0.9553\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9647 - val_loss: 0.1372 - val_accuracy: 0.9605\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9736 - val_loss: 0.1177 - val_accuracy: 0.9653\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9785 - val_loss: 0.1117 - val_accuracy: 0.9667\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.1019 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.1039 - val_accuracy: 0.9690\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9893 - val_loss: 0.0979 - val_accuracy: 0.9712\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0928 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 0.0943 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.0948 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.0953 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "72/80 [==========================>...] - ETA: 0s - loss: 0.0082 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 11.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.0940 - val_accuracy: 0.9736\n",
      "Epoch 16: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.9929 - accuracy: 0.7719 - val_loss: 0.2971 - val_accuracy: 0.9139\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9258 - val_loss: 0.2268 - val_accuracy: 0.9335\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9451 - val_loss: 0.1847 - val_accuracy: 0.9457\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9581 - val_loss: 0.1654 - val_accuracy: 0.9510\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9656 - val_loss: 0.1336 - val_accuracy: 0.9610\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9738 - val_loss: 0.1190 - val_accuracy: 0.9644\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9787 - val_loss: 0.1147 - val_accuracy: 0.9655\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.1047 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.1002 - val_accuracy: 0.9703\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0956 - val_accuracy: 0.9721\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.0977 - val_accuracy: 0.9720\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0949 - val_accuracy: 0.9725\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.1007 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.1012 - val_accuracy: 0.9736\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0947 - val_accuracy: 0.9739\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0954 - val_accuracy: 0.9739\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0979 - val_accuracy: 0.9743\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0989 - val_accuracy: 0.9751\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1026 - val_accuracy: 0.9740\n",
      "Epoch 21/25\n",
      "72/80 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1006 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.9444 - accuracy: 0.7858 - val_loss: 0.2923 - val_accuracy: 0.9140\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9263 - val_loss: 0.2264 - val_accuracy: 0.9316\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9454 - val_loss: 0.1799 - val_accuracy: 0.9482\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.9591 - val_loss: 0.1441 - val_accuracy: 0.9588\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9681 - val_loss: 0.1284 - val_accuracy: 0.9620\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9746 - val_loss: 0.1125 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9804 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.1018 - val_accuracy: 0.9683\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9878 - val_loss: 0.1151 - val_accuracy: 0.9651\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.1015 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0926 - val_accuracy: 0.9723\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0881 - val_accuracy: 0.9743\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 0.0916 - val_accuracy: 0.9740\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0895 - val_accuracy: 0.9745\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.0856 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.0899 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0873 - val_accuracy: 0.9768\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.0999 - val_accuracy: 0.9741\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0906 - val_accuracy: 0.9770\n",
      "Epoch 20/25\n",
      "70/80 [=========================>....] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 15.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0874 - val_accuracy: 0.9768\n",
      "Epoch 20: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 1.0448 - accuracy: 0.7660 - val_loss: 0.2979 - val_accuracy: 0.9126\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9258 - val_loss: 0.2246 - val_accuracy: 0.9342\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9451 - val_loss: 0.1862 - val_accuracy: 0.9472\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9656 - val_loss: 0.1362 - val_accuracy: 0.9603\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9733 - val_loss: 0.1208 - val_accuracy: 0.9639\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9782 - val_loss: 0.1138 - val_accuracy: 0.9657\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 0.1018 - val_accuracy: 0.9696\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9863 - val_loss: 0.1100 - val_accuracy: 0.9682\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0995 - val_accuracy: 0.9708\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.0972 - val_accuracy: 0.9713\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 0.0913 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0967 - val_accuracy: 0.9724\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0953 - val_accuracy: 0.9736\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0996 - val_accuracy: 0.9737\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0930 - val_accuracy: 0.9743\n",
      "Epoch 17/25\n",
      "66/80 [=======================>......] - ETA: 0s - loss: 0.0066 - accuracy: 0.9994Restoring model weights from the end of the best epoch: 12.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0944 - val_accuracy: 0.9755\n",
      "Epoch 17: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 2s 10ms/step - loss: 1.0101 - accuracy: 0.7714 - val_loss: 0.2898 - val_accuracy: 0.9136\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2514 - accuracy: 0.9255 - val_loss: 0.2309 - val_accuracy: 0.9318\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.9458 - val_loss: 0.1828 - val_accuracy: 0.9481\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9583 - val_loss: 0.1578 - val_accuracy: 0.9553\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9647 - val_loss: 0.1372 - val_accuracy: 0.9605\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9736 - val_loss: 0.1177 - val_accuracy: 0.9653\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9785 - val_loss: 0.1117 - val_accuracy: 0.9667\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.1019 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.1039 - val_accuracy: 0.9690\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9893 - val_loss: 0.0979 - val_accuracy: 0.9712\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0928 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9944 - val_loss: 0.0943 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.0948 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.0953 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "66/80 [=======================>......] - ETA: 0s - loss: 0.0078 - accuracy: 0.9991Restoring model weights from the end of the best epoch: 11.\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.0940 - val_accuracy: 0.9736\n",
      "Epoch 16: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 8ms/step - loss: 0.9929 - accuracy: 0.7719 - val_loss: 0.2971 - val_accuracy: 0.9139\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2547 - accuracy: 0.9258 - val_loss: 0.2268 - val_accuracy: 0.9335\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9451 - val_loss: 0.1847 - val_accuracy: 0.9457\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9581 - val_loss: 0.1654 - val_accuracy: 0.9510\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9656 - val_loss: 0.1336 - val_accuracy: 0.9610\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9738 - val_loss: 0.1190 - val_accuracy: 0.9644\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9787 - val_loss: 0.1147 - val_accuracy: 0.9655\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.1047 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.1002 - val_accuracy: 0.9703\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0956 - val_accuracy: 0.9721\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.0977 - val_accuracy: 0.9720\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0949 - val_accuracy: 0.9725\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.1007 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.1012 - val_accuracy: 0.9736\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.0947 - val_accuracy: 0.9739\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0954 - val_accuracy: 0.9739\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0979 - val_accuracy: 0.9743\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0989 - val_accuracy: 0.9751\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1026 - val_accuracy: 0.9740\n",
      "Epoch 21/25\n",
      "71/80 [=========================>....] - ETA: 0s - loss: 0.0032 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 16.\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.1006 - val_accuracy: 0.9745\n",
      "Epoch 21: early stopping\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6742 - accuracy: 0.8272 - val_loss: 0.2613 - val_accuracy: 0.9248\n",
      "Epoch 2/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.9332 - val_loss: 0.2111 - val_accuracy: 0.9369\n",
      "Epoch 3/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9519 - val_loss: 0.1562 - val_accuracy: 0.9563\n",
      "Epoch 4/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9634 - val_loss: 0.1300 - val_accuracy: 0.9601\n",
      "Epoch 5/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9710 - val_loss: 0.1152 - val_accuracy: 0.9648\n",
      "Epoch 6/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9783 - val_loss: 0.1026 - val_accuracy: 0.9689\n",
      "Epoch 7/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9824 - val_loss: 0.0911 - val_accuracy: 0.9729\n",
      "Epoch 8/25\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9861 - val_loss: 0.0930 - val_accuracy: 0.9710\n",
      "Epoch 9/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9879 - val_loss: 0.0798 - val_accuracy: 0.9764\n",
      "Epoch 10/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9920 - val_loss: 0.0862 - val_accuracy: 0.9748\n",
      "Epoch 11/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0860 - val_accuracy: 0.9747\n",
      "Epoch 12/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.0797 - val_accuracy: 0.9773\n",
      "Epoch 13/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.0849 - val_accuracy: 0.9758\n",
      "Epoch 14/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 15/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.0761 - val_accuracy: 0.9797\n",
      "Epoch 16/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0822 - val_accuracy: 0.9787\n",
      "Epoch 17/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
      "Epoch 18/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0907 - val_accuracy: 0.9770\n",
      "Epoch 19/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0971 - val_accuracy: 0.9754\n",
      "Epoch 20/25\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.0061 - accuracy: 0.9985Restoring model weights from the end of the best epoch: 15.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0846 - val_accuracy: 0.9787\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    rmsprop_grid_result = rmsprop_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f79d15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.974313 using {'batch_size': 400, 'optimizer_learning_rate': 0.0015, 'optimizer_momentum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (rmsprop_grid_result.best_score_, rmsprop_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "33f874fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",rmsprop_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc5554",
   "metadata": {},
   "source": [
    "### Model Convergence: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545fa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 5,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "sgd_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=400,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.001,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='SGD',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=30,\n",
    ")\n",
    "sgd_param_grid = {\n",
    "    'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    'batch_size':[100,200,300]\n",
    "}\n",
    "sgd_grid = GridSearchCV(\n",
    "    estimator=sgd_estimator, \n",
    "    param_grid=sgd_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9bfb76b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4423 - accuracy: 0.8814 - val_loss: 0.2123 - val_accuracy: 0.9382\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9507 - val_loss: 0.1469 - val_accuracy: 0.9563\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9677 - val_loss: 0.1224 - val_accuracy: 0.9628\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9780 - val_loss: 0.1035 - val_accuracy: 0.9675\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.1000 - val_accuracy: 0.9701\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 0.0957 - val_accuracy: 0.9717\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0957 - val_accuracy: 0.9732\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1010 - val_accuracy: 0.9731\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.1016 - val_accuracy: 0.9747\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0988 - val_accuracy: 0.9743\n",
      "Epoch 11/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.1078 - val_accuracy: 0.9741\n",
      "Epoch 12/30\n",
      "357/360 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9959Restoring model weights from the end of the best epoch: 7.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1304 - val_accuracy: 0.9708\n",
      "Epoch 12: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4372 - accuracy: 0.8788 - val_loss: 0.2079 - val_accuracy: 0.9403\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9523 - val_loss: 0.1418 - val_accuracy: 0.9569\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9679 - val_loss: 0.1168 - val_accuracy: 0.9650\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9789 - val_loss: 0.1093 - val_accuracy: 0.9657\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.1007 - val_accuracy: 0.9703\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.1018 - val_accuracy: 0.9699\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0897 - val_accuracy: 0.9747\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0907 - val_accuracy: 0.9766\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0969 - val_accuracy: 0.9753\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.1168 - val_accuracy: 0.9711\n",
      "Epoch 11/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.1103 - val_accuracy: 0.9737\n",
      "Epoch 12/30\n",
      "354/360 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9938Restoring model weights from the end of the best epoch: 7.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.1205 - val_accuracy: 0.9738\n",
      "Epoch 12: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 4ms/step - loss: 0.4424 - accuracy: 0.8804 - val_loss: 0.2164 - val_accuracy: 0.9376\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9504 - val_loss: 0.1462 - val_accuracy: 0.9577\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9678 - val_loss: 0.1076 - val_accuracy: 0.9657\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9782 - val_loss: 0.0953 - val_accuracy: 0.9707\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0977 - val_accuracy: 0.9712\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0857 - val_accuracy: 0.9762\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0988 - val_accuracy: 0.9730\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.1019 - val_accuracy: 0.9732\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.1024 - val_accuracy: 0.9737\n",
      "Epoch 11/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.1119 - val_accuracy: 0.9746\n",
      "Epoch 12/30\n",
      "348/360 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 7.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1297 - val_accuracy: 0.9706\n",
      "Epoch 12: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 4ms/step - loss: 0.4348 - accuracy: 0.8837 - val_loss: 0.2363 - val_accuracy: 0.9258\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9515 - val_loss: 0.1403 - val_accuracy: 0.9586\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9696 - val_loss: 0.1098 - val_accuracy: 0.9669\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9795 - val_loss: 0.1042 - val_accuracy: 0.9681\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.1007 - val_accuracy: 0.9710\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.1181 - val_accuracy: 0.9631\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.1010 - val_accuracy: 0.9697\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.1156 - val_accuracy: 0.9693\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.1036 - val_accuracy: 0.9722\n",
      "Epoch 10/30\n",
      "347/360 [===========================>..] - ETA: 0s - loss: 0.0137 - accuracy: 0.9956Restoring model weights from the end of the best epoch: 5.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1067 - val_accuracy: 0.9737\n",
      "Epoch 10: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 4ms/step - loss: 0.4434 - accuracy: 0.8892 - val_loss: 0.1927 - val_accuracy: 0.9420\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9563 - val_loss: 0.1226 - val_accuracy: 0.9629\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9719 - val_loss: 0.1289 - val_accuracy: 0.9599\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9807 - val_loss: 0.1003 - val_accuracy: 0.9689\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9856 - val_loss: 0.1041 - val_accuracy: 0.9697\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.1114 - val_accuracy: 0.9684\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 0.0973 - val_accuracy: 0.9731\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.1228 - val_accuracy: 0.9695\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.1076 - val_accuracy: 0.9747\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1377 - val_accuracy: 0.9678\n",
      "Epoch 11/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.1378 - val_accuracy: 0.9685\n",
      "Epoch 12/30\n",
      "354/360 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9943Restoring model weights from the end of the best epoch: 7.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1335 - val_accuracy: 0.9739\n",
      "Epoch 12: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 4ms/step - loss: 0.4580 - accuracy: 0.8853 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9567 - val_loss: 0.1242 - val_accuracy: 0.9611\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9716 - val_loss: 0.1073 - val_accuracy: 0.9673\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9797 - val_loss: 0.1002 - val_accuracy: 0.9693\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0943 - val_accuracy: 0.9713\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0929 - val_accuracy: 0.9753\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0963 - val_accuracy: 0.9781\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.0935 - val_accuracy: 0.9761\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.1241 - val_accuracy: 0.9709\n",
      "Epoch 11/30\n",
      "355/360 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9915Restoring model weights from the end of the best epoch: 6.\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.1019 - val_accuracy: 0.9761\n",
      "Epoch 11: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4632 - accuracy: 0.8858 - val_loss: 0.1867 - val_accuracy: 0.9461\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9556 - val_loss: 0.1231 - val_accuracy: 0.9626\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9712 - val_loss: 0.1021 - val_accuracy: 0.9692\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9799 - val_loss: 0.0955 - val_accuracy: 0.9716\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.1011 - val_accuracy: 0.9707\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0974 - val_accuracy: 0.9731\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.1022 - val_accuracy: 0.9718\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1014 - val_accuracy: 0.9732\n",
      "Epoch 9/30\n",
      "358/360 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 4.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.1049 - val_accuracy: 0.9753\n",
      "Epoch 9: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4481 - accuracy: 0.8905 - val_loss: 0.1995 - val_accuracy: 0.9394\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.9570 - val_loss: 0.1363 - val_accuracy: 0.9585\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9729 - val_loss: 0.1029 - val_accuracy: 0.9681\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.1033 - val_accuracy: 0.9696\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.0988 - val_accuracy: 0.9727\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.1065 - val_accuracy: 0.9703\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.1247 - val_accuracy: 0.9640\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.0920 - val_accuracy: 0.9749\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.1375 - val_accuracy: 0.9656\n",
      "Epoch 10/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.1294 - val_accuracy: 0.9700\n",
      "Epoch 11/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.1379 - val_accuracy: 0.9697\n",
      "Epoch 12/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.1088 - val_accuracy: 0.9760\n",
      "Epoch 13/30\n",
      "355/360 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9939Restoring model weights from the end of the best epoch: 8.\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.1454 - val_accuracy: 0.9676\n",
      "Epoch 13: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.8891 - val_loss: 0.1833 - val_accuracy: 0.9457\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9591 - val_loss: 0.1228 - val_accuracy: 0.9622\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9741 - val_loss: 0.1183 - val_accuracy: 0.9643\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 0.0935 - val_accuracy: 0.9722\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.1072 - val_accuracy: 0.9700\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 0.1067 - val_accuracy: 0.9692\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0995 - val_accuracy: 0.9747\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.1086 - val_accuracy: 0.9732\n",
      "Epoch 9/30\n",
      "353/360 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9908Restoring model weights from the end of the best epoch: 4.\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0997 - val_accuracy: 0.9745\n",
      "Epoch 9: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4756 - accuracy: 0.8885 - val_loss: 0.1692 - val_accuracy: 0.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.1284 - accuracy: 0.9613 - val_loss: 0.1130 - val_accuracy: 0.9648\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9736 - val_loss: 0.1073 - val_accuracy: 0.9677\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.1101 - val_accuracy: 0.9653\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9860 - val_loss: 0.1022 - val_accuracy: 0.9707\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 0.1025 - val_accuracy: 0.9704\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.1124 - val_accuracy: 0.9702\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.1203 - val_accuracy: 0.9712\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.1087 - val_accuracy: 0.9734\n",
      "Epoch 10/30\n",
      "344/360 [===========================>..] - ETA: 0s - loss: 0.0195 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 5.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.1101 - val_accuracy: 0.9739\n",
      "Epoch 10: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 5ms/step - loss: 0.4822 - accuracy: 0.8887 - val_loss: 0.1670 - val_accuracy: 0.9513\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1343 - accuracy: 0.9586 - val_loss: 0.1163 - val_accuracy: 0.9641\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.9737 - val_loss: 0.1019 - val_accuracy: 0.9674\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9804 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.1098 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9889 - val_loss: 0.1108 - val_accuracy: 0.9700\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 0.1006 - val_accuracy: 0.9740\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.1050 - val_accuracy: 0.9745\n",
      "Epoch 9/30\n",
      "349/360 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9913Restoring model weights from the end of the best epoch: 4.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.1086 - val_accuracy: 0.9736\n",
      "Epoch 9: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8911 - val_loss: 0.1734 - val_accuracy: 0.9467\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.1320 - accuracy: 0.9588 - val_loss: 0.1293 - val_accuracy: 0.9599\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9745 - val_loss: 0.1113 - val_accuracy: 0.9654\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.1102 - val_accuracy: 0.9684\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 0.0946 - val_accuracy: 0.9738\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.1420 - val_accuracy: 0.9633\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9898 - val_loss: 0.1092 - val_accuracy: 0.9728\n",
      "Epoch 8/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.1092 - val_accuracy: 0.9707\n",
      "Epoch 9/30\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.1115 - val_accuracy: 0.9722\n",
      "Epoch 10/30\n",
      "349/360 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9921Restoring model weights from the end of the best epoch: 5.\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.1246 - val_accuracy: 0.9717\n",
      "Epoch 10: early stopping\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6274 - accuracy: 0.8427 - val_loss: 0.2647 - val_accuracy: 0.9203\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9365 - val_loss: 0.2086 - val_accuracy: 0.9382\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9559 - val_loss: 0.1540 - val_accuracy: 0.9557\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9666 - val_loss: 0.1369 - val_accuracy: 0.9585\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9754 - val_loss: 0.1259 - val_accuracy: 0.9625\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9814 - val_loss: 0.1026 - val_accuracy: 0.9685\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.9868 - val_loss: 0.0904 - val_accuracy: 0.9728\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9891 - val_loss: 0.0934 - val_accuracy: 0.9718\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.0869 - val_accuracy: 0.9740\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9943 - val_loss: 0.0905 - val_accuracy: 0.9740\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9751\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0910 - val_accuracy: 0.9764\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0946 - val_accuracy: 0.9741\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0896 - val_accuracy: 0.9771\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0912 - val_accuracy: 0.9780\n",
      "Epoch 16/30\n",
      "170/180 [===========================>..] - ETA: 0s - loss: 0.0030 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 11.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1012 - val_accuracy: 0.9749\n",
      "Epoch 16: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.8563 - val_loss: 0.2489 - val_accuracy: 0.9280\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2053 - accuracy: 0.9390 - val_loss: 0.1806 - val_accuracy: 0.9477\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9578 - val_loss: 0.1537 - val_accuracy: 0.9550\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1039 - accuracy: 0.9694 - val_loss: 0.1214 - val_accuracy: 0.9617\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0760 - accuracy: 0.9779 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.1073 - val_accuracy: 0.9689\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0918 - val_accuracy: 0.9725\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0949 - val_accuracy: 0.9709\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.0832 - val_accuracy: 0.9747\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.0923 - val_accuracy: 0.9736\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0939 - val_accuracy: 0.9740\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0993 - val_accuracy: 0.9732\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0919 - val_accuracy: 0.9765\n",
      "Epoch 14/30\n",
      "172/180 [===========================>..] - ETA: 0s - loss: 0.0056 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.5899 - accuracy: 0.8486 - val_loss: 0.2564 - val_accuracy: 0.9270\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2164 - accuracy: 0.9376 - val_loss: 0.1884 - val_accuracy: 0.9448\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1513 - accuracy: 0.9558 - val_loss: 0.1515 - val_accuracy: 0.9564\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1108 - accuracy: 0.9669 - val_loss: 0.1200 - val_accuracy: 0.9652\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 0.1242 - val_accuracy: 0.9623\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9801 - val_loss: 0.1126 - val_accuracy: 0.9683\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.0964 - val_accuracy: 0.9711\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0935 - val_accuracy: 0.9728\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0966 - val_accuracy: 0.9717\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0900 - val_accuracy: 0.9753\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0912 - val_accuracy: 0.9752\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0937 - val_accuracy: 0.9748\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0932 - val_accuracy: 0.9751\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0946 - val_accuracy: 0.9758\n",
      "Epoch 15/30\n",
      "170/180 [===========================>..] - ETA: 0s - loss: 0.0053 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 10.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1102 - val_accuracy: 0.9709\n",
      "Epoch 15: early stopping\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.8503 - val_loss: 0.2484 - val_accuracy: 0.9298\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2139 - accuracy: 0.9387 - val_loss: 0.1841 - val_accuracy: 0.9458\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9570 - val_loss: 0.1422 - val_accuracy: 0.9594\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1096 - accuracy: 0.9689 - val_loss: 0.1264 - val_accuracy: 0.9628\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9754 - val_loss: 0.1189 - val_accuracy: 0.9652\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9809 - val_loss: 0.1113 - val_accuracy: 0.9678\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9858 - val_loss: 0.0966 - val_accuracy: 0.9702\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 0.0931 - val_accuracy: 0.9732\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 0.0895 - val_accuracy: 0.9736\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1014 - val_accuracy: 0.9719\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0991 - val_accuracy: 0.9730\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.0966 - val_accuracy: 0.9737\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0916 - val_accuracy: 0.9756\n",
      "Epoch 14/30\n",
      "167/180 [==========================>...] - ETA: 0s - loss: 0.0103 - accuracy: 0.9969Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1035 - val_accuracy: 0.9743\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6561 - accuracy: 0.8528 - val_loss: 0.2387 - val_accuracy: 0.9287\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9450 - val_loss: 0.1804 - val_accuracy: 0.9463\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1234 - accuracy: 0.9634 - val_loss: 0.1431 - val_accuracy: 0.9565\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9735 - val_loss: 0.1120 - val_accuracy: 0.9654\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.1054 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9901 - val_loss: 0.0922 - val_accuracy: 0.9728\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0918 - val_accuracy: 0.9730\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0905 - val_accuracy: 0.9742\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.0966 - val_accuracy: 0.9753\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0900 - val_accuracy: 0.9758\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0886 - val_accuracy: 0.9777\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0926 - val_accuracy: 0.9758\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.1150 - val_accuracy: 0.9728\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.1376 - val_accuracy: 0.9673\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.1254 - val_accuracy: 0.9691\n",
      "Epoch 17/30\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9935Restoring model weights from the end of the best epoch: 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.1136 - val_accuracy: 0.9760\n",
      "Epoch 17: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6530 - accuracy: 0.8511 - val_loss: 0.2372 - val_accuracy: 0.9312\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1895 - accuracy: 0.9441 - val_loss: 0.1625 - val_accuracy: 0.9526\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9621 - val_loss: 0.1426 - val_accuracy: 0.9580\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9726 - val_loss: 0.1094 - val_accuracy: 0.9672\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9807 - val_loss: 0.1116 - val_accuracy: 0.9660\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.0996 - val_accuracy: 0.9713\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9904 - val_loss: 0.0894 - val_accuracy: 0.9737\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0954 - val_accuracy: 0.9723\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0949 - val_accuracy: 0.9739\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.1003 - val_accuracy: 0.9723\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0963 - val_accuracy: 0.9748\n",
      "Epoch 12/30\n",
      "164/180 [==========================>...] - ETA: 0s - loss: 0.0118 - accuracy: 0.9965Restoring model weights from the end of the best epoch: 7.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0976 - val_accuracy: 0.9751\n",
      "Epoch 12: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6549 - accuracy: 0.8492 - val_loss: 0.2356 - val_accuracy: 0.9328\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1906 - accuracy: 0.9455 - val_loss: 0.1609 - val_accuracy: 0.9532\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1292 - accuracy: 0.9616 - val_loss: 0.1249 - val_accuracy: 0.9624\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 0.1174 - val_accuracy: 0.9629\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.1030 - val_accuracy: 0.9700\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0954 - val_accuracy: 0.9713\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.0970 - val_accuracy: 0.9727\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0879 - val_accuracy: 0.9751\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.1014 - val_accuracy: 0.9734\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0984 - val_accuracy: 0.9747\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.1039 - val_accuracy: 0.9735\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.1020 - val_accuracy: 0.9748\n",
      "Epoch 14/30\n",
      "164/180 [==========================>...] - ETA: 0s - loss: 0.0162 - accuracy: 0.9945Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1033 - val_accuracy: 0.9753\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6574 - accuracy: 0.8476 - val_loss: 0.2275 - val_accuracy: 0.9365\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9456 - val_loss: 0.1611 - val_accuracy: 0.9532\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9641 - val_loss: 0.1269 - val_accuracy: 0.9625\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9739 - val_loss: 0.1129 - val_accuracy: 0.9661\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9804 - val_loss: 0.1061 - val_accuracy: 0.9682\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.1063 - val_accuracy: 0.9693\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0961 - val_accuracy: 0.9703\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0923 - val_accuracy: 0.9738\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0881 - val_accuracy: 0.9747\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0973 - val_accuracy: 0.9741\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.1091 - val_accuracy: 0.9723\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0992 - val_accuracy: 0.9749\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1400 - val_accuracy: 0.9675\n",
      "Epoch 14/30\n",
      "164/180 [==========================>...] - ETA: 0s - loss: 0.0138 - accuracy: 0.9955Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.1222 - val_accuracy: 0.9732\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7205 - accuracy: 0.8516 - val_loss: 0.2252 - val_accuracy: 0.9358\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1765 - accuracy: 0.9484 - val_loss: 0.1635 - val_accuracy: 0.9507\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9665 - val_loss: 0.1310 - val_accuracy: 0.9597\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9764 - val_loss: 0.1059 - val_accuracy: 0.9681\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.1026 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0934 - val_accuracy: 0.9720\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.0926 - val_accuracy: 0.9721\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0894 - val_accuracy: 0.9746\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0942 - val_accuracy: 0.9737\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.1096 - val_accuracy: 0.9716\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.1144 - val_accuracy: 0.9689\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1165 - val_accuracy: 0.9732\n",
      "Epoch 13/30\n",
      "167/180 [==========================>...] - ETA: 0s - loss: 0.0117 - accuracy: 0.9963Restoring model weights from the end of the best epoch: 8.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.1273 - val_accuracy: 0.9712\n",
      "Epoch 13: early stopping\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7427 - accuracy: 0.8423 - val_loss: 0.2264 - val_accuracy: 0.9345\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9480 - val_loss: 0.1551 - val_accuracy: 0.9543\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1144 - accuracy: 0.9655 - val_loss: 0.1233 - val_accuracy: 0.9624\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9761 - val_loss: 0.1094 - val_accuracy: 0.9673\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 0.1053 - val_accuracy: 0.9691\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.1086 - val_accuracy: 0.9680\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0912 - val_accuracy: 0.9737\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0975 - val_accuracy: 0.9732\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0995 - val_accuracy: 0.9738\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0980 - val_accuracy: 0.9743\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1009 - val_accuracy: 0.9748\n",
      "Epoch 12/30\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9943Restoring model weights from the end of the best epoch: 7.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.1185 - val_accuracy: 0.9715\n",
      "Epoch 12: early stopping\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7204 - accuracy: 0.8492 - val_loss: 0.2130 - val_accuracy: 0.9406\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.9511 - val_loss: 0.1394 - val_accuracy: 0.9604\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9668 - val_loss: 0.1140 - val_accuracy: 0.9657\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9776 - val_loss: 0.1045 - val_accuracy: 0.9682\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9848 - val_loss: 0.1096 - val_accuracy: 0.9669\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.1045 - val_accuracy: 0.9695\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.0979 - val_accuracy: 0.9710\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0960 - val_accuracy: 0.9743\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0903 - val_accuracy: 0.9751\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1108 - val_accuracy: 0.9741\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1064 - val_accuracy: 0.9746\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1202 - val_accuracy: 0.9720\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.1664 - val_accuracy: 0.9631\n",
      "Epoch 14/30\n",
      "175/180 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9898Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9897 - val_loss: 0.1115 - val_accuracy: 0.9745\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7230 - accuracy: 0.8480 - val_loss: 0.2088 - val_accuracy: 0.9408\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9500 - val_loss: 0.1423 - val_accuracy: 0.9582\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9688 - val_loss: 0.1242 - val_accuracy: 0.9617\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9782 - val_loss: 0.1048 - val_accuracy: 0.9674\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.1101 - val_accuracy: 0.9679\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.1106 - val_accuracy: 0.9672\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.0954 - val_accuracy: 0.9728\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0954 - val_accuracy: 0.9743\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0905 - val_accuracy: 0.9753\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0995 - val_accuracy: 0.9742\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1394 - val_accuracy: 0.9668\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.1192 - val_accuracy: 0.9713\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.1350 - val_accuracy: 0.9668\n",
      "Epoch 14/30\n",
      "164/180 [==========================>...] - ETA: 0s - loss: 0.0160 - accuracy: 0.9942Restoring model weights from the end of the best epoch: 9.\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.1198 - val_accuracy: 0.9731\n",
      "Epoch 14: early stopping\n",
      "60/60 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.7410 - accuracy: 0.8233 - val_loss: 0.2797 - val_accuracy: 0.9202\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9281 - val_loss: 0.2193 - val_accuracy: 0.9366\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.9469 - val_loss: 0.1837 - val_accuracy: 0.9485\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9593 - val_loss: 0.1486 - val_accuracy: 0.9572\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9692 - val_loss: 0.1434 - val_accuracy: 0.9574\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9743 - val_loss: 0.1136 - val_accuracy: 0.9665\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9793 - val_loss: 0.1071 - val_accuracy: 0.9677\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9829 - val_loss: 0.1016 - val_accuracy: 0.9687\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.1014 - val_accuracy: 0.9703\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.0922 - val_accuracy: 0.9715\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0935 - val_accuracy: 0.9714\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.0880 - val_accuracy: 0.9755\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.0907 - val_accuracy: 0.9728\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.0902 - val_accuracy: 0.9737\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0888 - val_accuracy: 0.9758\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0881 - val_accuracy: 0.9763\n",
      "Epoch 17/30\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.0070 - accuracy: 0.9989Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0882 - val_accuracy: 0.9772\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6959 - accuracy: 0.8277 - val_loss: 0.2871 - val_accuracy: 0.9172\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9303 - val_loss: 0.2190 - val_accuracy: 0.9369\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9468 - val_loss: 0.1735 - val_accuracy: 0.9506\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9598 - val_loss: 0.1448 - val_accuracy: 0.9571\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9687 - val_loss: 0.1404 - val_accuracy: 0.9583\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9755 - val_loss: 0.1224 - val_accuracy: 0.9633\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9801 - val_loss: 0.1076 - val_accuracy: 0.9674\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9840 - val_loss: 0.0999 - val_accuracy: 0.9704\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.1037 - val_accuracy: 0.9682\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0946 - val_accuracy: 0.9717\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9928 - val_loss: 0.0919 - val_accuracy: 0.9734\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0872 - val_accuracy: 0.9745\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.0910 - val_accuracy: 0.9753\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.0929 - val_accuracy: 0.9755\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0921 - val_accuracy: 0.9760\n",
      "Epoch 17/30\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.0057 - accuracy: 0.9992Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0932 - val_accuracy: 0.9770\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7137 - accuracy: 0.8250 - val_loss: 0.2844 - val_accuracy: 0.9168\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.9301 - val_loss: 0.2132 - val_accuracy: 0.9391\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9474 - val_loss: 0.1804 - val_accuracy: 0.9467\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9595 - val_loss: 0.1466 - val_accuracy: 0.9579\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9678 - val_loss: 0.1334 - val_accuracy: 0.9595\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9725 - val_loss: 0.1220 - val_accuracy: 0.9646\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.1102 - val_accuracy: 0.9674\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9841 - val_loss: 0.1054 - val_accuracy: 0.9693\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9878 - val_loss: 0.1023 - val_accuracy: 0.9695\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9897 - val_loss: 0.0948 - val_accuracy: 0.9716\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9920 - val_loss: 0.0918 - val_accuracy: 0.9732\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0997 - val_accuracy: 0.9714\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961 - val_loss: 0.0903 - val_accuracy: 0.9746\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0885 - val_accuracy: 0.9747\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0950 - val_accuracy: 0.9739\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.0882 - val_accuracy: 0.9758\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0883 - val_accuracy: 0.9759\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0876 - val_accuracy: 0.9768\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0902 - val_accuracy: 0.9767\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0887 - val_accuracy: 0.9771\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0907 - val_accuracy: 0.9775\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0901 - val_accuracy: 0.9774\n",
      "Epoch 23/30\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 18.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9779\n",
      "Epoch 23: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.6888 - accuracy: 0.8313 - val_loss: 0.2771 - val_accuracy: 0.9216\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9309 - val_loss: 0.2141 - val_accuracy: 0.9377\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9486 - val_loss: 0.1774 - val_accuracy: 0.9492\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9611 - val_loss: 0.1494 - val_accuracy: 0.9553\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9686 - val_loss: 0.1301 - val_accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9746 - val_loss: 0.1171 - val_accuracy: 0.9656\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9794 - val_loss: 0.1032 - val_accuracy: 0.9689\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9850 - val_loss: 0.1011 - val_accuracy: 0.9705\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.0972 - val_accuracy: 0.9694\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.0947 - val_accuracy: 0.9719\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0954 - val_accuracy: 0.9722\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.0913 - val_accuracy: 0.9735\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.0935 - val_accuracy: 0.9725\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.0955 - val_accuracy: 0.9725\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0963 - val_accuracy: 0.9729\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0962 - val_accuracy: 0.9734\n",
      "Epoch 17/30\n",
      "106/120 [=========================>....] - ETA: 0s - loss: 0.0082 - accuracy: 0.9983Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0920 - val_accuracy: 0.9758\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8613 - accuracy: 0.8159 - val_loss: 0.2656 - val_accuracy: 0.9220\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9343 - val_loss: 0.1937 - val_accuracy: 0.9447\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9542 - val_loss: 0.1598 - val_accuracy: 0.9545\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9658 - val_loss: 0.1365 - val_accuracy: 0.9582\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9744 - val_loss: 0.1210 - val_accuracy: 0.9630\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9808 - val_loss: 0.1035 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9862 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9882 - val_loss: 0.0888 - val_accuracy: 0.9735\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.0966 - val_accuracy: 0.9719\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.0872 - val_accuracy: 0.9743\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0918 - val_accuracy: 0.9738\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.0856 - val_accuracy: 0.9768\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0997 - val_accuracy: 0.9721\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0885 - val_accuracy: 0.9769\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0916 - val_accuracy: 0.9779\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
      "Epoch 17/30\n",
      "105/120 [=========================>....] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0914 - val_accuracy: 0.9783\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8311 - accuracy: 0.8200 - val_loss: 0.2733 - val_accuracy: 0.9204\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9376 - val_loss: 0.1903 - val_accuracy: 0.9456\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9550 - val_loss: 0.1496 - val_accuracy: 0.9567\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9669 - val_loss: 0.1233 - val_accuracy: 0.9627\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9749 - val_loss: 0.1124 - val_accuracy: 0.9657\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9816 - val_loss: 0.1071 - val_accuracy: 0.9672\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9858 - val_loss: 0.0955 - val_accuracy: 0.9702\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 0.0942 - val_accuracy: 0.9718\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.0936 - val_accuracy: 0.9721\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0909 - val_accuracy: 0.9737\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0902 - val_accuracy: 0.9749\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.0937 - val_accuracy: 0.9743\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0901 - val_accuracy: 0.9765\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0885 - val_accuracy: 0.9776\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0906 - val_accuracy: 0.9773\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.1008 - val_accuracy: 0.9748\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9793\n",
      "Epoch 19/30\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 14.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0935 - val_accuracy: 0.9793\n",
      "Epoch 19: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.8310 - accuracy: 0.8217 - val_loss: 0.2706 - val_accuracy: 0.9213\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2235 - accuracy: 0.9357 - val_loss: 0.1952 - val_accuracy: 0.9448\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9540 - val_loss: 0.1631 - val_accuracy: 0.9538\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9663 - val_loss: 0.1325 - val_accuracy: 0.9609\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9735 - val_loss: 0.1201 - val_accuracy: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9785 - val_loss: 0.1079 - val_accuracy: 0.9674\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9842 - val_loss: 0.0982 - val_accuracy: 0.9698\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.1012 - val_accuracy: 0.9698\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.0898 - val_accuracy: 0.9719\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.0939 - val_accuracy: 0.9727\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0845 - val_accuracy: 0.9760\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0892 - val_accuracy: 0.9743\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0944 - val_accuracy: 0.9744\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0930 - val_accuracy: 0.9758\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0920 - val_accuracy: 0.9768\n",
      "Epoch 16/30\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 11.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0892 - val_accuracy: 0.9770\n",
      "Epoch 16: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 2s 10ms/step - loss: 0.7911 - accuracy: 0.8278 - val_loss: 0.2615 - val_accuracy: 0.9261\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.9367 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9562 - val_loss: 0.1551 - val_accuracy: 0.9567\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9679 - val_loss: 0.1340 - val_accuracy: 0.9592\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9752 - val_loss: 0.1113 - val_accuracy: 0.9674\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9793 - val_loss: 0.1018 - val_accuracy: 0.9701\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0881 - val_accuracy: 0.9727\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.0917 - val_accuracy: 0.9736\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.0936 - val_accuracy: 0.9743\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0893 - val_accuracy: 0.9762\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0896 - val_accuracy: 0.9758\n",
      "Epoch 14/30\n",
      "113/120 [===========================>..] - ETA: 0s - loss: 0.0056 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 9.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.0946 - val_accuracy: 0.9748\n",
      "Epoch 14: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9942 - accuracy: 0.8112 - val_loss: 0.2577 - val_accuracy: 0.9250\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.9385 - val_loss: 0.1811 - val_accuracy: 0.9467\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9581 - val_loss: 0.1498 - val_accuracy: 0.9580\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9693 - val_loss: 0.1259 - val_accuracy: 0.9628\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9779 - val_loss: 0.1114 - val_accuracy: 0.9653\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9842 - val_loss: 0.0973 - val_accuracy: 0.9705\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0955 - val_accuracy: 0.9714\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: 0.0896 - val_accuracy: 0.9745\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0893 - val_accuracy: 0.9751\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.0894 - val_accuracy: 0.9758\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0856 - val_accuracy: 0.9776\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0865 - val_accuracy: 0.9772\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0918 - val_accuracy: 0.9770\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0955 - val_accuracy: 0.9769\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0939 - val_accuracy: 0.9776\n",
      "Epoch 17/30\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999Restoring model weights from the end of the best epoch: 12.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0931 - val_accuracy: 0.9779\n",
      "Epoch 17: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9681 - accuracy: 0.8135 - val_loss: 0.2556 - val_accuracy: 0.9255\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9384 - val_loss: 0.1837 - val_accuracy: 0.9472\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9569 - val_loss: 0.1521 - val_accuracy: 0.9568\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9696 - val_loss: 0.1198 - val_accuracy: 0.9650\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9780 - val_loss: 0.1107 - val_accuracy: 0.9652\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.1065 - val_accuracy: 0.9695\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0924 - val_accuracy: 0.9710\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 0.0964 - val_accuracy: 0.9720\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.0942 - val_accuracy: 0.9714\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0986 - val_accuracy: 0.9728\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.0932 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 7.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0939 - val_accuracy: 0.9762\n",
      "Epoch 12: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.9382 - accuracy: 0.8207 - val_loss: 0.2543 - val_accuracy: 0.9249\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9407 - val_loss: 0.1728 - val_accuracy: 0.9500\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9604 - val_loss: 0.1423 - val_accuracy: 0.9577\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9730 - val_loss: 0.1193 - val_accuracy: 0.9638\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9793 - val_loss: 0.1055 - val_accuracy: 0.9686\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9837 - val_loss: 0.1058 - val_accuracy: 0.9682\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.0930 - val_accuracy: 0.9717\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0988 - val_accuracy: 0.9703\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.0877 - val_accuracy: 0.9737\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0946 - val_accuracy: 0.9733\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0900 - val_accuracy: 0.9754\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0920 - val_accuracy: 0.9751\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0944 - val_accuracy: 0.9752\n",
      "Epoch 14/30\n",
      "115/120 [===========================>..] - ETA: 0s - loss: 0.0046 - accuracy: 0.9993Restoring model weights from the end of the best epoch: 9.\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0890 - val_accuracy: 0.9770\n",
      "Epoch 14: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9369 - accuracy: 0.8179 - val_loss: 0.2510 - val_accuracy: 0.9268\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.9399 - val_loss: 0.1769 - val_accuracy: 0.9492\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9589 - val_loss: 0.1443 - val_accuracy: 0.9576\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9709 - val_loss: 0.1227 - val_accuracy: 0.9629\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9781 - val_loss: 0.1069 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9819 - val_loss: 0.1013 - val_accuracy: 0.9692\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0942 - val_accuracy: 0.9712\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 0.0951 - val_accuracy: 0.9711\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0866 - val_accuracy: 0.9739\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.0922 - val_accuracy: 0.9741\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0939 - val_accuracy: 0.9733\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0882 - val_accuracy: 0.9758\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0907 - val_accuracy: 0.9760\n",
      "Epoch 14/30\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.0044 - accuracy: 0.9996Restoring model weights from the end of the best epoch: 9.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0950 - val_accuracy: 0.9743\n",
      "Epoch 14: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.5309 - accuracy: 0.8718 - val_loss: 0.2073 - val_accuracy: 0.9385\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9517 - val_loss: 0.1432 - val_accuracy: 0.9564\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.1045 - val_accuracy: 0.9680\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 0.0894 - val_accuracy: 0.9718\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.0848 - val_accuracy: 0.9731\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0807 - val_accuracy: 0.9762\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0878 - val_accuracy: 0.9744\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0854 - val_accuracy: 0.9751\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0844 - val_accuracy: 0.9764\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0845 - val_accuracy: 0.9793\n",
      "Epoch 11/30\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 6.\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.1054 - val_accuracy: 0.9739\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    sgd_grid_result = sgd_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "950cf75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.974250 using {'batch_size': 200, 'optimizer_learning_rate': 0.0015}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (sgd_grid_result.best_score_, sgd_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078b35e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",sgd_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf9674",
   "metadata": {},
   "source": [
    "### Models convergence results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c06359b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam</th>\n",
       "      <th>rmsprop</th>\n",
       "      <th>sgd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.973729</td>\n",
       "      <td>0.974313</td>\n",
       "      <td>0.9745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>375.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_learning_rate</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop epoch</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_momentum</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               adam     rmsprop       sgd\n",
       "score                      0.973729    0.974313    0.9745\n",
       "batch_size               300.000000  400.000000  375.0000\n",
       "optimizer_learning_rate    0.001500    0.001500    0.0020\n",
       "stop epoch                13.000000   20.000000   14.0000\n",
       "optimizer_momentum              NaN    0.000000       NaN"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convg_results = {\n",
    "    'adam':{'score':adam_grid_result.best_score_},\n",
    "    'rmsprop':{'score':rmsprop_grid_result.best_score_},\n",
    "    'sgd':{'score':sgd_grid_result.best_score_},\n",
    "}\n",
    "# append best parameters\n",
    "convg_results['adam'] = convg_results['adam'] | adam_grid_result.best_params_\n",
    "convg_results['rmsprop'] = convg_results['rmsprop'] | rmsprop_grid_result.best_params_\n",
    "convg_results['sgd'] = convg_results['sgd'] | sgd_grid_result.best_params_\n",
    "# append stopped epoch\n",
    "convg_results['adam']['stop epoch'] = adam_grid_result.best_estimator_.current_epoch\n",
    "convg_results['rmsprop']['stop epoch'] = rmsprop_grid_result.best_estimator_.current_epoch\n",
    "convg_results['sgd']['stop epoch'] = sgd_grid_result.best_estimator_.current_epoch\n",
    "\n",
    "pd.DataFrame(convg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bd40d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training convergence results\n",
    "# model convergence with optimizer adam\n",
    "adam_model_convg = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0.0,\n",
    "    dropoutHL2 = 0.0, \n",
    "    optimizer_learning_rate = 0.0015, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='Adam',\n",
    ")\n",
    "adam_model_convg._name = 'adam_convg'\n",
    "\n",
    "# model convergence with optimizer RMSprop\n",
    "rmsprop_model_convg = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0.0,\n",
    "    dropoutHL2 = 0.0, \n",
    "    optimizer_learning_rate = 0.0015, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='RMSprop',\n",
    ")\n",
    "rmsprop_model_convg._name = 'rmsprop_convg'\n",
    "\n",
    "# model convergence with optimizer SGD\n",
    "sgd_model_convg = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 400, \n",
    "    dropoutHL1 = 0.0,\n",
    "    dropoutHL2 = 0.0, \n",
    "    optimizer_learning_rate = 0.002, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='SGD',\n",
    ")\n",
    "sgd_model_convg._name = 'sgd_convg'\n",
    "\n",
    "\n",
    "# models list\n",
    "models_list = [adam_model_convg,rmsprop_model_convg,sgd_model_convg]\n",
    "# epochs list in order: [adam,rmsprop,sgd]\n",
    "models_epochs_list = [13,20,14]\n",
    "# batch size list in order: [adam,rmsprop,sgd]\n",
    "models_batch_size_list = [300,400,375]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc05d6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.8487 - val_loss: 0.2403 - val_accuracy: 0.9288\n",
      "Epoch 2/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2056 - accuracy: 0.9393 - val_loss: 0.1789 - val_accuracy: 0.9467\n",
      "Epoch 3/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9580 - val_loss: 0.1432 - val_accuracy: 0.9588\n",
      "Epoch 4/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9695 - val_loss: 0.1152 - val_accuracy: 0.9641\n",
      "Epoch 5/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.1044 - val_accuracy: 0.9676\n",
      "Epoch 6/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0926 - val_accuracy: 0.9719\n",
      "Epoch 7/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
      "Epoch 8/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.0895 - val_accuracy: 0.9727\n",
      "Epoch 9/13\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0795 - val_accuracy: 0.9757\n",
      "Epoch 10/13\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0838 - val_accuracy: 0.9761\n",
      "Epoch 11/13\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0890 - val_accuracy: 0.9744\n",
      "Epoch 12/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0896 - val_accuracy: 0.9748\n",
      "Epoch 13/13\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0851 - val_accuracy: 0.9766\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9103 - accuracy: 0.8054 - val_loss: 0.2360 - val_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1853 - accuracy: 0.9431 - val_loss: 0.1316 - val_accuracy: 0.9614\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9673 - val_loss: 0.1021 - val_accuracy: 0.9687\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.0770 - val_accuracy: 0.9774\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.1025 - val_accuracy: 0.9696\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0741 - val_accuracy: 0.9797\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0804 - val_accuracy: 0.9790\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0938 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1007 - val_accuracy: 0.9773\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1024 - val_accuracy: 0.9786\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.1159 - val_accuracy: 0.9779\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.1043 - val_accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1086 - val_accuracy: 0.9811\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1098 - val_accuracy: 0.9814\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0997 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1274 - val_accuracy: 0.9799\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1243 - val_accuracy: 0.9804\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1378 - val_accuracy: 0.9799\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1229 - val_accuracy: 0.9831\n",
      "Epoch 1/14\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 1.7877 - accuracy: 0.4589 - val_loss: 1.2735 - val_accuracy: 0.6863\n",
      "Epoch 2/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.0700 - accuracy: 0.7425 - val_loss: 0.9200 - val_accuracy: 0.7795\n",
      "Epoch 3/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.8331 - accuracy: 0.7990 - val_loss: 0.7608 - val_accuracy: 0.8129\n",
      "Epoch 4/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.8238 - val_loss: 0.6695 - val_accuracy: 0.8288\n",
      "Epoch 5/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.8384 - val_loss: 0.6090 - val_accuracy: 0.8433\n",
      "Epoch 6/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.8487 - val_loss: 0.5664 - val_accuracy: 0.8519\n",
      "Epoch 7/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.8560 - val_loss: 0.5356 - val_accuracy: 0.8578\n",
      "Epoch 8/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.8622 - val_loss: 0.5101 - val_accuracy: 0.8632\n",
      "Epoch 9/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8670 - val_loss: 0.4886 - val_accuracy: 0.8679\n",
      "Epoch 10/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8713 - val_loss: 0.4718 - val_accuracy: 0.8707\n",
      "Epoch 11/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8742 - val_loss: 0.4598 - val_accuracy: 0.8717\n",
      "Epoch 12/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8776 - val_loss: 0.4452 - val_accuracy: 0.8758\n",
      "Epoch 13/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8793 - val_loss: 0.4340 - val_accuracy: 0.8785\n",
      "Epoch 14/14\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8816 - val_loss: 0.4254 - val_accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "models_convg_results = model_train_results(\n",
    "    models = models_list,\n",
    "    epochs = models_epochs_list,\n",
    "    batch_size = models_batch_size_list,\n",
    "    X = X_train,\n",
    "    Y = y_train,\n",
    "    X_val = X_validation,\n",
    "    Y_val = y_validation,\n",
    "    callbacks=None,\n",
    "    verbose = 1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951e20c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x1300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_results(models_convg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d1c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model adam_convg validation loss: 0.08512312173843384\n",
      "model adam_convg validation accuracy: 0.9765833616256714\n",
      "\n",
      "\n",
      "model rmsprop_convg validation loss: 0.12291974574327469\n",
      "model rmsprop_convg validation accuracy: 0.9830833077430725\n",
      "\n",
      "\n",
      "model sgd_convg validation loss: 0.425358384847641\n",
      "model sgd_convg validation accuracy: 0.8804166913032532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    print(f\"model {model.name} validation loss: {models_convg_results[model.name]['val_loss']}\")\n",
    "    print(f\"model {model.name} validation accuracy: {models_convg_results[model.name]['val_accuracy']}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef06b10",
   "metadata": {},
   "source": [
    "The models improved performance after finding a suitable `batch size` number and using `early stop` to monitor `validation loss` when the metric stopped to improve (to avoid overfitting), which resulted in smoother `convergence` and less variability(less erratic curves).\n",
    "\n",
    "Also, I had to slightly tune the `learning rate` of every model due to the other hyperparameter modifications.\n",
    "\n",
    "Models with `Adam` and `RMSprop` optimizers continue having signs of `overfitting` due to the `validation loss` value being higher than the `training loss`. \n",
    "\n",
    "The model with `SGD` optimizer converges at a certain point and has no signs of `overfitting` but has the low accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdb053",
   "metadata": {},
   "source": [
    "## Dropout Regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa66f7",
   "metadata": {},
   "source": [
    "### model dropout with 'adam' optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f4c93d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "adam_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.0015,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='Adam',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=30,\n",
    "    batch_size=300,\n",
    ")\n",
    "adam_param_grid = {\n",
    "    #'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    #'batch_size':[200,300,400],\n",
    "    'dropoutHL1':[0.6],\n",
    "    'dropoutHL2':[0.3,0.4],\n",
    "}\n",
    "adam_grid = GridSearchCV(\n",
    "    estimator=adam_estimator, \n",
    "    param_grid=adam_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e201df5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 0.8734 - accuracy: 0.7476 - val_loss: 0.2644 - val_accuracy: 0.9189\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8973 - val_loss: 0.1871 - val_accuracy: 0.9444\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.9231 - val_loss: 0.1524 - val_accuracy: 0.9539\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9386 - val_loss: 0.1305 - val_accuracy: 0.9592\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9454 - val_loss: 0.1153 - val_accuracy: 0.9640\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9523 - val_loss: 0.1046 - val_accuracy: 0.9660\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9569 - val_loss: 0.0964 - val_accuracy: 0.9702\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9625 - val_loss: 0.0916 - val_accuracy: 0.9702\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9650 - val_loss: 0.0886 - val_accuracy: 0.9714\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9684 - val_loss: 0.0859 - val_accuracy: 0.9731\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9715 - val_loss: 0.0814 - val_accuracy: 0.9745\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9697 - val_loss: 0.0775 - val_accuracy: 0.9762\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9734 - val_loss: 0.0794 - val_accuracy: 0.9762\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9743 - val_loss: 0.0782 - val_accuracy: 0.9762\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.0765 - val_accuracy: 0.9765\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.0777 - val_accuracy: 0.9768\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.0770 - val_accuracy: 0.9770\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.0741 - val_accuracy: 0.9791\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0719 - val_accuracy: 0.9790\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9802\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0763 - val_accuracy: 0.9787\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9820 - val_loss: 0.0745 - val_accuracy: 0.9784\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 0.0758 - val_accuracy: 0.9795\n",
      "Epoch 24/30\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.0501 - accuracy: 0.9830Restoring model weights from the end of the best epoch: 20.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 0.0755 - val_accuracy: 0.9784\n",
      "Epoch 24: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8518 - accuracy: 0.7504 - val_loss: 0.2574 - val_accuracy: 0.9209\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8981 - val_loss: 0.1871 - val_accuracy: 0.9443\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9244 - val_loss: 0.1540 - val_accuracy: 0.9543\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9386 - val_loss: 0.1290 - val_accuracy: 0.9597\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9479 - val_loss: 0.1184 - val_accuracy: 0.9627\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9526 - val_loss: 0.1066 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9583 - val_loss: 0.1001 - val_accuracy: 0.9676\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9626 - val_loss: 0.0944 - val_accuracy: 0.9702\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9649 - val_loss: 0.0924 - val_accuracy: 0.9703\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9689 - val_loss: 0.0912 - val_accuracy: 0.9708\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9707 - val_loss: 0.0850 - val_accuracy: 0.9729\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9709 - val_loss: 0.0787 - val_accuracy: 0.9758\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9741 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9749 - val_loss: 0.0797 - val_accuracy: 0.9750\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.0836 - val_accuracy: 0.9741\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9767 - val_loss: 0.0764 - val_accuracy: 0.9754\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9775 - val_loss: 0.0789 - val_accuracy: 0.9758\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9793 - val_loss: 0.0757 - val_accuracy: 0.9783\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.0785 - val_accuracy: 0.9765\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9801 - val_loss: 0.0785 - val_accuracy: 0.9761\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.0736 - val_accuracy: 0.9785\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9791\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.0722 - val_accuracy: 0.9802\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 0.0811 - val_accuracy: 0.9766\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.0757 - val_accuracy: 0.9800\n",
      "Epoch 26/30\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.0486 - accuracy: 0.9839Restoring model weights from the end of the best epoch: 22.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.0756 - val_accuracy: 0.9788\n",
      "Epoch 26: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8555 - accuracy: 0.7506 - val_loss: 0.2610 - val_accuracy: 0.9208\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8957 - val_loss: 0.1954 - val_accuracy: 0.9411\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9249 - val_loss: 0.1628 - val_accuracy: 0.9503\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.9371 - val_loss: 0.1353 - val_accuracy: 0.9589\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9477 - val_loss: 0.1175 - val_accuracy: 0.9627\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9536 - val_loss: 0.1082 - val_accuracy: 0.9669\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9572 - val_loss: 0.1039 - val_accuracy: 0.9664\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9624 - val_loss: 0.0915 - val_accuracy: 0.9710\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9650 - val_loss: 0.0887 - val_accuracy: 0.9715\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 0.0917 - val_accuracy: 0.9716\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.0852 - val_accuracy: 0.9740\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9764\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.0819 - val_accuracy: 0.9756\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9748 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9764 - val_loss: 0.0751 - val_accuracy: 0.9762\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9777 - val_loss: 0.0741 - val_accuracy: 0.9781\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9782\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.0745 - val_accuracy: 0.9786\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9804 - val_loss: 0.0720 - val_accuracy: 0.9780\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9803 - val_loss: 0.0717 - val_accuracy: 0.9779\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9808 - val_loss: 0.0695 - val_accuracy: 0.9793\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9822 - val_loss: 0.0706 - val_accuracy: 0.9792\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 0.0680 - val_accuracy: 0.9793\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9828 - val_loss: 0.0715 - val_accuracy: 0.9789\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.0728 - val_accuracy: 0.9798\n",
      "Epoch 27/30\n",
      "107/120 [=========================>....] - ETA: 0s - loss: 0.0437 - accuracy: 0.9855Restoring model weights from the end of the best epoch: 23.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 0.0736 - val_accuracy: 0.9802\n",
      "Epoch 27: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8429 - accuracy: 0.7537 - val_loss: 0.2582 - val_accuracy: 0.9230\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8982 - val_loss: 0.1935 - val_accuracy: 0.9422\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9250 - val_loss: 0.1595 - val_accuracy: 0.9516\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9363 - val_loss: 0.1362 - val_accuracy: 0.9588\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9489 - val_loss: 0.1209 - val_accuracy: 0.9629\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9517 - val_loss: 0.1061 - val_accuracy: 0.9663\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9571 - val_loss: 0.1019 - val_accuracy: 0.9678\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9625 - val_loss: 0.0945 - val_accuracy: 0.9696\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9647 - val_loss: 0.0882 - val_accuracy: 0.9716\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9685 - val_loss: 0.0879 - val_accuracy: 0.9727\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9686 - val_loss: 0.0822 - val_accuracy: 0.9756\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9713 - val_loss: 0.0836 - val_accuracy: 0.9747\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9726 - val_loss: 0.0813 - val_accuracy: 0.9747\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9746 - val_loss: 0.0832 - val_accuracy: 0.9747\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9769 - val_loss: 0.0819 - val_accuracy: 0.9753\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9779 - val_loss: 0.0778 - val_accuracy: 0.9772\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9782 - val_loss: 0.0798 - val_accuracy: 0.9762\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.0801 - val_accuracy: 0.9763\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.0765 - val_accuracy: 0.9777\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.0755 - val_accuracy: 0.9770\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.0706 - val_accuracy: 0.9794\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9827 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9841 - val_loss: 0.0741 - val_accuracy: 0.9778\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.0744 - val_accuracy: 0.9791\n",
      "Epoch 25/30\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.0488 - accuracy: 0.9835Restoring model weights from the end of the best epoch: 21.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.0764 - val_accuracy: 0.9782\n",
      "Epoch 25: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.9212 - accuracy: 0.7328 - val_loss: 0.2777 - val_accuracy: 0.9147\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8902 - val_loss: 0.1957 - val_accuracy: 0.9393\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.9194 - val_loss: 0.1572 - val_accuracy: 0.9519\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9342 - val_loss: 0.1363 - val_accuracy: 0.9572\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9433 - val_loss: 0.1196 - val_accuracy: 0.9619\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9504 - val_loss: 0.1077 - val_accuracy: 0.9643\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9552 - val_loss: 0.1023 - val_accuracy: 0.9680\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9597 - val_loss: 0.0927 - val_accuracy: 0.9697\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9632 - val_loss: 0.0896 - val_accuracy: 0.9714\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9654 - val_loss: 0.0892 - val_accuracy: 0.9716\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9683 - val_loss: 0.0853 - val_accuracy: 0.9722\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9688 - val_loss: 0.0789 - val_accuracy: 0.9753\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9696 - val_loss: 0.0835 - val_accuracy: 0.9743\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9725 - val_loss: 0.0800 - val_accuracy: 0.9754\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9738 - val_loss: 0.0752 - val_accuracy: 0.9760\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9746 - val_loss: 0.0792 - val_accuracy: 0.9774\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9777 - val_loss: 0.0807 - val_accuracy: 0.9768\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.0779 - val_accuracy: 0.9780\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9783 - val_loss: 0.0750 - val_accuracy: 0.9791\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0722 - val_accuracy: 0.9786\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 0.0754 - val_accuracy: 0.9790\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.0787 - val_accuracy: 0.9776\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0726 - val_accuracy: 0.9790\n",
      "Epoch 24/30\n",
      "112/120 [===========================>..] - ETA: 0s - loss: 0.0540 - accuracy: 0.9818Restoring model weights from the end of the best epoch: 20.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 0.0774 - val_accuracy: 0.9783\n",
      "Epoch 24: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 2s 7ms/step - loss: 0.9061 - accuracy: 0.7327 - val_loss: 0.2665 - val_accuracy: 0.9187\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8936 - val_loss: 0.1890 - val_accuracy: 0.9416\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9197 - val_loss: 0.1541 - val_accuracy: 0.9538\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.9350 - val_loss: 0.1327 - val_accuracy: 0.9596\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9441 - val_loss: 0.1197 - val_accuracy: 0.9639\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9503 - val_loss: 0.1092 - val_accuracy: 0.9665\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9558 - val_loss: 0.1029 - val_accuracy: 0.9686\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9596 - val_loss: 0.0968 - val_accuracy: 0.9704\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9635 - val_loss: 0.0915 - val_accuracy: 0.9705\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9673 - val_loss: 0.0962 - val_accuracy: 0.9693\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9693 - val_loss: 0.0867 - val_accuracy: 0.9737\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.0823 - val_accuracy: 0.9747\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9709 - val_loss: 0.0855 - val_accuracy: 0.9730\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9713 - val_loss: 0.0814 - val_accuracy: 0.9748\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9736 - val_loss: 0.0818 - val_accuracy: 0.9752\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9743 - val_loss: 0.0817 - val_accuracy: 0.9755\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9769 - val_loss: 0.0772 - val_accuracy: 0.9759\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 0.0765 - val_accuracy: 0.9768\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9794 - val_loss: 0.0811 - val_accuracy: 0.9758\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9794 - val_loss: 0.0756 - val_accuracy: 0.9778\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.0763 - val_accuracy: 0.9772\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.0693 - val_accuracy: 0.9797\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9812 - val_loss: 0.0743 - val_accuracy: 0.9784\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.0747 - val_accuracy: 0.9785\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.0807 - val_accuracy: 0.9780\n",
      "Epoch 27/30\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9832Restoring model weights from the end of the best epoch: 23.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.0739 - val_accuracy: 0.9806\n",
      "Epoch 27: early stopping\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9052 - accuracy: 0.7317 - val_loss: 0.2654 - val_accuracy: 0.9209\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8925 - val_loss: 0.1963 - val_accuracy: 0.9398\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9191 - val_loss: 0.1607 - val_accuracy: 0.9509\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9342 - val_loss: 0.1380 - val_accuracy: 0.9572\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.9441 - val_loss: 0.1203 - val_accuracy: 0.9621\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9506 - val_loss: 0.1111 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9546 - val_loss: 0.1050 - val_accuracy: 0.9662\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9596 - val_loss: 0.0980 - val_accuracy: 0.9694\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9612 - val_loss: 0.0909 - val_accuracy: 0.9706\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9648 - val_loss: 0.0955 - val_accuracy: 0.9696\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9673 - val_loss: 0.0875 - val_accuracy: 0.9726\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9685 - val_loss: 0.0848 - val_accuracy: 0.9743\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9710 - val_loss: 0.0835 - val_accuracy: 0.9746\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 0.0875 - val_accuracy: 0.9730\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9745 - val_loss: 0.0813 - val_accuracy: 0.9750\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9755 - val_loss: 0.0769 - val_accuracy: 0.9773\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.0777 - val_accuracy: 0.9766\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.0780 - val_accuracy: 0.9785\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9777 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9778 - val_loss: 0.0710 - val_accuracy: 0.9779\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 0.0744 - val_accuracy: 0.9783\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0750 - val_accuracy: 0.9786\n",
      "Epoch 24/30\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9818Restoring model weights from the end of the best epoch: 20.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9818 - val_loss: 0.0753 - val_accuracy: 0.9792\n",
      "Epoch 24: early stopping\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8910 - accuracy: 0.7377 - val_loss: 0.2644 - val_accuracy: 0.9222\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8917 - val_loss: 0.1988 - val_accuracy: 0.9404\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.9214 - val_loss: 0.1595 - val_accuracy: 0.9507\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2140 - accuracy: 0.9347 - val_loss: 0.1371 - val_accuracy: 0.9575\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9455 - val_loss: 0.1222 - val_accuracy: 0.9619\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9511 - val_loss: 0.1081 - val_accuracy: 0.9661\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9553 - val_loss: 0.1025 - val_accuracy: 0.9683\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9587 - val_loss: 0.1004 - val_accuracy: 0.9684\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9621 - val_loss: 0.0904 - val_accuracy: 0.9714\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9657 - val_loss: 0.0885 - val_accuracy: 0.9717\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9676 - val_loss: 0.0855 - val_accuracy: 0.9739\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9692 - val_loss: 0.0869 - val_accuracy: 0.9730\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9708 - val_loss: 0.0829 - val_accuracy: 0.9743\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9737 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9736 - val_loss: 0.0832 - val_accuracy: 0.9743\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.0794 - val_accuracy: 0.9757\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9760 - val_loss: 0.0763 - val_accuracy: 0.9763\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.0775 - val_accuracy: 0.9759\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.0833 - val_accuracy: 0.9757\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.0751 - val_accuracy: 0.9764\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 0.0731 - val_accuracy: 0.9794\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9809 - val_loss: 0.0767 - val_accuracy: 0.9780\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 0.0750 - val_accuracy: 0.9780\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.0728 - val_accuracy: 0.9790\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.0829 - val_accuracy: 0.9768\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.0740 - val_accuracy: 0.9784\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9827 - val_loss: 0.0727 - val_accuracy: 0.9799\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0759 - val_accuracy: 0.9797\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9849 - val_loss: 0.0732 - val_accuracy: 0.9803\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "160/160 [==============================] - 1s 5ms/step - loss: 0.7372 - accuracy: 0.7836 - val_loss: 0.2329 - val_accuracy: 0.9288\n",
      "Epoch 2/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.2865 - accuracy: 0.9126 - val_loss: 0.1693 - val_accuracy: 0.9485\n",
      "Epoch 3/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9350 - val_loss: 0.1286 - val_accuracy: 0.9611\n",
      "Epoch 4/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9463 - val_loss: 0.1133 - val_accuracy: 0.9642\n",
      "Epoch 5/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9528 - val_loss: 0.0991 - val_accuracy: 0.9689\n",
      "Epoch 6/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1297 - accuracy: 0.9600 - val_loss: 0.0928 - val_accuracy: 0.9706\n",
      "Epoch 7/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9646 - val_loss: 0.0903 - val_accuracy: 0.9719\n",
      "Epoch 8/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9650 - val_loss: 0.0877 - val_accuracy: 0.9711\n",
      "Epoch 9/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9681 - val_loss: 0.0789 - val_accuracy: 0.9756\n",
      "Epoch 10/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9710 - val_loss: 0.0767 - val_accuracy: 0.9764\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9727 - val_loss: 0.0752 - val_accuracy: 0.9781\n",
      "Epoch 12/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9756 - val_loss: 0.0783 - val_accuracy: 0.9760\n",
      "Epoch 13/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9764 - val_loss: 0.0754 - val_accuracy: 0.9774\n",
      "Epoch 14/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "Epoch 15/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 0.0684 - val_accuracy: 0.9798\n",
      "Epoch 16/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
      "Epoch 17/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.0695 - val_accuracy: 0.9786\n",
      "Epoch 18/30\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.0726 - val_accuracy: 0.9779\n",
      "Epoch 19/30\n",
      "144/160 [==========================>...] - ETA: 0s - loss: 0.0597 - accuracy: 0.9800Restoring model weights from the end of the best epoch: 15.\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.0692 - val_accuracy: 0.9808\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    adam_grid_result = adam_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8c9c7c1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.978646 using {'dropoutHL1': 0.6, 'dropoutHL2': 0.3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (adam_grid_result.best_score_, adam_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "479bd8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 19\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",adam_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc13dd",
   "metadata": {},
   "source": [
    "### model dropout with 'RMSprop' optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81128981",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "rmsprop_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.0015,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='RMSprop',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=25,\n",
    "    batch_size=400,\n",
    ")\n",
    "rmsprop_param_grid = {\n",
    "    #'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    #'batch_size':[300,400,500],\n",
    "    'dropoutHL1':[0.5,0.6],\n",
    "    'dropoutHL2':[0.0,0.1,0.2],\n",
    "}\n",
    "rmsprop_grid = GridSearchCV(\n",
    "    estimator=rmsprop_estimator, \n",
    "    param_grid=rmsprop_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe5085c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8391 - accuracy: 0.7699 - val_loss: 0.2821 - val_accuracy: 0.9139\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.9093 - val_loss: 0.2097 - val_accuracy: 0.9367\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9324 - val_loss: 0.1653 - val_accuracy: 0.9509\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9474 - val_loss: 0.1400 - val_accuracy: 0.9593\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9569 - val_loss: 0.1225 - val_accuracy: 0.9635\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9633 - val_loss: 0.1104 - val_accuracy: 0.9667\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 0.0980 - val_accuracy: 0.9714\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9719 - val_loss: 0.0915 - val_accuracy: 0.9711\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9743 - val_loss: 0.0914 - val_accuracy: 0.9728\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9764 - val_loss: 0.0869 - val_accuracy: 0.9737\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.0817 - val_accuracy: 0.9748\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0818 - val_accuracy: 0.9761\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9831 - val_loss: 0.0864 - val_accuracy: 0.9750\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9839 - val_loss: 0.0829 - val_accuracy: 0.9751\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0780 - val_accuracy: 0.9766\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0782 - val_accuracy: 0.9776\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0827 - val_accuracy: 0.9773\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.0814 - val_accuracy: 0.9774\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0757 - val_accuracy: 0.9806\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0812 - val_accuracy: 0.9789\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0878 - val_accuracy: 0.9784\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.0855 - val_accuracy: 0.9782\n",
      "Epoch 24/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0248 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0840 - val_accuracy: 0.9782\n",
      "Epoch 24: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8147 - accuracy: 0.7744 - val_loss: 0.2765 - val_accuracy: 0.9182\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9105 - val_loss: 0.2053 - val_accuracy: 0.9396\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9349 - val_loss: 0.1677 - val_accuracy: 0.9525\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9476 - val_loss: 0.1387 - val_accuracy: 0.9586\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9573 - val_loss: 0.1209 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9635 - val_loss: 0.1081 - val_accuracy: 0.9686\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9688 - val_loss: 0.1037 - val_accuracy: 0.9675\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9728 - val_loss: 0.0946 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9754 - val_loss: 0.0918 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9767 - val_loss: 0.0890 - val_accuracy: 0.9729\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9780 - val_loss: 0.0838 - val_accuracy: 0.9756\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.0782 - val_accuracy: 0.9768\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9835 - val_loss: 0.0852 - val_accuracy: 0.9762\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9839 - val_loss: 0.0789 - val_accuracy: 0.9764\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 0.0836 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9864Restoring model weights from the end of the best epoch: 12.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.0834 - val_accuracy: 0.9764\n",
      "Epoch 16: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8138 - accuracy: 0.7746 - val_loss: 0.2784 - val_accuracy: 0.9165\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9096 - val_loss: 0.2157 - val_accuracy: 0.9345\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2185 - accuracy: 0.9345 - val_loss: 0.1722 - val_accuracy: 0.9499\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9482 - val_loss: 0.1453 - val_accuracy: 0.9568\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9557 - val_loss: 0.1227 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9639 - val_loss: 0.1124 - val_accuracy: 0.9668\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9681 - val_loss: 0.1080 - val_accuracy: 0.9671\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9717 - val_loss: 0.1046 - val_accuracy: 0.9691\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9743 - val_loss: 0.0951 - val_accuracy: 0.9708\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9758 - val_loss: 0.0914 - val_accuracy: 0.9721\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9797 - val_loss: 0.0845 - val_accuracy: 0.9749\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0817 - val_accuracy: 0.9759\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.0864 - val_accuracy: 0.9755\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0835 - val_accuracy: 0.9758\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.0839 - val_accuracy: 0.9764\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9871 - val_loss: 0.0810 - val_accuracy: 0.9771\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.0834 - val_accuracy: 0.9768\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.0833 - val_accuracy: 0.9777\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.0790 - val_accuracy: 0.9782\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.0791 - val_accuracy: 0.9783\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0840 - val_accuracy: 0.9794\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.0771 - val_accuracy: 0.9797\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0805 - val_accuracy: 0.9796\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0874 - val_accuracy: 0.9781\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.7997 - accuracy: 0.7733 - val_loss: 0.2781 - val_accuracy: 0.9175\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.9109 - val_loss: 0.2143 - val_accuracy: 0.9354\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9344 - val_loss: 0.1715 - val_accuracy: 0.9493\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9484 - val_loss: 0.1430 - val_accuracy: 0.9580\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9562 - val_loss: 0.1217 - val_accuracy: 0.9655\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9630 - val_loss: 0.1115 - val_accuracy: 0.9665\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.1057 - val_accuracy: 0.9685\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9708 - val_loss: 0.1028 - val_accuracy: 0.9687\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9736 - val_loss: 0.0896 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9767 - val_loss: 0.0915 - val_accuracy: 0.9730\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9807 - val_loss: 0.0868 - val_accuracy: 0.9749\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0848 - val_accuracy: 0.9749\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9831 - val_loss: 0.0829 - val_accuracy: 0.9761\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0811 - val_accuracy: 0.9767\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.0813 - val_accuracy: 0.9767\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0859 - val_accuracy: 0.9738\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.0850 - val_accuracy: 0.9768\n",
      "Epoch 19/25\n",
      "76/90 [========================>.....] - ETA: 0s - loss: 0.0345 - accuracy: 0.9883Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0886 - val_accuracy: 0.9766\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8745 - accuracy: 0.7552 - val_loss: 0.2829 - val_accuracy: 0.9145\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.9045 - val_loss: 0.2003 - val_accuracy: 0.9392\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9297 - val_loss: 0.1623 - val_accuracy: 0.9514\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9444 - val_loss: 0.1395 - val_accuracy: 0.9568\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9523 - val_loss: 0.1183 - val_accuracy: 0.9636\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9596 - val_loss: 0.1089 - val_accuracy: 0.9665\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9657 - val_loss: 0.0987 - val_accuracy: 0.9699\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9688 - val_loss: 0.0896 - val_accuracy: 0.9718\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9717 - val_loss: 0.0901 - val_accuracy: 0.9721\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9737 - val_loss: 0.0864 - val_accuracy: 0.9736\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9776 - val_loss: 0.0829 - val_accuracy: 0.9742\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0808 - val_accuracy: 0.9757\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9819 - val_loss: 0.0774 - val_accuracy: 0.9766\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.0815 - val_accuracy: 0.9761\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9862 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
      "Epoch 19/25\n",
      "88/90 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9868Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9865 - val_loss: 0.0829 - val_accuracy: 0.9768\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8603 - accuracy: 0.7584 - val_loss: 0.2775 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.9042 - val_loss: 0.1982 - val_accuracy: 0.9406\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9299 - val_loss: 0.1633 - val_accuracy: 0.9526\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9435 - val_loss: 0.1378 - val_accuracy: 0.9591\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.9529 - val_loss: 0.1217 - val_accuracy: 0.9636\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9613 - val_loss: 0.1078 - val_accuracy: 0.9670\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.1015 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9695 - val_loss: 0.0953 - val_accuracy: 0.9705\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9719 - val_loss: 0.0909 - val_accuracy: 0.9723\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9747 - val_loss: 0.0873 - val_accuracy: 0.9731\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9766 - val_loss: 0.0814 - val_accuracy: 0.9760\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.0787 - val_accuracy: 0.9774\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.0823 - val_accuracy: 0.9748\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9761\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9827 - val_loss: 0.0785 - val_accuracy: 0.9771\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 0.0772 - val_accuracy: 0.9769\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0822 - val_accuracy: 0.9770\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9860 - val_loss: 0.0778 - val_accuracy: 0.9784\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.0808 - val_accuracy: 0.9769\n",
      "Epoch 20/25\n",
      "74/90 [=======================>......] - ETA: 0s - loss: 0.0343 - accuracy: 0.9884Restoring model weights from the end of the best epoch: 16.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 20: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8322 - accuracy: 0.7634 - val_loss: 0.2727 - val_accuracy: 0.9178\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.9055 - val_loss: 0.2007 - val_accuracy: 0.9388\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9301 - val_loss: 0.1644 - val_accuracy: 0.9522\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9441 - val_loss: 0.1402 - val_accuracy: 0.9581\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9541 - val_loss: 0.1197 - val_accuracy: 0.9643\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9593 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9660 - val_loss: 0.1046 - val_accuracy: 0.9667\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9687 - val_loss: 0.0995 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9719 - val_loss: 0.0909 - val_accuracy: 0.9721\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9742 - val_loss: 0.0905 - val_accuracy: 0.9722\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9772 - val_loss: 0.0869 - val_accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9786 - val_loss: 0.0823 - val_accuracy: 0.9758\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9796 - val_loss: 0.0831 - val_accuracy: 0.9753\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0838 - val_accuracy: 0.9753\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9852 - val_loss: 0.0803 - val_accuracy: 0.9770\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9852 - val_loss: 0.0832 - val_accuracy: 0.9757\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.0848 - val_accuracy: 0.9772\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0774 - val_accuracy: 0.9782\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0783 - val_accuracy: 0.9792\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.0779 - val_accuracy: 0.9792\n",
      "Epoch 24/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0285 - accuracy: 0.9900Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.0786 - val_accuracy: 0.9788\n",
      "Epoch 24: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8013 - accuracy: 0.7666 - val_loss: 0.2679 - val_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.9051 - val_loss: 0.1986 - val_accuracy: 0.9400\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9314 - val_loss: 0.1603 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9455 - val_loss: 0.1341 - val_accuracy: 0.9609\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9551 - val_loss: 0.1158 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9606 - val_loss: 0.1048 - val_accuracy: 0.9683\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9669 - val_loss: 0.1017 - val_accuracy: 0.9694\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9692 - val_loss: 0.0982 - val_accuracy: 0.9688\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9709 - val_loss: 0.0897 - val_accuracy: 0.9728\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9755 - val_loss: 0.0885 - val_accuracy: 0.9735\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 0.0822 - val_accuracy: 0.9755\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9800 - val_loss: 0.0836 - val_accuracy: 0.9754\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.0822 - val_accuracy: 0.9765\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9814 - val_loss: 0.0791 - val_accuracy: 0.9764\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9834 - val_loss: 0.0810 - val_accuracy: 0.9754\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 0.0794 - val_accuracy: 0.9774\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.0803 - val_accuracy: 0.9771\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9857 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0836 - val_accuracy: 0.9770\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0784 - val_accuracy: 0.9773\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.0771 - val_accuracy: 0.9782\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.0809 - val_accuracy: 0.9780\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.0766 - val_accuracy: 0.9797\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0760 - val_accuracy: 0.9796\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.9159 - accuracy: 0.7409 - val_loss: 0.2898 - val_accuracy: 0.9112\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8988 - val_loss: 0.2014 - val_accuracy: 0.9377\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9264 - val_loss: 0.1623 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9392 - val_loss: 0.1407 - val_accuracy: 0.9564\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9505 - val_loss: 0.1213 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9556 - val_loss: 0.1110 - val_accuracy: 0.9649\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9619 - val_loss: 0.1018 - val_accuracy: 0.9688\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9664 - val_loss: 0.0898 - val_accuracy: 0.9717\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9701 - val_loss: 0.0893 - val_accuracy: 0.9712\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9712 - val_loss: 0.0871 - val_accuracy: 0.9722\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9738 - val_loss: 0.0801 - val_accuracy: 0.9740\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.0800 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9782 - val_loss: 0.0792 - val_accuracy: 0.9760\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.0758 - val_accuracy: 0.9767\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9818 - val_loss: 0.0741 - val_accuracy: 0.9777\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9834 - val_loss: 0.0780 - val_accuracy: 0.9771\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0805 - val_accuracy: 0.9772\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9845 - val_loss: 0.0785 - val_accuracy: 0.9781\n",
      "Epoch 19/25\n",
      "87/90 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9867Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.0800 - val_accuracy: 0.9772\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8872 - accuracy: 0.7477 - val_loss: 0.2845 - val_accuracy: 0.9149\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8986 - val_loss: 0.1971 - val_accuracy: 0.9408\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9269 - val_loss: 0.1593 - val_accuracy: 0.9539\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9400 - val_loss: 0.1344 - val_accuracy: 0.9597\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9507 - val_loss: 0.1218 - val_accuracy: 0.9628\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9588 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9616 - val_loss: 0.1020 - val_accuracy: 0.9679\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9677 - val_loss: 0.0928 - val_accuracy: 0.9707\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9700 - val_loss: 0.0939 - val_accuracy: 0.9712\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9715 - val_loss: 0.0867 - val_accuracy: 0.9732\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9741 - val_loss: 0.0825 - val_accuracy: 0.9755\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0833 - val_accuracy: 0.9755\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9784 - val_loss: 0.0825 - val_accuracy: 0.9747\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9797 - val_loss: 0.0804 - val_accuracy: 0.9758\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0798 - val_accuracy: 0.9764\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.0774 - val_accuracy: 0.9767\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.0812 - val_accuracy: 0.9756\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0744 - val_accuracy: 0.9787\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0792 - val_accuracy: 0.9779\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.0782 - val_accuracy: 0.9786\n",
      "Epoch 22/25\n",
      "75/90 [========================>.....] - ETA: 0s - loss: 0.0371 - accuracy: 0.9871Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.0805 - val_accuracy: 0.9777\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8476 - accuracy: 0.7553 - val_loss: 0.2722 - val_accuracy: 0.9168\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.9012 - val_loss: 0.1959 - val_accuracy: 0.9409\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9278 - val_loss: 0.1605 - val_accuracy: 0.9529\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9430 - val_loss: 0.1372 - val_accuracy: 0.9597\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9523 - val_loss: 0.1205 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9580 - val_loss: 0.1080 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9627 - val_loss: 0.1031 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9668 - val_loss: 0.1010 - val_accuracy: 0.9680\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9690 - val_loss: 0.0918 - val_accuracy: 0.9707\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9731 - val_loss: 0.0889 - val_accuracy: 0.9728\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9740 - val_loss: 0.0877 - val_accuracy: 0.9733\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 0.0806 - val_accuracy: 0.9759\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.0818 - val_accuracy: 0.9762\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.0852 - val_accuracy: 0.9745\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0792 - val_accuracy: 0.9767\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0789 - val_accuracy: 0.9777\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9834 - val_loss: 0.0778 - val_accuracy: 0.9776\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9847 - val_loss: 0.0778 - val_accuracy: 0.9783\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0743 - val_accuracy: 0.9787\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.0793 - val_accuracy: 0.9772\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.0778 - val_accuracy: 0.9780\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0728 - val_accuracy: 0.9793\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.0722 - val_accuracy: 0.9805\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 0.0767 - val_accuracy: 0.9797\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.0784 - val_accuracy: 0.9787\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8227 - accuracy: 0.7591 - val_loss: 0.2722 - val_accuracy: 0.9200\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.9019 - val_loss: 0.1968 - val_accuracy: 0.9402\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2329 - accuracy: 0.9286 - val_loss: 0.1598 - val_accuracy: 0.9523\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9429 - val_loss: 0.1336 - val_accuracy: 0.9585\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9523 - val_loss: 0.1184 - val_accuracy: 0.9631\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9579 - val_loss: 0.1046 - val_accuracy: 0.9684\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9644 - val_loss: 0.1020 - val_accuracy: 0.9681\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9674 - val_loss: 0.1006 - val_accuracy: 0.9681\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9701 - val_loss: 0.0871 - val_accuracy: 0.9722\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9741 - val_loss: 0.0868 - val_accuracy: 0.9728\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9759 - val_loss: 0.0855 - val_accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9783 - val_loss: 0.0817 - val_accuracy: 0.9746\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9797 - val_loss: 0.0829 - val_accuracy: 0.9761\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.0802 - val_accuracy: 0.9761\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9828 - val_loss: 0.0838 - val_accuracy: 0.9748\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9834 - val_loss: 0.0774 - val_accuracy: 0.9769\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 0.0771 - val_accuracy: 0.9762\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.0793 - val_accuracy: 0.9780\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.0799 - val_accuracy: 0.9768\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.0827 - val_accuracy: 0.9758\n",
      "Epoch 21/25\n",
      "73/90 [=======================>......] - ETA: 0s - loss: 0.0363 - accuracy: 0.9879Restoring model weights from the end of the best epoch: 17.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9876 - val_loss: 0.0794 - val_accuracy: 0.9780\n",
      "Epoch 21: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8589 - accuracy: 0.7610 - val_loss: 0.2849 - val_accuracy: 0.9139\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.9044 - val_loss: 0.2073 - val_accuracy: 0.9370\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9264 - val_loss: 0.1674 - val_accuracy: 0.9524\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1940 - accuracy: 0.9421 - val_loss: 0.1438 - val_accuracy: 0.9579\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9509 - val_loss: 0.1231 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9569 - val_loss: 0.1173 - val_accuracy: 0.9655\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9619 - val_loss: 0.1078 - val_accuracy: 0.9685\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9664 - val_loss: 0.0994 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9690 - val_loss: 0.0955 - val_accuracy: 0.9722\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9716 - val_loss: 0.0945 - val_accuracy: 0.9718\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.0875 - val_accuracy: 0.9724\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9758 - val_loss: 0.0841 - val_accuracy: 0.9767\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.0842 - val_accuracy: 0.9763\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9779 - val_loss: 0.0838 - val_accuracy: 0.9761\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.0799 - val_accuracy: 0.9779\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9820 - val_loss: 0.0876 - val_accuracy: 0.9760\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9824 - val_loss: 0.0807 - val_accuracy: 0.9777\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.0805 - val_accuracy: 0.9779\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0772 - val_accuracy: 0.9787\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0804 - val_accuracy: 0.9799\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9854 - val_loss: 0.0838 - val_accuracy: 0.9773\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9864 - val_loss: 0.0771 - val_accuracy: 0.9795\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0812 - val_accuracy: 0.9787\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.0752 - val_accuracy: 0.9800\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8263 - accuracy: 0.7688 - val_loss: 0.2769 - val_accuracy: 0.9183\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.9061 - val_loss: 0.2050 - val_accuracy: 0.9385\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9299 - val_loss: 0.1665 - val_accuracy: 0.9520\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9419 - val_loss: 0.1449 - val_accuracy: 0.9570\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9524 - val_loss: 0.1265 - val_accuracy: 0.9621\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9596 - val_loss: 0.1118 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9619 - val_loss: 0.1061 - val_accuracy: 0.9674\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9671 - val_loss: 0.0988 - val_accuracy: 0.9695\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9693 - val_loss: 0.0990 - val_accuracy: 0.9712\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9718 - val_loss: 0.0921 - val_accuracy: 0.9731\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9747 - val_loss: 0.0844 - val_accuracy: 0.9754\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9756 - val_loss: 0.0802 - val_accuracy: 0.9752\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9767 - val_loss: 0.0857 - val_accuracy: 0.9742\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.0822 - val_accuracy: 0.9763\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.0789 - val_accuracy: 0.9764\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9820 - val_loss: 0.0776 - val_accuracy: 0.9773\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 0.0811 - val_accuracy: 0.9780\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9828 - val_loss: 0.0779 - val_accuracy: 0.9788\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9838 - val_loss: 0.0812 - val_accuracy: 0.9771\n",
      "Epoch 20/25\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9851Restoring model weights from the end of the best epoch: 16.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0777 - val_accuracy: 0.9784\n",
      "Epoch 20: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.8222 - accuracy: 0.7681 - val_loss: 0.2768 - val_accuracy: 0.9175\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.9071 - val_loss: 0.2175 - val_accuracy: 0.9338\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.9296 - val_loss: 0.1718 - val_accuracy: 0.9492\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1881 - accuracy: 0.9433 - val_loss: 0.1467 - val_accuracy: 0.9565\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9512 - val_loss: 0.1256 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9589 - val_loss: 0.1127 - val_accuracy: 0.9661\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9626 - val_loss: 0.1084 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9663 - val_loss: 0.0984 - val_accuracy: 0.9703\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9683 - val_loss: 0.0974 - val_accuracy: 0.9700\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9719 - val_loss: 0.0927 - val_accuracy: 0.9723\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9747 - val_loss: 0.0876 - val_accuracy: 0.9753\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9751 - val_loss: 0.0833 - val_accuracy: 0.9752\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.0860 - val_accuracy: 0.9755\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9796 - val_loss: 0.0843 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9814 - val_loss: 0.0837 - val_accuracy: 0.9763\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0807 - val_accuracy: 0.9770\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.0839 - val_accuracy: 0.9763\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.0799 - val_accuracy: 0.9781\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 0.0762 - val_accuracy: 0.9786\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.0764 - val_accuracy: 0.9797\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 0.0786 - val_accuracy: 0.9784\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 0.0787 - val_accuracy: 0.9799\n",
      "Epoch 24/25\n",
      "80/90 [=========================>....] - ETA: 0s - loss: 0.0361 - accuracy: 0.9879Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0817 - val_accuracy: 0.9781\n",
      "Epoch 24: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.8100 - accuracy: 0.7698 - val_loss: 0.2754 - val_accuracy: 0.9161\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.9074 - val_loss: 0.2120 - val_accuracy: 0.9364\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.9297 - val_loss: 0.1719 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9434 - val_loss: 0.1468 - val_accuracy: 0.9572\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9520 - val_loss: 0.1249 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9587 - val_loss: 0.1141 - val_accuracy: 0.9665\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9637 - val_loss: 0.1084 - val_accuracy: 0.9683\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9666 - val_loss: 0.1023 - val_accuracy: 0.9686\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9684 - val_loss: 0.0925 - val_accuracy: 0.9722\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9717 - val_loss: 0.0940 - val_accuracy: 0.9718\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9744 - val_loss: 0.0885 - val_accuracy: 0.9741\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9768 - val_loss: 0.0889 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.0860 - val_accuracy: 0.9753\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.0825 - val_accuracy: 0.9768\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.0810 - val_accuracy: 0.9769\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9817 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9842 - val_loss: 0.0837 - val_accuracy: 0.9769\n",
      "Epoch 19/25\n",
      "78/90 [=========================>....] - ETA: 0s - loss: 0.0469 - accuracy: 0.9846Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.0849 - val_accuracy: 0.9763\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9073 - accuracy: 0.7465 - val_loss: 0.2863 - val_accuracy: 0.9128\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8980 - val_loss: 0.2040 - val_accuracy: 0.9363\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9231 - val_loss: 0.1639 - val_accuracy: 0.9506\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9384 - val_loss: 0.1434 - val_accuracy: 0.9568\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9467 - val_loss: 0.1237 - val_accuracy: 0.9626\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9542 - val_loss: 0.1146 - val_accuracy: 0.9653\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9601 - val_loss: 0.1097 - val_accuracy: 0.9672\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9638 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9669 - val_loss: 0.0955 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9683 - val_loss: 0.0937 - val_accuracy: 0.9712\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9710 - val_loss: 0.0847 - val_accuracy: 0.9739\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9728 - val_loss: 0.0841 - val_accuracy: 0.9743\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 0.0842 - val_accuracy: 0.9739\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9754 - val_loss: 0.0818 - val_accuracy: 0.9748\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9784 - val_loss: 0.0790 - val_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0819 - val_accuracy: 0.9761\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.0838 - val_accuracy: 0.9758\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9817 - val_loss: 0.0805 - val_accuracy: 0.9769\n",
      "Epoch 19/25\n",
      "74/90 [=======================>......] - ETA: 0s - loss: 0.0524 - accuracy: 0.9821Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.0824 - val_accuracy: 0.9768\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8734 - accuracy: 0.7527 - val_loss: 0.2774 - val_accuracy: 0.9174\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8984 - val_loss: 0.2015 - val_accuracy: 0.9398\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9241 - val_loss: 0.1654 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9373 - val_loss: 0.1421 - val_accuracy: 0.9578\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9488 - val_loss: 0.1263 - val_accuracy: 0.9624\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9564 - val_loss: 0.1135 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9596 - val_loss: 0.1050 - val_accuracy: 0.9681\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9649 - val_loss: 0.0995 - val_accuracy: 0.9691\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9656 - val_loss: 0.1007 - val_accuracy: 0.9698\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9700 - val_loss: 0.0935 - val_accuracy: 0.9719\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9724 - val_loss: 0.0850 - val_accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9727 - val_loss: 0.0812 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9749 - val_loss: 0.0819 - val_accuracy: 0.9750\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9758 - val_loss: 0.0793 - val_accuracy: 0.9751\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9783 - val_loss: 0.0792 - val_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9797 - val_loss: 0.0768 - val_accuracy: 0.9768\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.0831 - val_accuracy: 0.9757\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 0.0746 - val_accuracy: 0.9788\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 0.0762 - val_accuracy: 0.9776\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 0.0742 - val_accuracy: 0.9788\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 0.0769 - val_accuracy: 0.9786\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9839 - val_loss: 0.0777 - val_accuracy: 0.9782\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.0766 - val_accuracy: 0.9794\n",
      "Epoch 24/25\n",
      "77/90 [========================>.....] - ETA: 0s - loss: 0.0397 - accuracy: 0.9872Restoring model weights from the end of the best epoch: 20.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0782 - val_accuracy: 0.9796\n",
      "Epoch 24: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8535 - accuracy: 0.7562 - val_loss: 0.2745 - val_accuracy: 0.9184\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8999 - val_loss: 0.2069 - val_accuracy: 0.9377\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9255 - val_loss: 0.1680 - val_accuracy: 0.9498\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9396 - val_loss: 0.1433 - val_accuracy: 0.9582\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9485 - val_loss: 0.1268 - val_accuracy: 0.9615\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9557 - val_loss: 0.1109 - val_accuracy: 0.9668\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9598 - val_loss: 0.1051 - val_accuracy: 0.9670\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9641 - val_loss: 0.1019 - val_accuracy: 0.9682\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.9658 - val_loss: 0.0969 - val_accuracy: 0.9704\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9703 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9727 - val_loss: 0.0864 - val_accuracy: 0.9745\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.0850 - val_accuracy: 0.9737\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9747 - val_loss: 0.0840 - val_accuracy: 0.9749\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9780 - val_loss: 0.0806 - val_accuracy: 0.9764\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 0.0835 - val_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9812 - val_loss: 0.0920 - val_accuracy: 0.9749\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 0.0821 - val_accuracy: 0.9757\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9828 - val_loss: 0.0812 - val_accuracy: 0.9775\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.0775 - val_accuracy: 0.9784\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 0.0824 - val_accuracy: 0.9773\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0747 - val_accuracy: 0.9803\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.0813 - val_accuracy: 0.9783\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9846 - val_loss: 0.0780 - val_accuracy: 0.9788\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8258 - accuracy: 0.7615 - val_loss: 0.2697 - val_accuracy: 0.9186\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.9011 - val_loss: 0.2002 - val_accuracy: 0.9384\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9279 - val_loss: 0.1653 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9392 - val_loss: 0.1415 - val_accuracy: 0.9569\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9486 - val_loss: 0.1231 - val_accuracy: 0.9626\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9552 - val_loss: 0.1115 - val_accuracy: 0.9655\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9599 - val_loss: 0.1071 - val_accuracy: 0.9678\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.0992 - val_accuracy: 0.9697\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9673 - val_loss: 0.0917 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9699 - val_loss: 0.0902 - val_accuracy: 0.9720\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9726 - val_loss: 0.0862 - val_accuracy: 0.9736\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9746 - val_loss: 0.0843 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9764 - val_loss: 0.0824 - val_accuracy: 0.9750\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 0.0823 - val_accuracy: 0.9758\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.0802 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0786 - val_accuracy: 0.9768\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.0808 - val_accuracy: 0.9761\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9821 - val_loss: 0.0779 - val_accuracy: 0.9772\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.0779 - val_accuracy: 0.9787\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.0778 - val_accuracy: 0.9787\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.0762 - val_accuracy: 0.9790\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.0764 - val_accuracy: 0.9793\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.0748 - val_accuracy: 0.9791\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.9473 - accuracy: 0.7315 - val_loss: 0.2910 - val_accuracy: 0.9120\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8926 - val_loss: 0.2028 - val_accuracy: 0.9376\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9186 - val_loss: 0.1646 - val_accuracy: 0.9500\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9337 - val_loss: 0.1438 - val_accuracy: 0.9569\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9444 - val_loss: 0.1254 - val_accuracy: 0.9623\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9499 - val_loss: 0.1152 - val_accuracy: 0.9642\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9563 - val_loss: 0.1101 - val_accuracy: 0.9660\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9601 - val_loss: 0.0965 - val_accuracy: 0.9706\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9643 - val_loss: 0.0962 - val_accuracy: 0.9694\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9662 - val_loss: 0.0949 - val_accuracy: 0.9720\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9689 - val_loss: 0.0857 - val_accuracy: 0.9726\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9718 - val_loss: 0.0830 - val_accuracy: 0.9758\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 0.0838 - val_accuracy: 0.9740\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9742 - val_loss: 0.0830 - val_accuracy: 0.9737\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9769 - val_loss: 0.0782 - val_accuracy: 0.9760\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9784 - val_loss: 0.0820 - val_accuracy: 0.9755\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9770 - val_loss: 0.0847 - val_accuracy: 0.9743\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.0798 - val_accuracy: 0.9772\n",
      "Epoch 19/25\n",
      "89/90 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9807Restoring model weights from the end of the best epoch: 15.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.0807 - val_accuracy: 0.9768\n",
      "Epoch 19: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.9127 - accuracy: 0.7389 - val_loss: 0.2879 - val_accuracy: 0.9117\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8931 - val_loss: 0.2017 - val_accuracy: 0.9388\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9208 - val_loss: 0.1659 - val_accuracy: 0.9508\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9332 - val_loss: 0.1382 - val_accuracy: 0.9577\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9458 - val_loss: 0.1270 - val_accuracy: 0.9610\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9533 - val_loss: 0.1099 - val_accuracy: 0.9664\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9556 - val_loss: 0.1073 - val_accuracy: 0.9672\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1018 - val_accuracy: 0.9678\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9646 - val_loss: 0.1007 - val_accuracy: 0.9688\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9687 - val_loss: 0.0940 - val_accuracy: 0.9710\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9705 - val_loss: 0.0856 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9718 - val_loss: 0.0826 - val_accuracy: 0.9751\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.0816 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9753 - val_loss: 0.0833 - val_accuracy: 0.9742\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9758 - val_loss: 0.0767 - val_accuracy: 0.9768\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9779 - val_loss: 0.0777 - val_accuracy: 0.9760\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9796 - val_loss: 0.0798 - val_accuracy: 0.9761\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9797 - val_loss: 0.0735 - val_accuracy: 0.9793\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9803 - val_loss: 0.0785 - val_accuracy: 0.9773\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.0741 - val_accuracy: 0.9781\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0757 - val_accuracy: 0.9787\n",
      "Epoch 22/25\n",
      "83/90 [==========================>...] - ETA: 0s - loss: 0.0518 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 18.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.0764 - val_accuracy: 0.9784\n",
      "Epoch 22: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8929 - accuracy: 0.7416 - val_loss: 0.2806 - val_accuracy: 0.9152\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8938 - val_loss: 0.2025 - val_accuracy: 0.9362\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2533 - accuracy: 0.9224 - val_loss: 0.1685 - val_accuracy: 0.9493\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9352 - val_loss: 0.1392 - val_accuracy: 0.9574\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9466 - val_loss: 0.1256 - val_accuracy: 0.9625\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9526 - val_loss: 0.1075 - val_accuracy: 0.9664\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9567 - val_loss: 0.1060 - val_accuracy: 0.9673\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9631 - val_loss: 0.1018 - val_accuracy: 0.9684\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9638 - val_loss: 0.0928 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9696 - val_loss: 0.0954 - val_accuracy: 0.9711\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9699 - val_loss: 0.0869 - val_accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9724 - val_loss: 0.0807 - val_accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9732 - val_loss: 0.0843 - val_accuracy: 0.9749\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9768 - val_loss: 0.0818 - val_accuracy: 0.9757\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 0.0826 - val_accuracy: 0.9751\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9769 - val_loss: 0.0797 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9786 - val_loss: 0.0812 - val_accuracy: 0.9758\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9792 - val_loss: 0.0829 - val_accuracy: 0.9760\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9809 - val_loss: 0.0789 - val_accuracy: 0.9763\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0743 - val_accuracy: 0.9787\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0775 - val_accuracy: 0.9775\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0748 - val_accuracy: 0.9802\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 0.0797 - val_accuracy: 0.9775\n",
      "Epoch 25/25\n",
      "85/90 [===========================>..] - ETA: 0s - loss: 0.0477 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 21.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.0796 - val_accuracy: 0.9776\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.8599 - accuracy: 0.7517 - val_loss: 0.2724 - val_accuracy: 0.9193\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8962 - val_loss: 0.2010 - val_accuracy: 0.9388\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.9220 - val_loss: 0.1648 - val_accuracy: 0.9502\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9367 - val_loss: 0.1391 - val_accuracy: 0.9570\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9460 - val_loss: 0.1245 - val_accuracy: 0.9613\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9529 - val_loss: 0.1093 - val_accuracy: 0.9661\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9575 - val_loss: 0.1058 - val_accuracy: 0.9676\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9626 - val_loss: 0.0963 - val_accuracy: 0.9693\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9656 - val_loss: 0.0917 - val_accuracy: 0.9727\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9680 - val_loss: 0.0874 - val_accuracy: 0.9743\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9697 - val_loss: 0.0870 - val_accuracy: 0.9738\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9738 - val_loss: 0.0863 - val_accuracy: 0.9749\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.0834 - val_accuracy: 0.9757\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.0805 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9773 - val_loss: 0.0835 - val_accuracy: 0.9746\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9782 - val_loss: 0.0785 - val_accuracy: 0.9776\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9791 - val_loss: 0.0816 - val_accuracy: 0.9762\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.0795 - val_accuracy: 0.9767\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9821 - val_loss: 0.0785 - val_accuracy: 0.9768\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.0761 - val_accuracy: 0.9773\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.0754 - val_accuracy: 0.9787\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.0799 - val_accuracy: 0.9774\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0760 - val_accuracy: 0.9788\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.0798 - val_accuracy: 0.9783\n",
      "Epoch 25/25\n",
      "80/90 [=========================>....] - ETA: 0s - loss: 0.0430 - accuracy: 0.9852Restoring model weights from the end of the best epoch: 21.\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.0754 - val_accuracy: 0.9798\n",
      "Epoch 25: early stopping\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7193 - accuracy: 0.7926 - val_loss: 0.2436 - val_accuracy: 0.9251\n",
      "Epoch 2/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.2662 - accuracy: 0.9194 - val_loss: 0.1761 - val_accuracy: 0.9448\n",
      "Epoch 3/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9405 - val_loss: 0.1353 - val_accuracy: 0.9592\n",
      "Epoch 4/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9532 - val_loss: 0.1136 - val_accuracy: 0.9653\n",
      "Epoch 5/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9594 - val_loss: 0.0989 - val_accuracy: 0.9695\n",
      "Epoch 6/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9664 - val_loss: 0.0907 - val_accuracy: 0.9721\n",
      "Epoch 7/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9708 - val_loss: 0.0877 - val_accuracy: 0.9726\n",
      "Epoch 8/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9723 - val_loss: 0.0778 - val_accuracy: 0.9755\n",
      "Epoch 9/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9761 - val_loss: 0.0718 - val_accuracy: 0.9773\n",
      "Epoch 10/25\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9779 - val_loss: 0.0749 - val_accuracy: 0.9775\n",
      "Epoch 11/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9799 - val_loss: 0.0770 - val_accuracy: 0.9769\n",
      "Epoch 12/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
      "Epoch 13/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9826 - val_loss: 0.0699 - val_accuracy: 0.9788\n",
      "Epoch 14/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9841 - val_loss: 0.0675 - val_accuracy: 0.9797\n",
      "Epoch 15/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9850 - val_loss: 0.0675 - val_accuracy: 0.9803\n",
      "Epoch 16/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.0713 - val_accuracy: 0.9797\n",
      "Epoch 17/25\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9864 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 18/25\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.0352 - accuracy: 0.9880Restoring model weights from the end of the best epoch: 14.\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.0735 - val_accuracy: 0.9805\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    rmsprop_grid_result = rmsprop_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39f0a810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.977354 using {'dropoutHL1': 0.5, 'dropoutHL2': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (rmsprop_grid_result.best_score_, rmsprop_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72652d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 18\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",rmsprop_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bc6db",
   "metadata": {},
   "source": [
    "### model dropout with 'SGD' optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07cea6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor = \"val_loss\",\n",
    "                                patience = 4,\n",
    "                                mode = 'auto',\n",
    "                                restore_best_weights = True,\n",
    "                                verbose = 1)\n",
    "\n",
    "sgd_estimator = KerasClassifier(\n",
    "    model,\n",
    "    unitsHL1=750,\n",
    "    unitsHL2=200,\n",
    "    dropoutHL1 = 0,\n",
    "    dropoutHL2 = 0,\n",
    "    optimizer_learning_rate=0.002,\n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer='SGD',\n",
    "    callbacks=[earlystopping],\n",
    "    epochs=25,\n",
    "    batch_size=375,\n",
    ")\n",
    "sgd_param_grid = {\n",
    "    #'optimizer_learning_rate':[0.001,0.0015,0.002],\n",
    "    #'batch_size':[200,300,400],\n",
    "    'dropoutHL1':[0.0,0.1,0,0.2],\n",
    "    'dropoutHL2':[0.0,0.1,0.2],\n",
    "}\n",
    "sgd_grid = GridSearchCV(\n",
    "    estimator=sgd_estimator, \n",
    "    param_grid=sgd_param_grid,\n",
    "    cv=4, # cross-validation default 5-fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a134cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8991 - accuracy: 0.7941 - val_loss: 0.2774 - val_accuracy: 0.9193\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9282 - val_loss: 0.2123 - val_accuracy: 0.9379\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9478 - val_loss: 0.1732 - val_accuracy: 0.9513\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9614 - val_loss: 0.1401 - val_accuracy: 0.9598\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9712 - val_loss: 0.1215 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9769 - val_loss: 0.1081 - val_accuracy: 0.9690\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9817 - val_loss: 0.1059 - val_accuracy: 0.9673\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.0964 - val_accuracy: 0.9703\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.1100 - val_accuracy: 0.9673\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0949 - val_accuracy: 0.9715\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 0.0907 - val_accuracy: 0.9736\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.0884 - val_accuracy: 0.9748\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0921 - val_accuracy: 0.9742\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0919 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "79/96 [=======================>......] - ETA: 0s - loss: 0.0065 - accuracy: 0.9991Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0943 - val_accuracy: 0.9747\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9128 - accuracy: 0.7866 - val_loss: 0.2775 - val_accuracy: 0.9178\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9302 - val_loss: 0.2123 - val_accuracy: 0.9379\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9491 - val_loss: 0.1777 - val_accuracy: 0.9489\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9601 - val_loss: 0.1390 - val_accuracy: 0.9595\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9700 - val_loss: 0.1219 - val_accuracy: 0.9644\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9774 - val_loss: 0.1121 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9820 - val_loss: 0.1010 - val_accuracy: 0.9698\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9868 - val_loss: 0.0985 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9899 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9916 - val_loss: 0.0971 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0942 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0909 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0900 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0900 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0921 - val_accuracy: 0.9750\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0924 - val_accuracy: 0.9765\n",
      "Epoch 18/25\n",
      "81/96 [========================>.....] - ETA: 0s - loss: 0.0033 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 14.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0937 - val_accuracy: 0.9766\n",
      "Epoch 18: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8484 - accuracy: 0.8004 - val_loss: 0.2714 - val_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9313 - val_loss: 0.2128 - val_accuracy: 0.9375\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9508 - val_loss: 0.1840 - val_accuracy: 0.9453\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9614 - val_loss: 0.1389 - val_accuracy: 0.9586\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9693 - val_loss: 0.1212 - val_accuracy: 0.9638\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9767 - val_loss: 0.1104 - val_accuracy: 0.9673\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.1075 - val_accuracy: 0.9674\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9870 - val_loss: 0.0974 - val_accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.1003 - val_accuracy: 0.9693\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0945 - val_accuracy: 0.9712\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.0955 - val_accuracy: 0.9726\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.1005 - val_accuracy: 0.9709\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0972 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "81/96 [========================>.....] - ETA: 0s - loss: 0.0113 - accuracy: 0.9976Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0970 - val_accuracy: 0.9726\n",
      "Epoch 14: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8750 - accuracy: 0.7933 - val_loss: 0.2762 - val_accuracy: 0.9202\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9317 - val_loss: 0.2141 - val_accuracy: 0.9360\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9499 - val_loss: 0.1687 - val_accuracy: 0.9518\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9626 - val_loss: 0.1479 - val_accuracy: 0.9560\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9703 - val_loss: 0.1240 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.1116 - val_accuracy: 0.9669\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.1067 - val_accuracy: 0.9688\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9873 - val_loss: 0.0985 - val_accuracy: 0.9720\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9904 - val_loss: 0.0933 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9929 - val_loss: 0.0936 - val_accuracy: 0.9725\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0940 - val_accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 13/25\n",
      "83/96 [========================>.....] - ETA: 0s - loss: 0.0146 - accuracy: 0.9970Restoring model weights from the end of the best epoch: 9.\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1086 - val_accuracy: 0.9706\n",
      "Epoch 13: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9158 - accuracy: 0.7811 - val_loss: 0.2817 - val_accuracy: 0.9167\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9215 - val_loss: 0.2049 - val_accuracy: 0.9396\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9434 - val_loss: 0.1715 - val_accuracy: 0.9507\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9567 - val_loss: 0.1366 - val_accuracy: 0.9592\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9661 - val_loss: 0.1189 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9726 - val_loss: 0.1082 - val_accuracy: 0.9676\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9786 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9828 - val_loss: 0.0923 - val_accuracy: 0.9703\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.1001 - val_accuracy: 0.9695\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.0875 - val_accuracy: 0.9732\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0813 - val_accuracy: 0.9760\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0848 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0843 - val_accuracy: 0.9768\n",
      "Epoch 16/25\n",
      "92/96 [===========================>..] - ETA: 0s - loss: 0.0130 - accuracy: 0.9965Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0830 - val_accuracy: 0.9768\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9140 - accuracy: 0.7811 - val_loss: 0.2703 - val_accuracy: 0.9190\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9256 - val_loss: 0.2006 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9461 - val_loss: 0.1680 - val_accuracy: 0.9509\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9573 - val_loss: 0.1366 - val_accuracy: 0.9589\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9675 - val_loss: 0.1188 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9732 - val_loss: 0.1103 - val_accuracy: 0.9647\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 0.1007 - val_accuracy: 0.9678\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0920 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 0.0986 - val_accuracy: 0.9693\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.0932 - val_accuracy: 0.9713\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0860 - val_accuracy: 0.9749\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0931 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0869 - val_accuracy: 0.9749\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.0882 - val_accuracy: 0.9752\n",
      "Epoch 16/25\n",
      "90/96 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 0.9978Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8462 - accuracy: 0.7931 - val_loss: 0.2696 - val_accuracy: 0.9211\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9237 - val_loss: 0.2109 - val_accuracy: 0.9371\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.9449 - val_loss: 0.1672 - val_accuracy: 0.9507\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9566 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9656 - val_loss: 0.1199 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9727 - val_loss: 0.1059 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9783 - val_loss: 0.1000 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.0916 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9859 - val_loss: 0.0936 - val_accuracy: 0.9700\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.0874 - val_accuracy: 0.9737\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.0857 - val_accuracy: 0.9748\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0854 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0860 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0850 - val_accuracy: 0.9768\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0902 - val_accuracy: 0.9742\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0933 - val_accuracy: 0.9762\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0898 - val_accuracy: 0.9755\n",
      "Epoch 20/25\n",
      "77/96 [=======================>......] - ETA: 0s - loss: 0.0064 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 16.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0897 - val_accuracy: 0.9759\n",
      "Epoch 20: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8409 - accuracy: 0.7893 - val_loss: 0.2701 - val_accuracy: 0.9203\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9256 - val_loss: 0.2020 - val_accuracy: 0.9407\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9467 - val_loss: 0.1656 - val_accuracy: 0.9504\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9597 - val_loss: 0.1407 - val_accuracy: 0.9575\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9677 - val_loss: 0.1208 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9731 - val_loss: 0.1067 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9793 - val_loss: 0.1033 - val_accuracy: 0.9696\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0972 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.0927 - val_accuracy: 0.9713\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0943 - val_accuracy: 0.9710\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.0892 - val_accuracy: 0.9730\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0886 - val_accuracy: 0.9740\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.0901 - val_accuracy: 0.9739\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0953 - val_accuracy: 0.9723\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0941 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "79/96 [=======================>......] - ETA: 0s - loss: 0.0100 - accuracy: 0.9976Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0941 - val_accuracy: 0.9747\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9012 - accuracy: 0.7759 - val_loss: 0.2744 - val_accuracy: 0.9182\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9200 - val_loss: 0.1984 - val_accuracy: 0.9406\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9408 - val_loss: 0.1640 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9533 - val_loss: 0.1309 - val_accuracy: 0.9606\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9636 - val_loss: 0.1163 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9698 - val_loss: 0.1090 - val_accuracy: 0.9650\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9756 - val_loss: 0.0958 - val_accuracy: 0.9693\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9798 - val_loss: 0.0919 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9834 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0869 - val_accuracy: 0.9733\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.0859 - val_accuracy: 0.9733\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.0815 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0859 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0846 - val_accuracy: 0.9765\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0828 - val_accuracy: 0.9767\n",
      "Epoch 16/25\n",
      "81/96 [========================>.....] - ETA: 0s - loss: 0.0175 - accuracy: 0.9952Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0833 - val_accuracy: 0.9764\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9016 - accuracy: 0.7767 - val_loss: 0.2697 - val_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9224 - val_loss: 0.1984 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9433 - val_loss: 0.1594 - val_accuracy: 0.9546\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9556 - val_loss: 0.1337 - val_accuracy: 0.9597\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9646 - val_loss: 0.1132 - val_accuracy: 0.9663\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0935 - accuracy: 0.9718 - val_loss: 0.1061 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0979 - val_accuracy: 0.9691\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9815 - val_loss: 0.0903 - val_accuracy: 0.9717\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.0860 - val_accuracy: 0.9737\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0868 - val_accuracy: 0.9748\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0834 - val_accuracy: 0.9745\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0931 - val_accuracy: 0.9742\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0855 - val_accuracy: 0.9759\n",
      "Epoch 16/25\n",
      "92/96 [===========================>..] - ETA: 0s - loss: 0.0169 - accuracy: 0.9947Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0888 - val_accuracy: 0.9752\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8494 - accuracy: 0.7899 - val_loss: 0.2775 - val_accuracy: 0.9178\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9196 - val_loss: 0.2117 - val_accuracy: 0.9364\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9410 - val_loss: 0.1687 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9543 - val_loss: 0.1390 - val_accuracy: 0.9584\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9621 - val_loss: 0.1213 - val_accuracy: 0.9623\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9695 - val_loss: 0.1054 - val_accuracy: 0.9678\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9753 - val_loss: 0.0976 - val_accuracy: 0.9690\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.0918 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0913 - val_accuracy: 0.9721\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0843 - val_accuracy: 0.9757\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0838 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0838 - val_accuracy: 0.9754\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 0.0841 - val_accuracy: 0.9762\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0855 - val_accuracy: 0.9765\n",
      "Epoch 16/25\n",
      "78/96 [=======================>......] - ETA: 0s - loss: 0.0141 - accuracy: 0.9959Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0857 - val_accuracy: 0.9765\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8117 - accuracy: 0.7926 - val_loss: 0.2666 - val_accuracy: 0.9232\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9226 - val_loss: 0.1959 - val_accuracy: 0.9418\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9430 - val_loss: 0.1630 - val_accuracy: 0.9505\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9579 - val_loss: 0.1361 - val_accuracy: 0.9582\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9654 - val_loss: 0.1133 - val_accuracy: 0.9652\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9723 - val_loss: 0.1053 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9783 - val_loss: 0.0955 - val_accuracy: 0.9715\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0920 - val_accuracy: 0.9734\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0866 - val_accuracy: 0.9732\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.0873 - val_accuracy: 0.9744\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.0860 - val_accuracy: 0.9740\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0896 - val_accuracy: 0.9740\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0954 - val_accuracy: 0.9736\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0950 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "78/96 [=======================>......] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0890 - val_accuracy: 0.9769\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9249 - accuracy: 0.7846 - val_loss: 0.2733 - val_accuracy: 0.9183\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.9260 - val_loss: 0.2095 - val_accuracy: 0.9365\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9467 - val_loss: 0.1681 - val_accuracy: 0.9523\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9599 - val_loss: 0.1348 - val_accuracy: 0.9594\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9688 - val_loss: 0.1210 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9741 - val_loss: 0.1084 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9794 - val_loss: 0.1017 - val_accuracy: 0.9698\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9844 - val_loss: 0.0929 - val_accuracy: 0.9722\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0997 - val_accuracy: 0.9698\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.0905 - val_accuracy: 0.9724\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0863 - val_accuracy: 0.9763\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0851 - val_accuracy: 0.9762\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.0871 - val_accuracy: 0.9768\n",
      "Epoch 15/25\n",
      "87/96 [==========================>...] - ETA: 0s - loss: 0.0136 - accuracy: 0.9966Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0850 - val_accuracy: 0.9771\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9179 - accuracy: 0.7873 - val_loss: 0.2728 - val_accuracy: 0.9202\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9286 - val_loss: 0.2009 - val_accuracy: 0.9422\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9484 - val_loss: 0.1678 - val_accuracy: 0.9507\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9605 - val_loss: 0.1342 - val_accuracy: 0.9612\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9693 - val_loss: 0.1201 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 0.1088 - val_accuracy: 0.9664\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9809 - val_loss: 0.0977 - val_accuracy: 0.9705\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9842 - val_loss: 0.0930 - val_accuracy: 0.9723\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.0931 - val_accuracy: 0.9707\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0936 - val_accuracy: 0.9726\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.0899 - val_accuracy: 0.9744\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0903 - val_accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0941 - val_accuracy: 0.9745\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0906 - val_accuracy: 0.9748\n",
      "Epoch 15/25\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9970Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0904 - val_accuracy: 0.9765\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8880 - accuracy: 0.7934 - val_loss: 0.2761 - val_accuracy: 0.9179\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9278 - val_loss: 0.2097 - val_accuracy: 0.9383\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.9486 - val_loss: 0.1637 - val_accuracy: 0.9523\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9606 - val_loss: 0.1381 - val_accuracy: 0.9597\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9674 - val_loss: 0.1237 - val_accuracy: 0.9649\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9800 - val_loss: 0.0993 - val_accuracy: 0.9700\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9847 - val_loss: 0.0932 - val_accuracy: 0.9742\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 0.1006 - val_accuracy: 0.9690\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0921 - val_accuracy: 0.9726\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.0908 - val_accuracy: 0.9736\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0973 - val_accuracy: 0.9718\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.0922 - val_accuracy: 0.9735\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0939 - val_accuracy: 0.9739\n",
      "Epoch 15/25\n",
      "92/96 [===========================>..] - ETA: 0s - loss: 0.0146 - accuracy: 0.9962Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.1020 - val_accuracy: 0.9732\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8927 - accuracy: 0.7887 - val_loss: 0.2702 - val_accuracy: 0.9210\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2390 - accuracy: 0.9304 - val_loss: 0.2017 - val_accuracy: 0.9423\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9491 - val_loss: 0.1643 - val_accuracy: 0.9528\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9615 - val_loss: 0.1433 - val_accuracy: 0.9576\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9693 - val_loss: 0.1177 - val_accuracy: 0.9661\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9753 - val_loss: 0.1061 - val_accuracy: 0.9678\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9802 - val_loss: 0.1011 - val_accuracy: 0.9700\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.0972 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0895 - val_accuracy: 0.9719\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9919 - val_loss: 0.0865 - val_accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0934 - val_accuracy: 0.9720\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0967 - val_accuracy: 0.9722\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.0936 - val_accuracy: 0.9741\n",
      "Epoch 15/25\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9951Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0947 - val_accuracy: 0.9754\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9247 - accuracy: 0.7712 - val_loss: 0.2752 - val_accuracy: 0.9167\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.9214 - val_loss: 0.1971 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9439 - val_loss: 0.1624 - val_accuracy: 0.9530\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9574 - val_loss: 0.1301 - val_accuracy: 0.9611\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9647 - val_loss: 0.1158 - val_accuracy: 0.9645\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9715 - val_loss: 0.1001 - val_accuracy: 0.9702\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9766 - val_loss: 0.0939 - val_accuracy: 0.9716\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.0865 - val_accuracy: 0.9739\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.0969 - val_accuracy: 0.9701\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0828 - val_accuracy: 0.9747\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0829 - val_accuracy: 0.9753\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0809 - val_accuracy: 0.9774\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.0844 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.0826 - val_accuracy: 0.9766\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.0821 - val_accuracy: 0.9775\n",
      "Epoch 16/25\n",
      "93/96 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9945Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0843 - val_accuracy: 0.9770\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9285 - accuracy: 0.7762 - val_loss: 0.2757 - val_accuracy: 0.9190\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9216 - val_loss: 0.2002 - val_accuracy: 0.9409\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9439 - val_loss: 0.1591 - val_accuracy: 0.9543\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9562 - val_loss: 0.1365 - val_accuracy: 0.9595\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9654 - val_loss: 0.1175 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9717 - val_loss: 0.1058 - val_accuracy: 0.9679\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9760 - val_loss: 0.1036 - val_accuracy: 0.9678\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.0895 - val_accuracy: 0.9725\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.0915 - val_accuracy: 0.9720\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0876 - val_accuracy: 0.9736\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0817 - val_accuracy: 0.9759\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.0815 - val_accuracy: 0.9751\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0855 - val_accuracy: 0.9757\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0829 - val_accuracy: 0.9765\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0890 - val_accuracy: 0.9762\n",
      "Epoch 16/25\n",
      "89/96 [==========================>...] - ETA: 0s - loss: 0.0196 - accuracy: 0.9936Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0815 - val_accuracy: 0.9772\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8513 - accuracy: 0.7916 - val_loss: 0.2634 - val_accuracy: 0.9211\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9241 - val_loss: 0.1980 - val_accuracy: 0.9410\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9459 - val_loss: 0.1609 - val_accuracy: 0.9521\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9579 - val_loss: 0.1323 - val_accuracy: 0.9613\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9646 - val_loss: 0.1156 - val_accuracy: 0.9660\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9724 - val_loss: 0.1018 - val_accuracy: 0.9691\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9779 - val_loss: 0.0985 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9809 - val_loss: 0.0917 - val_accuracy: 0.9732\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.0894 - val_accuracy: 0.9722\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0876 - val_accuracy: 0.9728\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0851 - val_accuracy: 0.9752\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0868 - val_accuracy: 0.9768\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0900 - val_accuracy: 0.9747\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "91/96 [===========================>..] - ETA: 0s - loss: 0.0190 - accuracy: 0.9943Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0868 - val_accuracy: 0.9762\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.8704 - accuracy: 0.7877 - val_loss: 0.2669 - val_accuracy: 0.9204\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9246 - val_loss: 0.1937 - val_accuracy: 0.9438\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9459 - val_loss: 0.1548 - val_accuracy: 0.9542\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1395 - accuracy: 0.9585 - val_loss: 0.1383 - val_accuracy: 0.9578\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9654 - val_loss: 0.1122 - val_accuracy: 0.9667\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9730 - val_loss: 0.1036 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9781 - val_loss: 0.1000 - val_accuracy: 0.9704\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.0923 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0884 - val_accuracy: 0.9728\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.0901 - val_accuracy: 0.9739\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0859 - val_accuracy: 0.9755\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.0836 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0858 - val_accuracy: 0.9754\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0861 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0887 - val_accuracy: 0.9768\n",
      "Epoch 16/25\n",
      "84/96 [=========================>....] - ETA: 0s - loss: 0.0158 - accuracy: 0.9953Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0854 - val_accuracy: 0.9780\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9349 - accuracy: 0.7657 - val_loss: 0.2791 - val_accuracy: 0.9162\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.9159 - val_loss: 0.2009 - val_accuracy: 0.9402\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9396 - val_loss: 0.1601 - val_accuracy: 0.9523\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9531 - val_loss: 0.1291 - val_accuracy: 0.9615\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9621 - val_loss: 0.1175 - val_accuracy: 0.9634\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9681 - val_loss: 0.1010 - val_accuracy: 0.9679\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9736 - val_loss: 0.0911 - val_accuracy: 0.9722\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9788 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.0919 - val_accuracy: 0.9714\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.0819 - val_accuracy: 0.9758\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0832 - val_accuracy: 0.9758\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0845 - val_accuracy: 0.9766\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0806 - val_accuracy: 0.9767\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0790 - val_accuracy: 0.9783\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0826 - val_accuracy: 0.9771\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0852 - val_accuracy: 0.9777\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0888 - val_accuracy: 0.9762\n",
      "Epoch 19/25\n",
      "88/96 [==========================>...] - ETA: 0s - loss: 0.0159 - accuracy: 0.9948Restoring model weights from the end of the best epoch: 15.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
      "Epoch 19: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9519 - accuracy: 0.7631 - val_loss: 0.2776 - val_accuracy: 0.9183\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9144 - val_loss: 0.1948 - val_accuracy: 0.9420\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9403 - val_loss: 0.1591 - val_accuracy: 0.9546\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9526 - val_loss: 0.1349 - val_accuracy: 0.9608\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9618 - val_loss: 0.1161 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 0.9681 - val_loss: 0.1042 - val_accuracy: 0.9674\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9738 - val_loss: 0.1019 - val_accuracy: 0.9688\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 0.0868 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.0913 - val_accuracy: 0.9715\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0840 - val_accuracy: 0.9746\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.0831 - val_accuracy: 0.9747\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0802 - val_accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0829 - val_accuracy: 0.9758\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0791 - val_accuracy: 0.9789\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0792 - val_accuracy: 0.9772\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0859 - val_accuracy: 0.9768\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0839 - val_accuracy: 0.9783\n",
      "Epoch 19/25\n",
      "84/96 [=========================>....] - ETA: 0s - loss: 0.0162 - accuracy: 0.9950Restoring model weights from the end of the best epoch: 15.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0877 - val_accuracy: 0.9768\n",
      "Epoch 19: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8793 - accuracy: 0.7759 - val_loss: 0.2629 - val_accuracy: 0.9198\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9190 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9410 - val_loss: 0.1587 - val_accuracy: 0.9529\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9540 - val_loss: 0.1343 - val_accuracy: 0.9605\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9627 - val_loss: 0.1145 - val_accuracy: 0.9652\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9683 - val_loss: 0.1018 - val_accuracy: 0.9682\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9748 - val_loss: 0.0954 - val_accuracy: 0.9712\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9776 - val_loss: 0.0928 - val_accuracy: 0.9727\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.0883 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0867 - val_accuracy: 0.9744\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0806 - val_accuracy: 0.9767\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0873 - val_accuracy: 0.9758\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0909 - val_accuracy: 0.9754\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0840 - val_accuracy: 0.9757\n",
      "Epoch 15/25\n",
      "82/96 [========================>.....] - ETA: 0s - loss: 0.0245 - accuracy: 0.9920Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0859 - val_accuracy: 0.9768\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8789 - accuracy: 0.7779 - val_loss: 0.2661 - val_accuracy: 0.9198\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.9197 - val_loss: 0.1945 - val_accuracy: 0.9422\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9433 - val_loss: 0.1557 - val_accuracy: 0.9537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9544 - val_loss: 0.1375 - val_accuracy: 0.9575\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9632 - val_loss: 0.1127 - val_accuracy: 0.9668\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9711 - val_loss: 0.1020 - val_accuracy: 0.9689\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9759 - val_loss: 0.0979 - val_accuracy: 0.9703\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.0922 - val_accuracy: 0.9713\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.0862 - val_accuracy: 0.9723\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.0934 - val_accuracy: 0.9724\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0867 - val_accuracy: 0.9752\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0873 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.0902 - val_accuracy: 0.9748\n",
      "Epoch 15/25\n",
      "91/96 [===========================>..] - ETA: 0s - loss: 0.0244 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8991 - accuracy: 0.7941 - val_loss: 0.2774 - val_accuracy: 0.9193\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9282 - val_loss: 0.2123 - val_accuracy: 0.9379\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9478 - val_loss: 0.1732 - val_accuracy: 0.9513\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9614 - val_loss: 0.1401 - val_accuracy: 0.9598\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9712 - val_loss: 0.1215 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9769 - val_loss: 0.1081 - val_accuracy: 0.9690\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9817 - val_loss: 0.1059 - val_accuracy: 0.9673\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.0964 - val_accuracy: 0.9703\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.1100 - val_accuracy: 0.9673\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0949 - val_accuracy: 0.9715\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 0.0907 - val_accuracy: 0.9736\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.0884 - val_accuracy: 0.9748\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0921 - val_accuracy: 0.9742\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0919 - val_accuracy: 0.9758\n",
      "Epoch 16/25\n",
      "80/96 [========================>.....] - ETA: 0s - loss: 0.0065 - accuracy: 0.9990Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0943 - val_accuracy: 0.9747\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9128 - accuracy: 0.7866 - val_loss: 0.2775 - val_accuracy: 0.9178\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9302 - val_loss: 0.2123 - val_accuracy: 0.9379\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9491 - val_loss: 0.1777 - val_accuracy: 0.9489\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9601 - val_loss: 0.1390 - val_accuracy: 0.9595\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9700 - val_loss: 0.1219 - val_accuracy: 0.9644\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9774 - val_loss: 0.1121 - val_accuracy: 0.9663\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9820 - val_loss: 0.1010 - val_accuracy: 0.9698\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9868 - val_loss: 0.0985 - val_accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9899 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9916 - val_loss: 0.0971 - val_accuracy: 0.9703\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.0942 - val_accuracy: 0.9716\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0909 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0900 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0900 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0921 - val_accuracy: 0.9750\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0924 - val_accuracy: 0.9765\n",
      "Epoch 18/25\n",
      "83/96 [========================>.....] - ETA: 0s - loss: 0.0033 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 14.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0937 - val_accuracy: 0.9766\n",
      "Epoch 18: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.8484 - accuracy: 0.8004 - val_loss: 0.2714 - val_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9313 - val_loss: 0.2128 - val_accuracy: 0.9375\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9508 - val_loss: 0.1840 - val_accuracy: 0.9453\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9614 - val_loss: 0.1389 - val_accuracy: 0.9586\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9693 - val_loss: 0.1212 - val_accuracy: 0.9638\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9767 - val_loss: 0.1104 - val_accuracy: 0.9673\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.1075 - val_accuracy: 0.9674\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9870 - val_loss: 0.0974 - val_accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.1003 - val_accuracy: 0.9693\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0945 - val_accuracy: 0.9712\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.0955 - val_accuracy: 0.9726\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.1005 - val_accuracy: 0.9709\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0972 - val_accuracy: 0.9736\n",
      "Epoch 14/25\n",
      "90/96 [===========================>..] - ETA: 0s - loss: 0.0113 - accuracy: 0.9976Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0970 - val_accuracy: 0.9726\n",
      "Epoch 14: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8750 - accuracy: 0.7933 - val_loss: 0.2762 - val_accuracy: 0.9202\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9317 - val_loss: 0.2141 - val_accuracy: 0.9360\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9499 - val_loss: 0.1687 - val_accuracy: 0.9518\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9626 - val_loss: 0.1479 - val_accuracy: 0.9560\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9703 - val_loss: 0.1240 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.1116 - val_accuracy: 0.9669\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.1067 - val_accuracy: 0.9688\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9873 - val_loss: 0.0985 - val_accuracy: 0.9720\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9904 - val_loss: 0.0933 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9929 - val_loss: 0.0936 - val_accuracy: 0.9725\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.0940 - val_accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 13/25\n",
      "81/96 [========================>.....] - ETA: 0s - loss: 0.0146 - accuracy: 0.9970Restoring model weights from the end of the best epoch: 9.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1086 - val_accuracy: 0.9706\n",
      "Epoch 13: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.9158 - accuracy: 0.7811 - val_loss: 0.2817 - val_accuracy: 0.9167\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9215 - val_loss: 0.2049 - val_accuracy: 0.9396\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.9434 - val_loss: 0.1715 - val_accuracy: 0.9507\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9567 - val_loss: 0.1366 - val_accuracy: 0.9592\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9661 - val_loss: 0.1189 - val_accuracy: 0.9640\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9726 - val_loss: 0.1082 - val_accuracy: 0.9676\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9786 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9828 - val_loss: 0.0923 - val_accuracy: 0.9703\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.1001 - val_accuracy: 0.9695\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.0875 - val_accuracy: 0.9732\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0813 - val_accuracy: 0.9760\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.0864 - val_accuracy: 0.9753\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0848 - val_accuracy: 0.9753\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0843 - val_accuracy: 0.9768\n",
      "Epoch 16/25\n",
      "93/96 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9964Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0830 - val_accuracy: 0.9768\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9140 - accuracy: 0.7811 - val_loss: 0.2703 - val_accuracy: 0.9190\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9256 - val_loss: 0.2006 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9461 - val_loss: 0.1680 - val_accuracy: 0.9509\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9573 - val_loss: 0.1366 - val_accuracy: 0.9589\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9675 - val_loss: 0.1188 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9732 - val_loss: 0.1103 - val_accuracy: 0.9647\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 0.1007 - val_accuracy: 0.9678\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0920 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 0.0986 - val_accuracy: 0.9693\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.0932 - val_accuracy: 0.9713\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0860 - val_accuracy: 0.9749\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0931 - val_accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0869 - val_accuracy: 0.9749\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.0882 - val_accuracy: 0.9752\n",
      "Epoch 16/25\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9978Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8462 - accuracy: 0.7931 - val_loss: 0.2696 - val_accuracy: 0.9211\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9237 - val_loss: 0.2109 - val_accuracy: 0.9371\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.9449 - val_loss: 0.1672 - val_accuracy: 0.9507\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9566 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9656 - val_loss: 0.1199 - val_accuracy: 0.9647\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9727 - val_loss: 0.1059 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9783 - val_loss: 0.1000 - val_accuracy: 0.9697\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.0916 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9859 - val_loss: 0.0936 - val_accuracy: 0.9700\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.0874 - val_accuracy: 0.9737\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.0857 - val_accuracy: 0.9748\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0854 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0856 - val_accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0850 - val_accuracy: 0.9768\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0902 - val_accuracy: 0.9742\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0933 - val_accuracy: 0.9762\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0898 - val_accuracy: 0.9755\n",
      "Epoch 20/25\n",
      "91/96 [===========================>..] - ETA: 0s - loss: 0.0063 - accuracy: 0.9988Restoring model weights from the end of the best epoch: 16.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0897 - val_accuracy: 0.9759\n",
      "Epoch 20: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8409 - accuracy: 0.7893 - val_loss: 0.2701 - val_accuracy: 0.9203\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9256 - val_loss: 0.2020 - val_accuracy: 0.9407\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9467 - val_loss: 0.1656 - val_accuracy: 0.9504\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9597 - val_loss: 0.1407 - val_accuracy: 0.9575\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9677 - val_loss: 0.1208 - val_accuracy: 0.9642\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9731 - val_loss: 0.1067 - val_accuracy: 0.9672\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9793 - val_loss: 0.1033 - val_accuracy: 0.9696\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0972 - val_accuracy: 0.9719\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.0927 - val_accuracy: 0.9713\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0943 - val_accuracy: 0.9710\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.0892 - val_accuracy: 0.9730\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0886 - val_accuracy: 0.9740\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.0901 - val_accuracy: 0.9739\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0953 - val_accuracy: 0.9723\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0941 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "78/96 [=======================>......] - ETA: 0s - loss: 0.0099 - accuracy: 0.9977Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0941 - val_accuracy: 0.9747\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9012 - accuracy: 0.7759 - val_loss: 0.2744 - val_accuracy: 0.9182\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9200 - val_loss: 0.1984 - val_accuracy: 0.9406\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9408 - val_loss: 0.1640 - val_accuracy: 0.9517\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9533 - val_loss: 0.1309 - val_accuracy: 0.9606\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9636 - val_loss: 0.1163 - val_accuracy: 0.9637\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9698 - val_loss: 0.1090 - val_accuracy: 0.9650\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9756 - val_loss: 0.0958 - val_accuracy: 0.9693\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9798 - val_loss: 0.0919 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9834 - val_loss: 0.0939 - val_accuracy: 0.9708\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0869 - val_accuracy: 0.9733\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.0859 - val_accuracy: 0.9733\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.0815 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0859 - val_accuracy: 0.9751\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0846 - val_accuracy: 0.9765\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0828 - val_accuracy: 0.9767\n",
      "Epoch 16/25\n",
      "77/96 [=======================>......] - ETA: 0s - loss: 0.0168 - accuracy: 0.9955Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0833 - val_accuracy: 0.9764\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9016 - accuracy: 0.7767 - val_loss: 0.2697 - val_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9224 - val_loss: 0.1984 - val_accuracy: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9433 - val_loss: 0.1594 - val_accuracy: 0.9546\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9556 - val_loss: 0.1337 - val_accuracy: 0.9597\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9646 - val_loss: 0.1132 - val_accuracy: 0.9663\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0935 - accuracy: 0.9718 - val_loss: 0.1061 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9765 - val_loss: 0.0979 - val_accuracy: 0.9691\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9815 - val_loss: 0.0903 - val_accuracy: 0.9717\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.0860 - val_accuracy: 0.9737\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0868 - val_accuracy: 0.9748\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0834 - val_accuracy: 0.9745\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0931 - val_accuracy: 0.9742\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0855 - val_accuracy: 0.9759\n",
      "Epoch 16/25\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9946Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0888 - val_accuracy: 0.9752\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8494 - accuracy: 0.7899 - val_loss: 0.2775 - val_accuracy: 0.9178\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9196 - val_loss: 0.2117 - val_accuracy: 0.9364\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9410 - val_loss: 0.1687 - val_accuracy: 0.9503\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9543 - val_loss: 0.1390 - val_accuracy: 0.9584\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9621 - val_loss: 0.1213 - val_accuracy: 0.9623\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9695 - val_loss: 0.1054 - val_accuracy: 0.9678\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9753 - val_loss: 0.0976 - val_accuracy: 0.9690\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.0918 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0913 - val_accuracy: 0.9721\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0843 - val_accuracy: 0.9757\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.0838 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0838 - val_accuracy: 0.9754\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 0.0841 - val_accuracy: 0.9762\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0855 - val_accuracy: 0.9765\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9952Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0857 - val_accuracy: 0.9765\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8117 - accuracy: 0.7926 - val_loss: 0.2666 - val_accuracy: 0.9232\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9226 - val_loss: 0.1959 - val_accuracy: 0.9418\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9430 - val_loss: 0.1630 - val_accuracy: 0.9505\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9579 - val_loss: 0.1361 - val_accuracy: 0.9582\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9654 - val_loss: 0.1133 - val_accuracy: 0.9652\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9723 - val_loss: 0.1053 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9783 - val_loss: 0.0955 - val_accuracy: 0.9715\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0920 - val_accuracy: 0.9734\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0866 - val_accuracy: 0.9732\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.0873 - val_accuracy: 0.9744\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.0860 - val_accuracy: 0.9740\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0896 - val_accuracy: 0.9740\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0954 - val_accuracy: 0.9736\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0950 - val_accuracy: 0.9738\n",
      "Epoch 16/25\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9965Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0890 - val_accuracy: 0.9769\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8763 - accuracy: 0.7905 - val_loss: 0.2653 - val_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9274 - val_loss: 0.1963 - val_accuracy: 0.9416\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9481 - val_loss: 0.1561 - val_accuracy: 0.9553\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9624 - val_loss: 0.1272 - val_accuracy: 0.9617\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9685 - val_loss: 0.1123 - val_accuracy: 0.9657\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9759 - val_loss: 0.1030 - val_accuracy: 0.9691\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9789 - val_loss: 0.0946 - val_accuracy: 0.9713\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.0879 - val_accuracy: 0.9739\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9870 - val_loss: 0.1022 - val_accuracy: 0.9690\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.0853 - val_accuracy: 0.9744\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.0821 - val_accuracy: 0.9766\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0831 - val_accuracy: 0.9775\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0856 - val_accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0859 - val_accuracy: 0.9760\n",
      "Epoch 15/25\n",
      "78/96 [=======================>......] - ETA: 0s - loss: 0.0169 - accuracy: 0.9947Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0914 - val_accuracy: 0.9762\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9248 - accuracy: 0.7804 - val_loss: 0.2754 - val_accuracy: 0.9195\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.9250 - val_loss: 0.2039 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9461 - val_loss: 0.1674 - val_accuracy: 0.9521\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9583 - val_loss: 0.1335 - val_accuracy: 0.9609\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.9673 - val_loss: 0.1218 - val_accuracy: 0.9638\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9734 - val_loss: 0.1057 - val_accuracy: 0.9677\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9775 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9824 - val_loss: 0.0918 - val_accuracy: 0.9723\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 0.0903 - val_accuracy: 0.9730\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0895 - val_accuracy: 0.9739\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0845 - val_accuracy: 0.9754\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0840 - val_accuracy: 0.9752\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0874 - val_accuracy: 0.9757\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0862 - val_accuracy: 0.9758\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0882 - val_accuracy: 0.9760\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0840 - val_accuracy: 0.9773\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0863 - val_accuracy: 0.9769\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0818 - val_accuracy: 0.9788\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0923 - val_accuracy: 0.9781\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0957 - val_accuracy: 0.9750\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0918 - val_accuracy: 0.9775\n",
      "Epoch 22/25\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9965Restoring model weights from the end of the best epoch: 18.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0925 - val_accuracy: 0.9774\n",
      "Epoch 22: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8855 - accuracy: 0.7891 - val_loss: 0.2658 - val_accuracy: 0.9199\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9259 - val_loss: 0.2061 - val_accuracy: 0.9388\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.9474 - val_loss: 0.1621 - val_accuracy: 0.9532\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9595 - val_loss: 0.1340 - val_accuracy: 0.9603\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9668 - val_loss: 0.1191 - val_accuracy: 0.9649\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9737 - val_loss: 0.1035 - val_accuracy: 0.9685\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9784 - val_loss: 0.0970 - val_accuracy: 0.9712\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0905 - val_accuracy: 0.9729\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9847 - val_loss: 0.0916 - val_accuracy: 0.9712\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.0895 - val_accuracy: 0.9747\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0873 - val_accuracy: 0.9744\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.0855 - val_accuracy: 0.9747\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0860 - val_accuracy: 0.9742\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0830 - val_accuracy: 0.9768\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0853 - val_accuracy: 0.9762\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0853 - val_accuracy: 0.9761\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0833 - val_accuracy: 0.9777\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0828 - val_accuracy: 0.9775\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0902 - val_accuracy: 0.9746\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0919 - val_accuracy: 0.9762\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0888 - val_accuracy: 0.9758\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 18.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0916 - val_accuracy: 0.9764\n",
      "Epoch 22: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9035 - accuracy: 0.7856 - val_loss: 0.2716 - val_accuracy: 0.9203\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9259 - val_loss: 0.2015 - val_accuracy: 0.9420\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9476 - val_loss: 0.1585 - val_accuracy: 0.9540\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9599 - val_loss: 0.1390 - val_accuracy: 0.9600\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9671 - val_loss: 0.1149 - val_accuracy: 0.9656\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9742 - val_loss: 0.1038 - val_accuracy: 0.9691\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9789 - val_loss: 0.0968 - val_accuracy: 0.9716\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.0909 - val_accuracy: 0.9728\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9856 - val_loss: 0.0863 - val_accuracy: 0.9732\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.0864 - val_accuracy: 0.9747\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0912 - val_accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0861 - val_accuracy: 0.9760\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0881 - val_accuracy: 0.9747\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0867 - val_accuracy: 0.9750\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0872 - val_accuracy: 0.9765\n",
      "Epoch 16/25\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9953Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0876 - val_accuracy: 0.9758\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9147 - accuracy: 0.7744 - val_loss: 0.2669 - val_accuracy: 0.9210\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.9201 - val_loss: 0.1994 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9423 - val_loss: 0.1581 - val_accuracy: 0.9532\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9553 - val_loss: 0.1275 - val_accuracy: 0.9623\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9637 - val_loss: 0.1133 - val_accuracy: 0.9652\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9714 - val_loss: 0.1011 - val_accuracy: 0.9680\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9751 - val_loss: 0.0945 - val_accuracy: 0.9714\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.0844 - val_accuracy: 0.9744\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0958 - val_accuracy: 0.9703\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.0809 - val_accuracy: 0.9756\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0817 - val_accuracy: 0.9762\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0810 - val_accuracy: 0.9759\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0812 - val_accuracy: 0.9764\n",
      "Epoch 14/25\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 10.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0837 - val_accuracy: 0.9762\n",
      "Epoch 14: early stopping\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.9330 - accuracy: 0.7715 - val_loss: 0.2737 - val_accuracy: 0.9187\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9181 - val_loss: 0.2021 - val_accuracy: 0.9393\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9419 - val_loss: 0.1585 - val_accuracy: 0.9537\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9537 - val_loss: 0.1323 - val_accuracy: 0.9596\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9629 - val_loss: 0.1150 - val_accuracy: 0.9653\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9703 - val_loss: 0.1034 - val_accuracy: 0.9690\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9746 - val_loss: 0.0975 - val_accuracy: 0.9700\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9797 - val_loss: 0.0898 - val_accuracy: 0.9724\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.0874 - val_accuracy: 0.9724\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.0861 - val_accuracy: 0.9746\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0800 - val_accuracy: 0.9764\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0790 - val_accuracy: 0.9754\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.0871 - val_accuracy: 0.9743\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0828 - val_accuracy: 0.9749\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0841 - val_accuracy: 0.9768\n",
      "Epoch 16/25\n",
      "93/96 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9924Restoring model weights from the end of the best epoch: 12.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0847 - val_accuracy: 0.9755\n",
      "Epoch 16: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.8738 - accuracy: 0.7832 - val_loss: 0.2584 - val_accuracy: 0.9233\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9208 - val_loss: 0.1982 - val_accuracy: 0.9406\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9436 - val_loss: 0.1553 - val_accuracy: 0.9528\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9574 - val_loss: 0.1293 - val_accuracy: 0.9617\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9635 - val_loss: 0.1141 - val_accuracy: 0.9653\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9713 - val_loss: 0.1019 - val_accuracy: 0.9691\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9750 - val_loss: 0.0943 - val_accuracy: 0.9722\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9804 - val_loss: 0.0862 - val_accuracy: 0.9736\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.0912 - val_accuracy: 0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0860 - val_accuracy: 0.9732\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0809 - val_accuracy: 0.9756\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.0842 - val_accuracy: 0.9760\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.0895 - val_accuracy: 0.9743\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.0866 - val_accuracy: 0.9745\n",
      "Epoch 15/25\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9930Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0822 - val_accuracy: 0.9771\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8870 - accuracy: 0.7797 - val_loss: 0.2681 - val_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.9203 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9426 - val_loss: 0.1529 - val_accuracy: 0.9544\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9560 - val_loss: 0.1373 - val_accuracy: 0.9573\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1120 - val_accuracy: 0.9661\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9706 - val_loss: 0.1003 - val_accuracy: 0.9688\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.0942 - val_accuracy: 0.9719\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.0896 - val_accuracy: 0.9729\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9828 - val_loss: 0.0867 - val_accuracy: 0.9727\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.0833 - val_accuracy: 0.9748\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0852 - val_accuracy: 0.9744\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0837 - val_accuracy: 0.9756\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.0798 - val_accuracy: 0.9768\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0851 - val_accuracy: 0.9744\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0832 - val_accuracy: 0.9764\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0776 - val_accuracy: 0.9783\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0829 - val_accuracy: 0.9775\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0823 - val_accuracy: 0.9781\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0880 - val_accuracy: 0.9768\n",
      "Epoch 20/25\n",
      "93/96 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9945Restoring model weights from the end of the best epoch: 16.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0878 - val_accuracy: 0.9772\n",
      "Epoch 20: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9305 - accuracy: 0.7639 - val_loss: 0.2703 - val_accuracy: 0.9185\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.9152 - val_loss: 0.1951 - val_accuracy: 0.9417\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9384 - val_loss: 0.1567 - val_accuracy: 0.9542\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9525 - val_loss: 0.1225 - val_accuracy: 0.9630\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9617 - val_loss: 0.1126 - val_accuracy: 0.9654\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9684 - val_loss: 0.1006 - val_accuracy: 0.9692\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9731 - val_loss: 0.0919 - val_accuracy: 0.9729\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9780 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9791 - val_loss: 0.0963 - val_accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.0840 - val_accuracy: 0.9748\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.0797 - val_accuracy: 0.9758\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0827 - val_accuracy: 0.9762\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0809 - val_accuracy: 0.9773\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.0854 - val_accuracy: 0.9755\n",
      "Epoch 15/25\n",
      "90/96 [===========================>..] - ETA: 0s - loss: 0.0258 - accuracy: 0.9919Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0809 - val_accuracy: 0.9785\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.9458 - accuracy: 0.7601 - val_loss: 0.2713 - val_accuracy: 0.9179\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.9135 - val_loss: 0.1950 - val_accuracy: 0.9413\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9388 - val_loss: 0.1584 - val_accuracy: 0.9538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9506 - val_loss: 0.1333 - val_accuracy: 0.9602\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9610 - val_loss: 0.1154 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9672 - val_loss: 0.1031 - val_accuracy: 0.9682\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9728 - val_loss: 0.0967 - val_accuracy: 0.9700\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9767 - val_loss: 0.0898 - val_accuracy: 0.9726\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0853 - val_accuracy: 0.9736\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.0871 - val_accuracy: 0.9730\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0828 - val_accuracy: 0.9748\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.0817 - val_accuracy: 0.9760\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9871 - val_loss: 0.0853 - val_accuracy: 0.9758\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0838 - val_accuracy: 0.9748\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0826 - val_accuracy: 0.9781\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0872 - val_accuracy: 0.9760\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0855 - val_accuracy: 0.9774\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0922 - val_accuracy: 0.9758\n",
      "Epoch 20/25\n",
      "90/96 [===========================>..] - ETA: 0s - loss: 0.0172 - accuracy: 0.9943Restoring model weights from the end of the best epoch: 16.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0841 - val_accuracy: 0.9783\n",
      "Epoch 20: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8900 - accuracy: 0.7714 - val_loss: 0.2597 - val_accuracy: 0.9205\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.9160 - val_loss: 0.1980 - val_accuracy: 0.9403\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9387 - val_loss: 0.1541 - val_accuracy: 0.9536\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9528 - val_loss: 0.1306 - val_accuracy: 0.9612\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9608 - val_loss: 0.1140 - val_accuracy: 0.9646\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9676 - val_loss: 0.1001 - val_accuracy: 0.9684\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9728 - val_loss: 0.0933 - val_accuracy: 0.9718\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9776 - val_loss: 0.0913 - val_accuracy: 0.9722\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9801 - val_loss: 0.0877 - val_accuracy: 0.9732\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.0881 - val_accuracy: 0.9723\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.0789 - val_accuracy: 0.9761\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0830 - val_accuracy: 0.9761\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.0853 - val_accuracy: 0.9748\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.0856 - val_accuracy: 0.9751\n",
      "Epoch 15/25\n",
      "92/96 [===========================>..] - ETA: 0s - loss: 0.0280 - accuracy: 0.9909Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0843 - val_accuracy: 0.9763\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.8952 - accuracy: 0.7697 - val_loss: 0.2604 - val_accuracy: 0.9210\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9178 - val_loss: 0.1922 - val_accuracy: 0.9412\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9416 - val_loss: 0.1533 - val_accuracy: 0.9542\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9534 - val_loss: 0.1308 - val_accuracy: 0.9616\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9617 - val_loss: 0.1076 - val_accuracy: 0.9668\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9698 - val_loss: 0.0983 - val_accuracy: 0.9705\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9755 - val_loss: 0.0942 - val_accuracy: 0.9714\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9787 - val_loss: 0.0894 - val_accuracy: 0.9724\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.0849 - val_accuracy: 0.9741\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0859 - val_accuracy: 0.9740\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0807 - val_accuracy: 0.9765\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.0836 - val_accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0842 - val_accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0852 - val_accuracy: 0.9763\n",
      "Epoch 15/25\n",
      "92/96 [===========================>..] - ETA: 0s - loss: 0.0278 - accuracy: 0.9913Restoring model weights from the end of the best epoch: 11.\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0813 - val_accuracy: 0.9768\n",
      "Epoch 15: early stopping\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/25\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.6638 - accuracy: 0.8190 - val_loss: 0.2291 - val_accuracy: 0.9314\n",
      "Epoch 2/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.2264 - accuracy: 0.9319 - val_loss: 0.1645 - val_accuracy: 0.9495\n",
      "Epoch 3/25\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9526 - val_loss: 0.1238 - val_accuracy: 0.9630\n",
      "Epoch 4/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9637 - val_loss: 0.1007 - val_accuracy: 0.9688\n",
      "Epoch 5/25\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9717 - val_loss: 0.0921 - val_accuracy: 0.9704\n",
      "Epoch 6/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9770 - val_loss: 0.0825 - val_accuracy: 0.9733\n",
      "Epoch 7/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9808 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
      "Epoch 8/25\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0844 - val_accuracy: 0.9761\n",
      "Epoch 9/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9862 - val_loss: 0.0664 - val_accuracy: 0.9800\n",
      "Epoch 10/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 0.0774 - val_accuracy: 0.9766\n",
      "Epoch 11/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0718 - val_accuracy: 0.9806\n",
      "Epoch 12/25\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0715 - val_accuracy: 0.9809\n",
      "Epoch 13/25\n",
      "125/128 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9914Restoring model weights from the end of the best epoch: 9.\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0668 - val_accuracy: 0.9818\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    sgd_grid_result = sgd_grid.fit(\n",
    "        X= X_train, \n",
    "        y= y_train,\n",
    "        validation_data=(X_validation,y_validation),\n",
    "        verbose=1,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e5052c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.975833 using {'dropoutHL1': 0.1, 'dropoutHL2': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %f using %s\" % (sgd_grid_result.best_score_, sgd_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b550516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator stopped epoch: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator stopped epoch:\",sgd_grid_result.best_estimator_.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b475ce2",
   "metadata": {},
   "source": [
    "### models regularization dropout results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8bf698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training regularization results\n",
    "\n",
    "# model dropout with optimizer adam\n",
    "adam_model_dropout = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0.6,\n",
    "    dropoutHL2 = 0.3, \n",
    "    optimizer_learning_rate = 0.0015, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='Adam',\n",
    ")\n",
    "adam_model_dropout._name = 'adam_dropout'\n",
    "\n",
    "# model dropout with optimizer RMSprop\n",
    "rmsprop_model_dropout = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 200, \n",
    "    dropoutHL1 = 0.5,\n",
    "    dropoutHL2 = 0.1, \n",
    "    optimizer_learning_rate = 0.0015, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='RMSprop',\n",
    ")\n",
    "rmsprop_model_dropout._name = 'rmsprop_dropout'\n",
    "\n",
    "# model dropout with optimizer SGD\n",
    "sgd_model_dropout = model(\n",
    "    unitsHL1 = 750, \n",
    "    unitsHL2 = 400, \n",
    "    dropoutHL1 = 0.1,\n",
    "    dropoutHL2 = 0.2, \n",
    "    optimizer_learning_rate = 0.0020, \n",
    "    optimizer_momentum = 0.0,\n",
    "    optimizer ='SGD',\n",
    ")\n",
    "sgd_model_dropout._name = 'sgd_dropout'\n",
    "\n",
    "\n",
    "# models list\n",
    "models_list = [adam_model_dropout,rmsprop_model_dropout,sgd_model_dropout]\n",
    "# epochs list in order: [adam,rmsprop,sgd]\n",
    "models_epochs_list = [19,18,13]\n",
    "# batch size list in order: [adam,rmsprop,sgd]\n",
    "models_batch_size_list = [300,400,375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a1df474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "160/160 [==============================] - 1s 6ms/step - loss: 0.7372 - accuracy: 0.7836 - val_loss: 0.2295 - val_accuracy: 0.9307\n",
      "Epoch 2/19\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.9126 - val_loss: 0.1670 - val_accuracy: 0.9495\n",
      "Epoch 3/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9350 - val_loss: 0.1292 - val_accuracy: 0.9586\n",
      "Epoch 4/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9463 - val_loss: 0.1111 - val_accuracy: 0.9646\n",
      "Epoch 5/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9528 - val_loss: 0.0989 - val_accuracy: 0.9699\n",
      "Epoch 6/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1297 - accuracy: 0.9600 - val_loss: 0.0929 - val_accuracy: 0.9720\n",
      "Epoch 7/19\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9646 - val_loss: 0.0894 - val_accuracy: 0.9727\n",
      "Epoch 8/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9650 - val_loss: 0.0847 - val_accuracy: 0.9733\n",
      "Epoch 9/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9681 - val_loss: 0.0815 - val_accuracy: 0.9757\n",
      "Epoch 10/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9710 - val_loss: 0.0766 - val_accuracy: 0.9763\n",
      "Epoch 11/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9727 - val_loss: 0.0776 - val_accuracy: 0.9761\n",
      "Epoch 12/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9756 - val_loss: 0.0801 - val_accuracy: 0.9750\n",
      "Epoch 13/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9764 - val_loss: 0.0727 - val_accuracy: 0.9785\n",
      "Epoch 14/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.0691 - val_accuracy: 0.9799\n",
      "Epoch 15/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 0.0713 - val_accuracy: 0.9786\n",
      "Epoch 16/19\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9787 - val_loss: 0.0711 - val_accuracy: 0.9802\n",
      "Epoch 17/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 0.0707 - val_accuracy: 0.9784\n",
      "Epoch 18/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.0685 - val_accuracy: 0.9797\n",
      "Epoch 19/19\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.0646 - val_accuracy: 0.9809\n",
      "Epoch 1/18\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.8628 - accuracy: 0.7930 - val_loss: 0.2289 - val_accuracy: 0.9275\n",
      "Epoch 2/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9294 - val_loss: 0.1289 - val_accuracy: 0.9600\n",
      "Epoch 3/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9527 - val_loss: 0.1117 - val_accuracy: 0.9639\n",
      "Epoch 4/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.1187 - accuracy: 0.9629 - val_loss: 0.0929 - val_accuracy: 0.9714\n",
      "Epoch 5/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9683 - val_loss: 0.0862 - val_accuracy: 0.9743\n",
      "Epoch 6/18\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9725 - val_loss: 0.0790 - val_accuracy: 0.9761\n",
      "Epoch 7/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9761 - val_loss: 0.0777 - val_accuracy: 0.9764\n",
      "Epoch 8/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9788 - val_loss: 0.0698 - val_accuracy: 0.9792\n",
      "Epoch 9/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
      "Epoch 10/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9818 - val_loss: 0.0673 - val_accuracy: 0.9803\n",
      "Epoch 11/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
      "Epoch 12/18\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.0673 - val_accuracy: 0.9811\n",
      "Epoch 13/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9856 - val_loss: 0.0644 - val_accuracy: 0.9825\n",
      "Epoch 14/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 0.0693 - val_accuracy: 0.9836\n",
      "Epoch 15/18\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.0692 - val_accuracy: 0.9815\n",
      "Epoch 16/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9881 - val_loss: 0.0713 - val_accuracy: 0.9815\n",
      "Epoch 17/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0666 - val_accuracy: 0.9834\n",
      "Epoch 18/18\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.0792 - val_accuracy: 0.9802\n",
      "Epoch 1/13\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 2.4296 - accuracy: 0.2413 - val_loss: 1.2699 - val_accuracy: 0.6795\n",
      "Epoch 2/13\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.5216 - accuracy: 0.4875 - val_loss: 0.8982 - val_accuracy: 0.7815\n",
      "Epoch 3/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 1.1844 - accuracy: 0.6080 - val_loss: 0.7377 - val_accuracy: 0.8141\n",
      "Epoch 4/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 1.0019 - accuracy: 0.6731 - val_loss: 0.6498 - val_accuracy: 0.8316\n",
      "Epoch 5/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.7106 - val_loss: 0.5888 - val_accuracy: 0.8454\n",
      "Epoch 6/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.7369 - val_loss: 0.5496 - val_accuracy: 0.8513\n",
      "Epoch 7/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7562 - val_loss: 0.5195 - val_accuracy: 0.8587\n",
      "Epoch 8/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.7704 - val_loss: 0.4922 - val_accuracy: 0.8650\n",
      "Epoch 9/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.7810 - val_loss: 0.4725 - val_accuracy: 0.8691\n",
      "Epoch 10/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.7927 - val_loss: 0.4568 - val_accuracy: 0.8734\n",
      "Epoch 11/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7995 - val_loss: 0.4448 - val_accuracy: 0.8766\n",
      "Epoch 12/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.8066 - val_loss: 0.4320 - val_accuracy: 0.8789\n",
      "Epoch 13/13\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.8134 - val_loss: 0.4211 - val_accuracy: 0.8808\n"
     ]
    }
   ],
   "source": [
    "models_dropout_results = model_train_results(\n",
    "    models = models_list,\n",
    "    epochs = models_epochs_list,\n",
    "    batch_size = models_batch_size_list,\n",
    "    X = X_train,\n",
    "    Y = y_train,\n",
    "    X_val = X_test,\n",
    "    Y_val = y_test,\n",
    "    callbacks=None,\n",
    "    verbose = 1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d9ad3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x1300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_results(models_dropout_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a1d8acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: adam_dropout\n",
      "model adam_dropout validation loss: 0.06463388353586197\n",
      "model adam_dropout validation accuracy: 0.98089998960495\n",
      "model adam_dropout stop epoch: 19\n",
      "\n",
      "\n",
      "model: rmsprop_dropout\n",
      "model rmsprop_dropout validation loss: 0.07919890433549881\n",
      "model rmsprop_dropout validation accuracy: 0.9801999926567078\n",
      "model rmsprop_dropout stop epoch: 18\n",
      "\n",
      "\n",
      "model: sgd_dropout\n",
      "model sgd_dropout validation loss: 0.42107391357421875\n",
      "model sgd_dropout validation accuracy: 0.8808000087738037\n",
      "model sgd_dropout stop epoch: 13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    print(\"model:\",model.name)\n",
    "    print(f\"model {model.name} validation loss: {models_dropout_results[model.name]['val_loss']}\")\n",
    "    print(f\"model {model.name} validation accuracy: {models_dropout_results[model.name]['val_accuracy']}\")\n",
    "    print(f\"model {model.name} stop epoch: {models_dropout_results[model.name]['stop epochs']}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16551f8",
   "metadata": {},
   "source": [
    "`Dropout` regularization helps the models to avoid `overfitting` and reach a `convergence` point, the models perform well on the training and the validation data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10159a0f",
   "metadata": {},
   "source": [
    "# 6. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d45f02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointer file\n",
    "checkpointer_adam = ModelCheckpoint(\n",
    "    filepath='mnist_adam.best.hdf5', \n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "checkpointer_rmsprop = ModelCheckpoint(\n",
    "    filepath='mnist_rmsprop.best.hdf5', \n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "checkpointer_sgd = ModelCheckpoint(\n",
    "    filepath='mnist_sgd.best.hdf5', \n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fafbf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9828 - val_loss: 0.0171 - val_accuracy: 0.9947\n",
      "Epoch 2/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.0191 - val_accuracy: 0.9947\n",
      "Epoch 3/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
      "Epoch 4/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9843 - val_loss: 0.0189 - val_accuracy: 0.9946\n",
      "Epoch 5/19\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0471 - accuracy: 0.9840 - val_loss: 0.0220 - val_accuracy: 0.9932\n",
      "Epoch 6/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.0199 - val_accuracy: 0.9939\n",
      "Epoch 7/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.0238 - val_accuracy: 0.9914\n",
      "Epoch 8/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0270 - val_accuracy: 0.9907\n",
      "Epoch 9/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.0272 - val_accuracy: 0.9914\n",
      "Epoch 10/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.0265 - val_accuracy: 0.9916\n",
      "Epoch 11/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 0.0252 - val_accuracy: 0.9914\n",
      "Epoch 12/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 0.0350 - val_accuracy: 0.9887\n",
      "Epoch 13/19\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9852 - val_loss: 0.0306 - val_accuracy: 0.9897\n",
      "Epoch 14/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 0.0285 - val_accuracy: 0.9899\n",
      "Epoch 15/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 0.0293 - val_accuracy: 0.9897\n",
      "Epoch 16/19\n",
      "128/128 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0339 - val_accuracy: 0.9882\n",
      "Epoch 17/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 0.0276 - val_accuracy: 0.9903\n",
      "Epoch 18/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 0.0327 - val_accuracy: 0.9901\n",
      "Epoch 19/19\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0277 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "# model with adam optimizer\n",
    "hist_adam = adam_model_dropout.fit(X_train, y_train, batch_size=300, epochs=19,\n",
    "          validation_split=0.2, callbacks=[checkpointer_adam],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419400ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9890 - val_loss: 0.0073 - val_accuracy: 0.9976\n",
      "Epoch 2/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.0113 - val_accuracy: 0.9966\n",
      "Epoch 3/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.0132 - val_accuracy: 0.9952\n",
      "Epoch 4/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.0108 - val_accuracy: 0.9955\n",
      "Epoch 5/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.0126 - val_accuracy: 0.9960\n",
      "Epoch 6/18\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0134 - val_accuracy: 0.9954\n",
      "Epoch 7/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0146 - val_accuracy: 0.9954\n",
      "Epoch 8/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
      "Epoch 9/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0138 - val_accuracy: 0.9952\n",
      "Epoch 10/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
      "Epoch 11/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0203 - val_accuracy: 0.9933\n",
      "Epoch 12/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
      "Epoch 13/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0180 - val_accuracy: 0.9930\n",
      "Epoch 14/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0196 - val_accuracy: 0.9929\n",
      "Epoch 15/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0171 - val_accuracy: 0.9939\n",
      "Epoch 16/18\n",
      "96/96 [==============================] - 1s 5ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.0175 - val_accuracy: 0.9934\n",
      "Epoch 17/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9911\n",
      "Epoch 18/18\n",
      "96/96 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0208 - val_accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "# model with rmsprop optimizer\n",
    "hist_rmsprop = rmsprop_model_dropout.fit(X_train, y_train, batch_size=400, epochs=18,\n",
    "          validation_split=0.2, callbacks=[checkpointer_rmsprop],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077eb9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.5865 - accuracy: 0.8188 - val_loss: 0.4324 - val_accuracy: 0.8747\n",
      "Epoch 2/13\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.5744 - accuracy: 0.8191 - val_loss: 0.4271 - val_accuracy: 0.8764\n",
      "Epoch 3/13\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5624 - accuracy: 0.8233 - val_loss: 0.4201 - val_accuracy: 0.8786\n",
      "Epoch 4/13\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5555 - accuracy: 0.8276 - val_loss: 0.4160 - val_accuracy: 0.8798\n",
      "Epoch 5/13\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5448 - accuracy: 0.8317 - val_loss: 0.4100 - val_accuracy: 0.8805\n",
      "Epoch 6/13\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.5353 - accuracy: 0.8339 - val_loss: 0.4069 - val_accuracy: 0.8818\n",
      "Epoch 7/13\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5253 - accuracy: 0.8375 - val_loss: 0.4003 - val_accuracy: 0.8839\n",
      "Epoch 8/13\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5234 - accuracy: 0.8388 - val_loss: 0.3969 - val_accuracy: 0.8848\n",
      "Epoch 9/13\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5159 - accuracy: 0.8421 - val_loss: 0.3928 - val_accuracy: 0.8859\n",
      "Epoch 10/13\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.8412 - val_loss: 0.3888 - val_accuracy: 0.8855\n",
      "Epoch 11/13\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5054 - accuracy: 0.8455 - val_loss: 0.3839 - val_accuracy: 0.8874\n",
      "Epoch 12/13\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.8448 - val_loss: 0.3818 - val_accuracy: 0.8873\n",
      "Epoch 13/13\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8498 - val_loss: 0.3773 - val_accuracy: 0.8886\n"
     ]
    }
   ],
   "source": [
    "# model with sgd optimizer\n",
    "hist_sgd = sgd_model_dropout.fit(X_train, y_train, batch_size=375, epochs=13,\n",
    "          validation_split=0.2, callbacks=[checkpointer_sgd],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37144b1",
   "metadata": {},
   "source": [
    "# 7. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fd775",
   "metadata": {},
   "source": [
    "### Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433853fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "adam_model_dropout.load_weights('mnist_adam.best.hdf5')\n",
    "rmsprop_model_dropout.load_weights('mnist_rmsprop.best.hdf5')\n",
    "sgd_model_dropout.load_weights('mnist_sgd.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bad34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "adam_score = adam_model_dropout.evaluate(X_test,y_test,verbose=0)\n",
    "rmsprop_score = rmsprop_model_dropout.evaluate(X_test,y_test,verbose=0)\n",
    "sgd_score= sgd_model_dropout.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f926b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_test_accuracy = 100*adam_score[1]\n",
    "adam_test_loss = adam_score[0]\n",
    "\n",
    "rmsprop_test_accuracy = 100*rmsprop_score[1]\n",
    "rmsprop_test_loss = rmsprop_score[0]\n",
    "\n",
    "sgd_test_accuracy = 100*sgd_score[1]\n",
    "sgd_test_loss = sgd_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31361475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam model test accuracy: 97.96000123023987\n",
      "rmsprop model test accuracy: 98.36999773979187\n",
      "sgd model test accuracy: 89.56000208854675\n"
     ]
    }
   ],
   "source": [
    "print(\"adam model test accuracy:\",adam_test_accuracy)\n",
    "print(\"rmsprop model test accuracy:\",rmsprop_test_accuracy)\n",
    "print(\"sgd model test accuracy:\",sgd_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab8131",
   "metadata": {},
   "source": [
    "### prediction on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca667e",
   "metadata": {},
   "source": [
    "Images saved in `new_digits` folder have a length of 20 instances(`RGB` images of `32x32` pixels) and are labeled with the corresponding digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d91bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DigitsPreprocessing import custom_dataset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# convert custom images into a set for the MLP model\n",
    "folder_path = 'new_digits'\n",
    "custom_set, custom_labels = custom_dataset(folder_path)\n",
    "# preprocess custom set and labels\n",
    "custom_set = np.reshape(custom_set,(len(custom_set),28,28))\n",
    "custom_set = custom_set/255\n",
    "categorical_labels = to_categorical(custom_labels,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598f8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a raw image\n",
    "import cv2\n",
    "raw_image_path = 'new_digits/0.png'\n",
    "img = cv2.imread(raw_image_path)\n",
    "imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e9336ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot raw and preprocessed image\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(1,2,1) \n",
    "bx = fig.add_subplot(1,2,2) \n",
    "\n",
    "ax.imshow(imgRGB)\n",
    "ax.set_title(\"raw image\")\n",
    "\n",
    "bx.imshow(custom_set[0],cmap='gray')\n",
    "bx.set_title(\"preprocesed image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb86885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy prediction on custom set: 80.0000011920929\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy of the model with the custom set\n",
    "rmsprop_custom_score = rmsprop_model_dropout.evaluate(custom_set,categorical_labels,verbose=0)\n",
    "print(\"accuracy prediction on custom set:\",100*rmsprop_custom_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aabfa95f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "# predictions as single digits\n",
    "predicted_labels=[]\n",
    "predictions = rmsprop_model_dropout.predict(custom_set)\n",
    "for prediction in predictions:\n",
    "    # from categorical to single digit\n",
    "    predicted_labels.append(list(prediction).index(max(list(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2479bb34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original digits: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "predicted digits: [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 6, 2, 5, 8, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"original digits:\",custom_labels)\n",
    "print(\"predicted digits:\",predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe88b0",
   "metadata": {},
   "source": [
    "We can see that the MLP model with the `RMSprop` optimizer is the model with the highest accuracy, around  98.37%. The model performance decreases accuracy when we try to make predictions with other images that don't belong to the original dataset. The accuracy with a custom dataset was 80% (4 of the 20 images were misclassified)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
